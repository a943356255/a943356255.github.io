<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>随便起个名字吧</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-09-25T05:19:15.260Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Guo Junhao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>服务熔断</title>
    <link href="http://example.com/2023/09/25/%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/"/>
    <id>http://example.com/2023/09/25/%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/</id>
    <published>2023-09-25T05:18:00.000Z</published>
    <updated>2023-09-25T05:19:15.260Z</updated>
    
    <content type="html"><![CDATA[<h1 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h1><p>熔断机制：当服务之间发起调用的时候，如果被调用方返回的 指定错误码的比例超过一定的阈值，那么后续的请求将不会真正发起，而是由调用方直接返回错误。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230925125355151.png" alt="image-20230925125355151" style="zoom:67%;" /><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230925125408532.png" alt="image-20230925125408532"></p><p>首先是闭合状态，此时可以处理请求，但是需要一个计数器，来统计调用失败的次数，如果失败的次数达到阈值，则将状态改为闭合。</p><p>在闭合状态下，可以直接拒绝后续的请求，也可以对请求做一个降级（后续介绍）。此时会启动一个超时计时器，当计时器超时后，会转变为半打开状态。</p><p>在半打开状态下，允许一定数量的请求发往被调用的服务，如果这些调用正常，则就可以认为被调用服务已经恢复正常，此时熔断器切换为闭合状态，同时重置计数器。如果仍有部分调用失败的情况，则认为被调用方仍然没有恢复，熔断器会切换到断开状态，然后重置计数器。半打开状态是为了防止恢复中的服务被大量请求再次打垮的情况。</p><h2 id="熔断的关键点"><a href="#熔断的关键点" class="headerlink" title="熔断的关键点"></a>熔断的关键点</h2><p>有以下五个关键点：粒度控制、错误类型、存活与过载的区别、重试和熔断的关系和熔断机制的适应范围。</p><h3 id="粒度控制"><a href="#粒度控制" class="headerlink" title="粒度控制"></a>粒度控制</h3><p>该问题是指我们想将监控资源过载的粒度控制在一个什么样的范围内，这个范围可以由<strong>服务、实例和接口</strong>这三个维度的组合来得到。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230925130518335.png" alt="image-20230925130518335" style="zoom: 80%;" /><p>建议使用基于实例接口的熔断，这样的粒度最小，假如说一个实例有10个接口，只有一个接口请求超时，那么熔断该接口即可，其他接口仍然可以提供服务，将熔断的错误率讲到最低。</p><h3 id="错误类型"><a href="#错误类型" class="headerlink" title="错误类型"></a>错误类型</h3><p>由于熔断机制是用来消除系统过载的，所以，我们需要识别出与系统过载相关的错误，来进行 熔断处理，一般来说，主要有下面两个错误类型。</p><ol><li>系统被动对外表现出来的过载错误，一般来说，如果一个接口过载了，那么它的响应时间就会变长，熔断器捕获到的错误类型就是“响应超时”之类的超时错误。</li><li>系统主动对外表现出来的过载错误，对于这种情况，一般是请求的流量触发了限流等机制返回的错误码，这个是我们在程序开发过程中主动设计的。</li></ol><h3 id="过载与存活的区别"><a href="#过载与存活的区别" class="headerlink" title="过载与存活的区别"></a>过载与存活的区别</h3><p>熔断机制关心系统是否过载，最好的判断方式为利用队列中的平均等待时间来计算服务的负载。不利用服务的处理时间是为了考虑下游任务的处理时间，有时可能是因为下游处理太慢而导致的当前服务处理时间较长。</p><p>在熔断场景中，我们对过载判断进行了简化，直接通过接口请求的结果进行判断，如果发生请求错误，并且错误为超时或者限流等错误的比例超过一定的阈值，我们就可以认为系统过载，然后进行熔断。</p><p>而存活一般是指机器或者服务是否存活，对于机器是否存活，一般是通过定期 ping 机器的 IP ，如果超过一定时间不能 ping 通，则认为该机器不存活了。</p><h3 id="熔断与重试的关系"><a href="#熔断与重试的关系" class="headerlink" title="熔断与重试的关系"></a>熔断与重试的关系</h3><p>熔断和重试都会对服务之间的调用请求进行额外的处理，不同的是，重试是指我们认为该次调用失败是因为系统临时错误导致的，所以重发一次请求。而熔断是指我们已经认为系统过载了，为了保证系统不发生雪崩，为了使接口快速处理，而直接返回失败。</p><h3 id="熔断机制的适应范围"><a href="#熔断机制的适应范围" class="headerlink" title="熔断机制的适应范围"></a>熔断机制的适应范围</h3><p>只要是过载问题的场景， 我们都可以考虑利用熔断机制来解决，不论是分布式系统中服务之间的调用，还是服务与数据 库之间等其他场景的调用</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;熔断&quot;&gt;&lt;a href=&quot;#熔断&quot; class=&quot;headerlink&quot; title=&quot;熔断&quot;&gt;&lt;/a&gt;熔断&lt;/h1&gt;&lt;p&gt;熔断机制：当服务之间发起调用的时候，如果被调用方返回的 指定错误码的比例超过一定的阈值，那么后续的请求将不会真正发起，而是由调用方直接返回错</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>路由选择算法</title>
    <link href="http://example.com/2023/09/21/%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2023/09/21/%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95/</id>
    <published>2023-09-21T13:01:14.000Z</published>
    <updated>2023-09-23T13:13:20.552Z</updated>
    
    <content type="html"><![CDATA[<p>路由选择算法是为了选出从一个点发出的数据报，该如何经过各个路由器，以最小的成本或最快的速度到达目的ip的一种算法，可以理解为图中的最短路径问题。</p><p>一般而言，路由选择算法的一种分类方式是根据该算法是集中式还是分散式来划分。</p><h1 id="集中式还是分散式"><a href="#集中式还是分散式" class="headerlink" title="集中式还是分散式"></a>集中式还是分散式</h1><h2 id="集中式路由选择算法"><a href="#集中式路由选择算法" class="headerlink" title="集中式路由选择算法"></a>集中式路由选择算法</h2><p>该算法以所有节点的连通性以及所有链路的开销为输入，这就要求算法在开始之前获得这些信息。该算法可以在一个集中的控制器或者在每台路由器的路由选择组件中重复进行。</p><p>集中式算法具有关于连通性和链路开销方面的完整信息。具有全局状态信息的算法常被称作链路状态（Link State, LS）算法, 因为该算法必须知道网络中每条链路的开销。</p><h2 id="分散式路由选择算法"><a href="#分散式路由选择算法" class="headerlink" title="分散式路由选择算法"></a>分散式路由选择算法</h2><p>该算法中，路由器以迭代、分布式的方式计算出最低开销路径。没有节点拥有关于所有网络链路开销的完整信息。 相反，每个节点仅有与其直接相连链路的开销知识即可开始工作。</p><p>然后，通过迭代计算过程以及与相邻节点的信息交换，一个节点逐渐计算出到达某目的节点或一组目的节点的最低开销路径。</p><h1 id="静态的还是动态"><a href="#静态的还是动态" class="headerlink" title="静态的还是动态"></a>静态的还是动态</h1><p>路由选择算法的第二种分类是基于算法是静态的还是动态的进行分类。</p><p>在静态路由选择算法（static routing algorithm）中，路由随时间的变化非常缓慢，通常是人工进行调整。</p><p>动态路由选择算法（dynamic routing algorithm） 随着网络流量负载或拓扑发生变化而改变路由选择路径。一个动态算法可周期性地运行或 直接响应拓扑或链路开销的变化而运行。虽然动态算法易于对网络的变化做岀反应，但也 更容易受诸如路由选择循环、路由振荡之类问题的影响。</p><h1 id="负载敏感的还是负载迟钝"><a href="#负载敏感的还是负载迟钝" class="headerlink" title="负载敏感的还是负载迟钝"></a>负载敏感的还是负载迟钝</h1><p>负载敏感算法（load-sensitive algorithm）中，链路开销会动态地变化以反映出底层链路的当前拥塞水平。如果当前拥塞的一条链路与高开销相联系，则路由选择算法趋向于绕开该 拥塞链路来选择路由。</p><p>负载迟钝的并不会选择性的避开。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《计算机网络自顶向下》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;路由选择算法是为了选出从一个点发出的数据报，该如何经过各个路由器，以最小的成本或最快的速度到达目的ip的一种算法，可以理解为图中的最短路径问题。&lt;/p&gt;
&lt;p&gt;一般而言，路由选择算法的一种分类方式是根据该算法是集中式还是分散式来划分。&lt;/p&gt;
&lt;h1 id=&quot;集中式还是分散</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="网络层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>分布式场景下的CAP理论</title>
    <link href="http://example.com/2023/09/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84CAP%E7%90%86%E8%AE%BA/"/>
    <id>http://example.com/2023/09/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84CAP%E7%90%86%E8%AE%BA/</id>
    <published>2023-09-21T06:42:13.000Z</published>
    <updated>2023-09-21T07:44:01.508Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="CAP 理论"></a>CAP 理论</h1><p>CAP理论是关于数据一致性（ C：Consistency ）、服务可用性（ A：Availability ）、分区容错性（ P：Partition-tolerance ）。</p><p>CAP 理论告诉我们，一个分布式系统不可能同时满足数据一致性、服务可用性和分区容错性 这三个基本需求，最多只能同时满足其中的两个。</p><h1 id="一致性（-C-）"><a href="#一致性（-C-）" class="headerlink" title="一致性（ C ）"></a>一致性（ C ）</h1><p>这里的一致性是指强一致性，又叫线性一致性，它要求多节点组成的分布式系统，能像单节点一样运作，如果一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有的读操作都不能读到这个数据。</p><p>一致性中除了强一致性之外，还有其他的一致性级别，比如序列一致性（ Sequential Consistency ）和最终一致性（ Eventual Consistency ）等。</p><h1 id="可用性（-A-）"><a href="#可用性（-A-）" class="headerlink" title="可用性（ A ）"></a>可用性（ A ）</h1><p>可用性指的是要求系统提供的服务必须处于 100% 可用的状态，对于用 户的每一个操作请求，系统总能够在有限的时间内返回结果。</p><h1 id="分区容错性（-P-）"><a href="#分区容错性（-P-）" class="headerlink" title="分区容错性（ P ）"></a>分区容错性（ P ）</h1><p>分区指的是在整个分布式系统中，因为网络原因，系统被分隔成多个单独的部分，这里，不同系统之间在正常情况下应该是一个整体，因为网络原因不能通信才会被划分为不同的分区。在现实的分布式系统中，我们面对的就是一个不可靠的网络和有一定概率宕机的设备，这两个 因素都会导致分区出现，因此在分布式系统实现中，分区容错性 P 是一个必须项。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;CAP-理论&quot;&gt;&lt;a href=&quot;#CAP-理论&quot; class=&quot;headerlink&quot; title=&quot;CAP 理论&quot;&gt;&lt;/a&gt;CAP 理论&lt;/h1&gt;&lt;p&gt;CAP理论是关于数据一致性（ C：Consistency ）、服务可用性（ A：Availability ）</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式锁</title>
    <link href="http://example.com/2023/09/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://example.com/2023/09/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2023-09-19T07:11:08.000Z</published>
    <updated>2023-09-23T13:00:59.883Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>锁存在的意义是为了保证在多CPU，多个线程的环境中，某一个时间点上，只能由一个线程进入临界区代码，从而保证临界区操作数据的一致性。</p><p>进程内的锁，是操作系统直接提供的，对于同一台机器上的多进程，可以直接通过操作系统的锁来实现，只不过是协调了多个进程，需要将锁放在所有进程都可以访问的共享内存中，所有进程通过共享内存中的 锁来进行加锁和解锁。</p><p>但是分布式是在不同机器上，通过操作系统的锁已经无法实现。</p><h1 id="怎么实现分布式锁"><a href="#怎么实现分布式锁" class="headerlink" title="怎么实现分布式锁"></a>怎么实现分布式锁</h1><p>实现分布式锁，需要满足以下几个特性：</p><ol><li><p>互斥：保证不同节点、不同线程的互斥访问。</p></li><li><p>超时机制：即超时设置，防止死锁。因为锁服务和请求锁的服务分散在不同的机器上面，它们之间是通过网络来通信 的，所以我们需要用超时机制，来避免获得锁的节点故障或者网络异常，导致它持有的锁不能 归还，出现死锁的情况。</p><p>同时还要确保留有线程不断延长锁的时间，防止事务还没处理完，而时间到了，导致释放了锁。</p></li><li><p>完备的锁接口：比如说lock接口和trylock接口等。</p></li><li><p>可重入性：即一个节点的一个线程已经获取了锁，那么该节点持有锁的这个线程 可以再次成功获取锁。我们在加锁时，记录好当前获取锁的节点+线程组合的唯一标识，后续如果标识相同，直接返回加锁成功即可，否则按照正常流程处理。</p></li><li><p>公平性：即对于 Lock 接口获取锁失败被阻塞等待的加锁请求，在锁被释放后，如果按 先来后到的顺序，将锁颁发给等待时间最长的一个加锁请求，那么就是公平锁，否则就是非公 平锁。</p></li></ol><h1 id="分布式锁的挑战"><a href="#分布式锁的挑战" class="headerlink" title="分布式锁的挑战"></a>分布式锁的挑战</h1><p>分布式锁面临的挑战有：正确性、高可用和高性能。</p><p>首先考虑进程内的锁，如果一个线程持有锁，只要它不释放，就只有它能操作临界区的资源。同时，因为进程内锁的场景中，不会出现部分失败的情况，所以它崩溃无法释放锁时，会导致整个进程崩溃，不会出现死锁（这里不包括业务逻辑出错而导致的死锁）。</p><p>另一个方面，进程内锁的解锁操作是进程内部的函数调用，这个过程是同步的。只要发起加锁操作，就会成功（这个操作会成功，但是加锁不一定），解锁操作同样。</p><p>当存在多个进程时，加锁操作仍然是函数调用，和上边一样，但是存在一个进程获取锁后崩溃，导致无法释放锁，出现死锁。但是可以通过操作系统来判断一个进程是否存活，并查看它是否获取锁，从而解决问题。</p><p>但是在分布式场景下，发起获取锁的操作需要利用不可靠的网络，意味着发起获取锁的这个操作就有可能失败（这里称为获取锁的时延），而且获取锁后，该进程与服务器通信出现了问题，导致无法释放锁，造成死锁。这就需要设置一个超时时间，如果获取锁的进程超时，就自动释放锁。</p><p>在获取锁的时延上，如果采用超时加心跳，可能会导致服务端给客户端分发了锁，但是由于响应超时，导致客户端以为自己没有获取到锁。</p><p>为了解决这个问题，我们可以在生成锁的时候一并生成一个全局唯一且递增的版本号，当操作共享数据时，会检查版本号，如果出现版本号倒退的现象，则说明出了问题，拒绝该次请求即可。</p><h1 id="分布式锁的权衡"><a href="#分布式锁的权衡" class="headerlink" title="分布式锁的权衡"></a>分布式锁的权衡</h1><p>我们无法保证分布式锁100%的有效，而且正确性要求越高，它的性能会越低。一般来说，会在成本可接受的范围内，提供性能最好的分布式锁服务，如果性能不佳，则需要告知。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;p&gt;锁存在的意义是为了保证在多CPU，多个线程的环境中，某一个时间点上，只能由一个线程进入临界区代码，从而保证临界区操作数据的一</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>负载均衡</title>
    <link href="http://example.com/2023/09/17/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>http://example.com/2023/09/17/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</id>
    <published>2023-09-17T06:18:17.000Z</published>
    <updated>2023-09-22T06:19:23.417Z</updated>
    
    <content type="html"><![CDATA[<h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><p>在分布式的环境下，单个模块往往会部署多个，当调用方通过注册发现组件获得了被调用方的网络地址时，会获得多个地址，这时候就要通过负载均衡组件来确定是调用哪一个具体的组件。</p><p>我们可以根据负载均衡策略是否关心请求中携带的信息，即请求是否有状态，将负载均衡策略分为无状态的负载均衡、半状态的负 载均衡和全状态的负载均衡。</p><h2 id="负载均衡的关键点"><a href="#负载均衡的关键点" class="headerlink" title="负载均衡的关键点"></a>负载均衡的关键点</h2><p>负载均衡需要考虑到各个实例性能差异的情况， 让每一个实例都能充分发挥它的能力，不要出现一些实例负载比较高，而另一些实例的负载却 非常低的情况，这样会造成资源浪费。所以负载均衡的第一个关键点是<strong>公平性</strong>。即要关注被调用服务组之间的公平性，不能旱的旱死，涝的涝死。</p><p>负载均衡需要确保外部对后端服务的请求，一定能被路由到可以提供正确服务的实例上。如果后端是有状态的，那么我们就要考虑在请求上携带状态信息，然后根据状态将请求发送到对应的路由上，所以第二个关键点是<strong>正确性</strong>，即对于有状态的服务来说，负载均 衡需要关心请求的状态，将请求调度到能处理它的后端实例上，不要出现不能处理和错误处理 的情况。</p><h2 id="无状态的负载均衡"><a href="#无状态的负载均衡" class="headerlink" title="无状态的负载均衡"></a>无状态的负载均衡</h2><p>无状态的负载均衡指的是所有后端实例都是对等的，不管请求发送到哪个实力上，都会得到正确的结果，所以无状态的负载均衡不需要关心请求的状态。</p><p>如果这些无状态的实例需要处理像存储数据这种状态，则需要将这些状态信息都交由一个中心存储负责，比如MySQL或者Redis，他们不会在本地磁盘存储任何状态信息。以下是两种具体的方案</p><h3 id="轮询"><a href="#轮询" class="headerlink" title="轮询"></a>轮询</h3><p>轮询的负载均衡策略非常简单，只需要将请求按顺序分配给多个实例，不用再做其他的处理。轮询在路由时，不利用请求的状态信息，属于无状态的负载均衡策略，所以它不能用于有状态 实例的负载均衡器。</p><h3 id="权重轮询"><a href="#权重轮询" class="headerlink" title="权重轮询"></a>权重轮询</h3><p>权重轮询的负载均衡策略是将每一个后端实例分配一个权重，分配请求的数量和实例的权重成 正比轮询。例如有两个实例 A，B，假设我们设置 A 的权重为 20，B 的权重为 80，那么负载 均衡会将 20% 的请求数量分配给 A，80 % 的请求数量分配给 B。</p><h2 id="半状态的负载均衡"><a href="#半状态的负载均衡" class="headerlink" title="半状态的负载均衡"></a>半状态的负载均衡</h2><p>半状态的负载均衡指的是，虽然负载均衡策略利用请求的状态信息进行路由，但是仅仅进行简单的规则处理，比如 Hash 运算加求模来路由请求，它不保证路由的正确性，这个正确性由后端实例来保证。</p><p>一些实例会在内存中存储一些状态数据来提升系统性能，如果一个请求被分配到错误的路由中，可以通过中心存储来读取所需要的数据。</p><p>半状态的负载均衡将请求按一定的策略进行路由，后端实例可以利用路 由规则来进行优化。</p><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>Hash 负载均衡策略是指将请求的状态信息，按一定的 Hash 算法固定分配到一个实例上，例 如，按请求的来源 IP 地址或者用户的 ID，将同一个来源 IP 地址或者用户 ID 的请求固定到一 个实例上。</p><p>存在的问题：如果机器数量发生改变，则请求和实例的分配关系则会发生变化，影响正确性。</p><h3 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h3><p>一致性 Hash可以解决Hash模式下的问题。</p><p>假设Hash环的大小为2^32，那么我们先将0~2^32均匀的分布在Hash环上，然后将所有的实例按照唯一标识来计算他们在环上的位置。</p><p>对于每个请求，也采用同样的方式，都是对2^32取模，然后计算位置。如果该位置没有节点，那么就顺时针往下走，知道找到第一个有节点的位置，该请求就交由该节点执行。</p><p>这样的好处是始终对2^32取模，不管有多少个节点变动，始终不影响结果。</p><h2 id="全状态的负载均衡"><a href="#全状态的负载均衡" class="headerlink" title="全状态的负载均衡"></a>全状态的负载均衡</h2><p>全状态的负载均衡是指，负载均衡策略不仅利用请求的状态信息进行路由，并且在后端实例有 状态的情况下，依然会保证路由的正确性。</p><p>全状态的负载均衡一般以路由服务的形式存在，在路由服务里面，都会存储后端实例 ID 和状 态信息的索引，在进行请求路由的时候，路由服务从请求的状态信息中获得索引的标识，通过 查询索引获得后端实例的 ID，然后再进行路由。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;负载均衡&quot;&gt;&lt;a href=&quot;#负载均衡&quot; class=&quot;headerlink&quot; title=&quot;负载均衡&quot;&gt;&lt;/a&gt;负载均衡&lt;/h1&gt;&lt;p&gt;在分布式的环境下，单个模块往往会部署多个，当调用方通过注册发现组件获得了被调用方的网络地址时，会获得多个地址，这时候就要通过</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>路由器结构</title>
    <link href="http://example.com/2023/09/15/%E8%B7%AF%E7%94%B1%E5%99%A8%E7%BB%93%E6%9E%84/"/>
    <id>http://example.com/2023/09/15/%E8%B7%AF%E7%94%B1%E5%99%A8%E7%BB%93%E6%9E%84/</id>
    <published>2023-09-15T06:19:49.000Z</published>
    <updated>2023-09-21T06:41:23.193Z</updated>
    
    <content type="html"><![CDATA[<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><h1 id="路由器结构"><a href="#路由器结构" class="headerlink" title="路由器结构"></a>路由器结构</h1><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230511101229903.png" alt="image-20230511101229903" style="zoom:80%;" /><p>路由器由输入端口，交换结构，路由选择处理器以及输出端口组成。输入端口负责接收数据报，并且在这里决定好要怎么进行转发，然后经过交换结构，到达输出端口。即在输入端口这里已经找到了他的下一跳的地址，然后传送给交换结构，交换结构只需要根据数据去找对应的输出端口即可，可以大大减小路由表的大小。</p><p>而具体怎么找到该送往那个端口，最简单的是做一个map，包含了所有的映射，但是由于映射数量达到上百亿，不可取。另一种方案是：根据最长前缀匹配，比如说0000发网接口0，0001发网接口1，以此类推。</p><p>这里，输入端口查找的是数据报目的的ip，可能需要经过多个路由器来进行转发，才能到达目地地址。</p><h1 id="交换"><a href="#交换" class="headerlink" title="交换"></a>交换</h1><p>交换技术有三种，经内存的交换，经总线交换，互联网络交换。</p><h2 id="经内存的交换"><a href="#经内存的交换" class="headerlink" title="经内存的交换"></a>经内存的交换</h2><p>这种方案下，输入端口和输出端口的功能有点像传统操作系统中的I&#x2F;O，当一个分组到达端口，改端口通过中断向路由选择处理器发送信号，然后将分组复制到处理器内存当中，路由选择器从分组的首部提取到目的地址，在转发表找适当的输出端口，再将该分组复制到输出端口的缓存当中。</p><h2 id="经总线交换"><a href="#经总线交换" class="headerlink" title="经总线交换"></a>经总线交换</h2><p>这种方案下，输入端口经一根总线将分组直接发送到输出端口，不需要路由选择处理器的干预。这种方案下，输入端口需要预先计划一个交换机内部标签，指示本地输出端口，该分组可以由所有输出端口接受，但是只有标签匹配的才会保留，标签在输出端口被去除。单一总线会对性能造成影响</p><h2 id="经互联网络交换"><a href="#经互联网络交换" class="headerlink" title="经互联网络交换"></a>经互联网络交换</h2><p>这种方案是用2N条总线连接输入和输出端口，总线可以通过交换设备自由闭合，比如A发往X的数据，可以调整只打开A和X，但是如果有多个数据报都发往X，那么在X之前还是需要排队。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《计算机网络自顶向下》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;结构&quot;&gt;&lt;a href=&quot;#结构&quot; class=&quot;headerlink&quot; title=&quot;结构&quot;&gt;&lt;/a&gt;结构&lt;/h1&gt;&lt;h1 id=&quot;路由器结构&quot;&gt;&lt;a href=&quot;#路由器结构&quot; class=&quot;headerlink&quot; title=&quot;路由器结构&quot;&gt;&lt;/a&gt;路由器结</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="网络层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>如何保证幂等</title>
    <link href="http://example.com/2023/09/14/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%B9%82%E7%AD%89/"/>
    <id>http://example.com/2023/09/14/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%B9%82%E7%AD%89/</id>
    <published>2023-09-14T04:05:29.000Z</published>
    <updated>2023-09-22T06:19:49.491Z</updated>
    
    <content type="html"><![CDATA[<p> 考虑如下问题：在一个电商系统中，如果用户下单后，在模块之间及逆行远程调用的过程中，出现了问题，给用户响应了请求超时，那么会影响到用户购买，导致损失订单。</p><p>但是，如果对请求超时进行重试，那么会导致用户重复下单，用户明明点击了一次，却显示购买了两次，导致一些问题。</p><p>这里就涉及到了一个问题，接口的幂等性，即不管执行几次，它的影响都和执行一次一样。</p><h1 id="如何保证Exactly-once"><a href="#如何保证Exactly-once" class="headerlink" title="如何保证Exactly-once"></a>如何保证Exactly-once</h1><p>不能保证 Exactly-once 的原因主要有两个，一个是网络出现丢包或者分区等故障，另一个是远端服务发生了故障。</p><p>一般来说，在分布式系统中，实现消息的 Exactly-once 传递，主要有三种方式：一种是至少一次消息传递加消息幂等性，一种是分布式快照加状态回滚，一种是整体重做。</p><h2 id="一次传递加幂等"><a href="#一次传递加幂等" class="headerlink" title="一次传递加幂等"></a>一次传递加幂等</h2><p>该思路比较简单，就是当处理失败后，并不给用户返回请求超时，而是进行重试，保证至少请求一次成功，然后每次请求带上一个全局的唯一id，当失败重试的时候，该id并不会发生改变，成功后，将本次请求保存在数据库中，如果第二次发现该id后，并不会执行，直接返回。</p><h2 id="分布式快照加回滚"><a href="#分布式快照加回滚" class="headerlink" title="分布式快照加回滚"></a>分布式快照加回滚</h2><p>分布式快照加状态回滚指的是，在整个分布式系统运行的过程中，定期对整个系统的状态做快照，在系统运行时，不论系统的哪个地方出现故障，就将整个系统回滚到上一个快照状态，然 后再重放上一个快照状态之后的情况，直到所有的消息都被正常处理。</p><p>但是该方式并不适合在线业务，因为对在线业务做快照很难，而且对整个系统做快照，耗费资源，而且做快照的时候会导致当前系统不可处理新的业务。</p><p>该方案只适合针对于像流式计算的场景。</p><h2 id="整体重做"><a href="#整体重做" class="headerlink" title="整体重做"></a>整体重做</h2><p>整体重做的 Exactly-once 的方式，可以看成是分布式快照加状态回滚的一种特殊情况。</p><h1 id="Exactly-once-的挑战"><a href="#Exactly-once-的挑战" class="headerlink" title="Exactly-once 的挑战"></a>Exactly-once 的挑战</h1><h2 id="重试面临的挑战"><a href="#重试面临的挑战" class="headerlink" title="重试面临的挑战"></a>重试面临的挑战</h2><p>当采用重试策略来保证消息最少传递一次时，我们需要限制重试的次数，来确保不会因为重试导致系统雪崩。而且重试的时间间隔也会因为重试的次数而增加。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 考虑如下问题：在一个电商系统中，如果用户下单后，在模块之间及逆行远程调用的过程中，出现了问题，给用户响应了请求超时，那么会影响到用户购买，导致损失订单。&lt;/p&gt;
&lt;p&gt;但是，如果对请求超时进行重试，那么会导致用户重复下单，用户明明点击了一次，却显示购买了两次，导致一些问题</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务</title>
    <link href="http://example.com/2023/09/13/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2023/09/13/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2023-09-13T09:08:11.000Z</published>
    <updated>2023-09-20T08:55:32.169Z</updated>
    
    <content type="html"><![CDATA[<p>分布式事务的实现，一般有三种方案：</p><ol><li>基于 XA 协议的二阶段提交协议方法； </li><li>三阶段提交协议方法； </li><li>基于消息的最终一致性方法</li></ol><h1 id="基于-XA-协议的二阶段提交方法"><a href="#基于-XA-协议的二阶段提交方法" class="headerlink" title="基于 XA 协议的二阶段提交方法"></a>基于 XA 协议的二阶段提交方法</h1><p>XA是一个分布式事务协议，规定了事务管理器和资源管理器接口，可以分为两部分：<strong>事务管理器</strong>和<strong>本地资源管理器</strong>。</p><p>大致原理是：事务管理器作为协调者，负责各个本地资源的提交和回滚，而资源管理器就是分布式事务的参与者，通常由数据库实现。</p><p>基于 XA 协议的二阶段提交方法中，二阶段提交协议（The two-phase commit protocol，2PC），用于保证分布式系统中事务提交时的数据一致性，是 XA 在全局事务中用于协调多个资源的机制。</p><h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h2><p>投票为第一阶段，协调者会向事务的参与者发起执行操作的请求，允许他们发起提交，参与者收到请求后，会执行请求中的事务，记录日志信息但不提交，待参与者执行成功后，向协调者发送yes表示同意操作，若不成功，则发送no，表示终止。</p><p>当所有的参与者都返回了yes或者no信息后，才会进入提交阶段。</p><p>在该阶段，如果所有的参与者都发送的是yes，那么协调者将通知所有参与者提交事务，参与者收到通知后，才会完成剩下的操作。如果有一个参与者提交了no，那么所有的参与者都无法提交该事务。</p><p>不足：</p><ol><li>同步阻塞问题：该算法执行过程中，所有参与者未收到协调者信息的情况下，都处于事务阻塞状态，如果占用临界资源，则其他系统也无法。</li><li>单点故障问题：如果资源管理器发生了故障，那么整个系统就会处于停滞状态。</li><li>数据不一致问题：在提交阶段，如果协调者给参与者发送确认提交的信息时网络异常，会导致一部分参与者无法提交事务，而导致数据不一致。</li></ol><h2 id="三阶段提交"><a href="#三阶段提交" class="headerlink" title="三阶段提交"></a>三阶段提交</h2><p>三阶段提交是对二阶段提交的改进，为了防止数据不一致以及同步阻塞问题，引入了超时机制和准备阶段。如果参与者或者协调者在规定的时间内没有收到信息，则选择提交或者终止整个事务。</p><p>在第一阶段和第二阶段中间引入了一个准备阶段，也就是在提交阶段之前，加入了一个预 提交阶段。在预提交阶段排除一些不一致的情况，保证在最后提交之前各参与节点的状态是一致的。</p><p>也就是说变为了三个阶段：可以提交，预提交，和提交。</p><p>可以提交和之前的一样，不过多阐述。</p><p>而<strong>预提交</strong>是协调者根据参与者的状态来决定是否可以预提交，如果所有参与者都回复yes，协调者就会执行事务的预执行：</p><p>首先是发送预提交请求，然后参与者收到后，执行事务操作，并记录Undo和Redo信息记录到事务日志，之后，参与者如果执行成功，则返回ACK响应，同时开始等待最终指令。</p><p>到了正式提交，才是真正的提交具体的事务。</p><p>不管是二阶段还是三阶段提交，都无法解决性能低，包括数据出现不一致的情况。</p><h1 id="基于分布式消息的最终一致性方案"><a href="#基于分布式消息的最终一致性方案" class="headerlink" title="基于分布式消息的最终一致性方案"></a>基于分布式消息的最终一致性方案</h1><p>这个就是引入了一个中间件，比如消息队列，用于存储消息，比如日志或者消息可以存进来，异步的去进行执行，来达到数据最终的一致性，中间还是会有部分时间的不一致。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《分布式技术原理与算法解析》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;分布式事务的实现，一般有三种方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于 XA 协议的二阶段提交协议方法； &lt;/li&gt;
&lt;li&gt;三阶段提交协议方法； &lt;/li&gt;
&lt;li&gt;基于消息的最终一致性方法&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;基于-XA-协议的二阶段提交方法&quot;&gt;&lt;a hr</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式下如何访问共享资源</title>
    <link href="http://example.com/2023/09/11/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E8%AE%BF%E9%97%AE%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90/"/>
    <id>http://example.com/2023/09/11/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E8%AE%BF%E9%97%AE%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90/</id>
    <published>2023-09-11T08:01:48.000Z</published>
    <updated>2023-09-20T08:25:56.617Z</updated>
    
    <content type="html"><![CDATA[<p>互斥资源指的是那种一次只可以一个系统访问的资源。</p><h1 id="集中式算法"><a href="#集中式算法" class="headerlink" title="集中式算法"></a>集中式算法</h1><p>该算法需要借助于一个第三方软件，或者说一个数据中心，每当有系统需要访问互斥资源时，需要先该数据中心发送请求，看是否其他的系统请求该资源。然后数据中心给系统返回是否可以访问该资源，如果同意，则系统访问互斥资源。</p><p>存在的问题：数据中心容易成为瓶颈，所有的系统都要请求数据中心，如果数据中心出现阻塞或者不可用，则有可能导致整个系统不可用。</p><h1 id="民主协商：分布式算法"><a href="#民主协商：分布式算法" class="headerlink" title="民主协商：分布式算法"></a>民主协商：分布式算法</h1><p>在该算法下，如果要访问互斥资源，则采用互相通信的形式，比如说现在有A，B，C，D四个系统，其中A想要访问某资源，它会向B，C，D三个系统发送请求，询问是否有人需要使用该资源。如果没有，则A访问该资源。假如D此时也想要访问该资源，则A，B，C会收到请求，而B，C即收到了A的请求，也受到了D的请求，由于A先到，所以会优先允许A访问资源。</p><p>而不同系统的请求会被放入一个队列当中，依次允许访问共享资源。</p><p>缺点：如果系统特别多，则访问一次资源所要发送的广播信息会消耗大量的资源，导致一定的浪费。而且部分节点可能不可用，导致一直处于等待，该问题的解决办法是忽略下线了的节点。</p><h1 id="轮值-CEO：令牌环算法"><a href="#轮值-CEO：令牌环算法" class="headerlink" title="轮值 CEO：令牌环算法"></a>轮值 CEO：令牌环算法</h1><p>该算法是产生一个令牌，令牌依次传递给每一个系统，拿到该令牌的系统，如果有访问共享资源的需求，则它可以访问共享资源，否则无法访问共享资源。</p><p>缺点：降低了系统的实时性。比如说有100个系统，系统1访问完共享资源后，其他99个系统无需访问共享资源，但令牌仍然需要转一圈才能到达系统1这里。而且令牌的传递需要忽略已经下线了的节点。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《分布式技术原理与算法解析》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;互斥资源指的是那种一次只可以一个系统访问的资源。&lt;/p&gt;
&lt;h1 id=&quot;集中式算法&quot;&gt;&lt;a href=&quot;#集中式算法&quot; class=&quot;headerlink&quot; title=&quot;集中式算法&quot;&gt;&lt;/a&gt;集中式算法&lt;/h1&gt;&lt;p&gt;该算法需要借助于一个第三方软件，或者说一个数据中心，</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>数据分区再平衡</title>
    <link href="http://example.com/2023/09/09/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1/"/>
    <id>http://example.com/2023/09/09/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1/</id>
    <published>2023-09-09T07:08:52.000Z</published>
    <updated>2023-09-20T04:06:10.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分区再平衡"><a href="#分区再平衡" class="headerlink" title="分区再平衡"></a>分区再平衡</h1><h2 id="采用取余的坏处"><a href="#采用取余的坏处" class="headerlink" title="采用取余的坏处"></a>采用取余的坏处</h2><p>如果采用取模的话，新添加节点或者删除节点，都有可能导致分区中的数据进行移动，最简单的例子，之前有10个节点，那么分区1000计算方法为1000%10 &#x3D; 0，就在第0个分区，如果此时添加一个新的节点，变为了1000%11 &#x3D; 10，此时就要将之前存在于下标为0的节点数据重新分配到下标为10的节点，导致性能损失。</p><h2 id="固定分区数量"><a href="#固定分区数量" class="headerlink" title="固定分区数量"></a>固定分区数量</h2><p>改策略是指提前规定好分区有多少个，比如说提前固定分区有1000个，然后当前有10个节点，那么每个节点就存在100个分区。这样做的好处就在于，如果存在新添加的节点，那么只需要将之前节点中存在的分区划分给新节点即可，如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230913151508491.png" alt="image-20230913151508491" style="zoom:67%;" /><p>这样可以避免采用取余的坏处，并不需要频繁的移动每个分区的数据。</p><h2 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h2><p>如果之前的分区不是很合理，导致了一个分区中存在大量的数据，而其他分区几乎是空的，就可以利用到动态分区。</p><p>他的设计方式如下：提前设置一个阈值，当某一个分区达到该值之后，就会将该分区拆分为两个分区，如果某些分区数据特别少，那么就会将相邻的两个分区进行合并。该过程类似于B树的分裂或者合并。</p><p>它的一个优点是分区数量可以自适应数据的总量，但是在一个空数据库中，一开始可能只有一个分区，当道达分裂点后，后续的写入可能还是会在一个分区中进行。</p><h2 id="按节点比例分区"><a href="#按节点比例分区" class="headerlink" title="按节点比例分区"></a>按节点比例分区</h2><p>该分区方式中，每个节点有固定数量的分区。</p><p>当节点数量不变时，每个分区的大小与数据集的大小成正比，当节点数增加时，分区则会调整变得更小。</p><p>当一个新的节点加入分区时，随机选择固定数量的分区进行分裂，然后拿走这些分区一半的数据量。</p><h1 id="路由发现"><a href="#路由发现" class="headerlink" title="路由发现"></a>路由发现</h1><p>当数据被分散到多个节点上时，我们读取数据的时候，如何知道我们想要的数据在哪里，这始终是一个问题，该问题也称为服务发现。</p><p>解决办法有以下三种：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230913155735479.png" alt="image-20230913155735479"></p><p>而该过程中，可能需要一些其他的第三方软件，比如Zookeeper。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230913155838336.png" alt="image-20230913155838336"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《数据密集型系统设计》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分区再平衡&quot;&gt;&lt;a href=&quot;#分区再平衡&quot; class=&quot;headerlink&quot; title=&quot;分区再平衡&quot;&gt;&lt;/a&gt;分区再平衡&lt;/h1&gt;&lt;h2 id=&quot;采用取余的坏处&quot;&gt;&lt;a href=&quot;#采用取余的坏处&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>如何实现高性能延时消息</title>
    <link href="http://example.com/2023/09/06/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF/"/>
    <id>http://example.com/2023/09/06/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF/</id>
    <published>2023-09-06T02:37:47.000Z</published>
    <updated>2023-09-06T03:14:36.965Z</updated>
    
    <content type="html"><![CDATA[<h1 id="延时消息使用场景"><a href="#延时消息使用场景" class="headerlink" title="延时消息使用场景"></a>延时消息使用场景</h1><p>需要某些事件在特定的时间点上触发时，就需要用到延时消息。</p><h1 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h1><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906104126430.png" alt="image-20230906104126430"></p><p>延时消息可以通过定时扫描来实现，但是资源浪费太多。</p><p>如果使用消息队列，可以理解为生产者生产一条消息，但是并不会被消费者看到，当到达固定的时间点后，消费者才能够看到并且消费消息。所以从技术上来看，消息队列实现延时消息主要包含<strong>数据存储、如何让消息可见、定时机制、主动推送</strong>四个部分。</p><p>以下主要介绍<strong>消息可见</strong>和<strong>定时机制</strong>。</p><h2 id="如何让消息可见"><a href="#如何让消息可见" class="headerlink" title="如何让消息可见"></a>如何让消息可见</h2><p>让消息从不可见变为可见的思路：先将数据写入到临时存储，然后根据一定机制在数据到期后让消费端可以看到该消息。</p><p>临时存储大多有以下三种选择：</p><ol><li><p>单独设计的数据结构</p></li><li><p>独立的 Topic</p></li><li><p>本地的某个存储引擎（如 RocksDB、Mnesia 等）</p></li></ol><p>延时到期后，消费者如何得知该消息可以消费，有以下两种实现：</p><ol><li>定时检测写入</li><li>消费时判断是否可见</li></ol><p>定时检测写入：指的是先将消息写入某个地方，同时有独立的线程去判断数据是否到期，如果到期则将数据写入真正的存储当中。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906104734666.png" alt="image-20230906104734666"></p><p>消费时判断数据是否可见：是指每次消费时判断是否有到期的延时消息，如果有则从第三方存储中拉取，供消费者消费。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906104931264.png" alt="image-20230906104931264"></p><p>实际上，大多采用第一种方案。因为每次消费时都去判断一下是否有消息可见，则会对性能造成一定的影响。</p><h2 id="定时机制的实现"><a href="#定时机制的实现" class="headerlink" title="定时机制的实现"></a>定时机制的实现</h2><p>定时机制的核心：随着时间的推移，拿出到期的延时消息进行处理。从技术上看，定时机制可以拆解为<strong>定时器</strong>和<strong>延时消息定位处理</strong>两部分。</p><p>定时器就是按照时间推进，说白了就是记录一下时间。</p><p>延时消息定位是指随着定时器的推进，在每个时间刻度可以高效定位，获取到该时刻需要处理的延时消息。</p><h1 id="延时消息的技术方案"><a href="#延时消息的技术方案" class="headerlink" title="延时消息的技术方案"></a>延时消息的技术方案</h1><p>延时消息的实现主要有基于轮询检测机制的实现和基于时间轮机制的实现两种方案。</p><h2 id="基于轮询检测机制的实现"><a href="#基于轮询检测机制的实现" class="headerlink" title="基于轮询检测机制的实现"></a>基于轮询检测机制的实现</h2><p>核心思路：将消息写入到独立的存储当中，利用类似于while + sleep的定时器，来推进时间，通过独立线程检测数据是否到期，然后取出到期数据，存入正式存储。</p><p>我们可以将独立存储根据时间划分，大致结构如下：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906110914110.png" alt="image-20230906110914110"></p><p>这样可以减小每个队列的长度。而每个队列采用什么结构，则可以根据实际的应用场景决定。</p><h2 id="基于时间轮机制的实现"><a href="#基于时间轮机制的实现" class="headerlink" title="基于时间轮机制的实现"></a>基于时间轮机制的实现</h2><p>核心思路：将延时消息写入到独立的存储中，然后通过构建多级时间轮，在每个时间刻度上挂载需要处理的延时消息的索引列表。再依赖时间轮的推进，获取到需要处理的延时消息列表，进行后续的处理。</p><p>时间轮是一个很成熟的算法，分为<strong>单级时间轮</strong>和<strong>多级时间轮</strong>，具体结构如下：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906111154935.png" alt="image-20230906111154935"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;延时消息使用场景&quot;&gt;&lt;a href=&quot;#延时消息使用场景&quot; class=&quot;headerlink&quot; title=&quot;延时消息使用场景&quot;&gt;&lt;/a&gt;延时消息使用场景&lt;/h1&gt;&lt;p&gt;需要某些事件在特定的时间点上触发时，就需要用到延时消息。&lt;/p&gt;
&lt;h1 id=&quot;如何实现&quot;</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消息队列分布式限流方案</title>
    <link href="http://example.com/2023/09/01/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81%E6%96%B9%E6%A1%88/"/>
    <id>http://example.com/2023/09/01/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81%E6%96%B9%E6%A1%88/</id>
    <published>2023-09-01T12:09:16.000Z</published>
    <updated>2023-09-01T12:15:10.618Z</updated>
    
    <content type="html"><![CDATA[<h1 id="限流分类"><a href="#限流分类" class="headerlink" title="限流分类"></a>限流分类</h1><p>1、单机限流</p><p>限制每一台broker的流量，如下图所示：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230901201114249.png" alt="image-20230901201114249"></p><p>2、全局限流</p><p>限制所有broker的流量和，这种方案往往需要一个第三方的平台来统计目前所有Broker的总流量，如下图所示：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230901201158231.png" alt="image-20230901201158231"></p><h1 id="对什么限流"><a href="#对什么限流" class="headerlink" title="对什么限流"></a>对什么限流</h1><p>主要对流量、连接数、请求数三类资源进行限流。</p><p><strong>流量限制</strong>指对生产、消费的流量限制。</p><p><strong>连接数限制</strong>指对客户端连接到服务端的 TCP 连接数量进行限制。因为 TCP 连接的建立和关闭需要消耗 CPU、内存等资源，限制是为了保护服务端不会因为连接数太多，耗尽资源，导致服务不可用，主要从一下三个方面：</p><ul><li><p>服务端单机可承载的最大连接数限制。</p></li><li><p>客户端单个 IP 可建立的连接数。</p></li><li><p>单个集群可建立的总链接数。</p></li></ul><p><strong>请求数限制</strong>指对单个接口的访问频次进行限制，来保护集群自身的可用性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;限流分类&quot;&gt;&lt;a href=&quot;#限流分类&quot; class=&quot;headerlink&quot; title=&quot;限流分类&quot;&gt;&lt;/a&gt;限流分类&lt;/h1&gt;&lt;p&gt;1、单机限流&lt;/p&gt;
&lt;p&gt;限制每一台broker的流量，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/09/Java/Mybatis%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A4%8D%E6%9D%82%E5%86%99%E6%B3%95/"/>
    <id>http://example.com/2023/08/09/Java/Mybatis%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A4%8D%E6%9D%82%E5%86%99%E6%B3%95/</id>
    <published>2023-08-09T05:16:01.853Z</published>
    <updated>2023-08-09T06:33:13.794Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Mybatis的一些复杂写法"><a href="#Mybatis的一些复杂写法" class="headerlink" title="Mybatis的一些复杂写法"></a>Mybatis的一些复杂写法</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 这里拿到的是key</span><br><span class="line">&lt;foreach collection=<span class="string">&quot;columns.keys&quot;</span> item=<span class="string">&quot;key&quot;</span> separator=<span class="string">&quot;,&quot;</span> open=<span class="string">&quot;(&quot;</span> close=<span class="string">&quot;)&quot;</span>&gt;</span><br><span class="line">    #&#123;key&#125;</span><br><span class="line">&lt;/foreach&gt;</span><br><span class="line"># 这里拿到的也是value</span><br><span class="line">&lt;foreach collection=<span class="string">&quot;columns.keys&quot;</span> item=<span class="string">&quot;key&quot;</span> separator=<span class="string">&quot;,&quot;</span> open=<span class="string">&quot;(&quot;</span> close=<span class="string">&quot;)&quot;</span>&gt;</span><br><span class="line">    #&#123;columns[$&#123;key&#125;]&#125;</span><br><span class="line">&lt;/foreach&gt;</span><br><span class="line"># 这里拿到的是value</span><br><span class="line">&lt;foreach collection=<span class="string">&quot;columns.values&quot;</span> item=<span class="string">&quot;key&quot;</span> separator=<span class="string">&quot;,&quot;</span> open=<span class="string">&quot;(&quot;</span> close=<span class="string">&quot;)&quot;</span>&gt;</span><br><span class="line">    #&#123;key&#125;</span><br><span class="line">&lt;/foreach&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Mybatis的一些复杂写法&quot;&gt;&lt;a href=&quot;#Mybatis的一些复杂写法&quot; class=&quot;headerlink&quot; title=&quot;Mybatis的一些复杂写法&quot;&gt;&lt;/a&gt;Mybatis的一些复杂写法&lt;/h1&gt;&lt;figure class=&quot;highlight </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Java开发分布式系统的编码技巧</title>
    <link href="http://example.com/2023/08/07/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Java%E5%BC%80%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BC%96%E7%A0%81%E6%8A%80%E5%B7%A7/"/>
    <id>http://example.com/2023/08/07/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Java%E5%BC%80%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BC%96%E7%A0%81%E6%8A%80%E5%B7%A7/</id>
    <published>2023-08-07T01:58:48.000Z</published>
    <updated>2023-08-07T02:55:28.177Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PageCache-调优和-Direct-IO"><a href="#PageCache-调优和-Direct-IO" class="headerlink" title="PageCache 调优和 Direct IO"></a>PageCache 调优和 Direct IO</h1><p>应用程序读取文件，会经过应用缓存、PageCache、DISK（硬盘）三层。</p><p>Linux内核读取到文件数据后，会把它缓存一段时间，这个文件缓存就是PageCache。它会进行适当的预读，比如用户当前只需要读取1kb的文件，但是它的算法觉得读取16k或者更多更合适，那么它就会读取16kb，加载到PageCache中，下次读取先去PageCache中查找。</p><p>但是以下三种情况没法使用PageCache：</p><ol><li><p>使用 FIleChannel 读写时，底层可能走 Direct IO，不走页缓存。</p></li><li><p>在内存有限或者不够用的时候，频繁换页，导致缓存命中率低。</p></li><li><p>大量随机读的场景，导致页缓存的数据无法命中。</p></li></ol><p>一种解决思路是：<strong>通过使用Direct IO 来模拟实现PageCahce的效果</strong>。原先PageCache的底层实现，是由操作系统实现的，比如说数据加载，缓存命中，换页，刷盘等，我们无法控制。我们可以通过自定义 Cache + Direct IO 来实现自己可控的操作。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230807102215994.png" alt="image-20230807102215994"></p><h1 id="FileChannel-和-mmap"><a href="#FileChannel-和-mmap" class="headerlink" title="FileChannel 和 mmap"></a>FileChannel 和 mmap</h1><p>Java 原生的 IO 主要可以分为普通 IO、FileChannel（文件通道）、mmap（内存映射）三种。</p><p>java.io 包中的 FileWriter 和 FileReader 属于普通 IO，java.nio 包中的 FileChannel 属于 NIO 的一种，mmap 是调用 FileChannel.map() 实例出来的一种特殊读写文件的方式，被称为内存映射。</p><h2 id="FileChannel"><a href="#FileChannel" class="headerlink" title="FileChannel"></a>FileChannel</h2><p><strong>FileChannel 大多数时候是和 ByteBuffer 打交道的</strong>，ByteBiffer是byte[]的一个封装类，ByteBuffer 是在应用内存中的，它和硬盘之间还隔着一层 PageCache。从使用上看，我们通过 filechannel.write 写入数据时，会将数据从应用内存写入到 PageCache，此时便认为完成了落盘操作。但实际上，操作系统最终帮我们将 PageCache 的数据自动刷到了硬盘。</p><h2 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h2><p>mmap 是一个把文件映射到内存的操作，因此可以像读写内存一样读写文件。它省去了用户空间到内核空间的数据复制过程，从而提高了读写性能。</p><p>从经验来看，mmap 在内存充足、数据文件较小且相对固定的场景下，性能比 FileChannel 高。<strong>但它有这样几个缺点：</strong></p><ol><li><p>使用时必须先指定好内存映射的大小，并且一次 Map 的大小限制在 1.5G 左右。</p></li><li><p>是由操作系统来刷盘的，手动刷盘时间不好掌握。</p></li><li><p>回收非常复杂，需要手动释放，并且代码和实现很复杂。</p></li></ol><p>在消息队列数据文件分段的场景下，因为每个段文件的大小是固定的，且大小还是可配置的，所以是可以使用 mmap 来提高性能的。</p><h1 id="直接内存（堆外）和堆内内存"><a href="#直接内存（堆外）和堆内内存" class="headerlink" title="直接内存（堆外）和堆内内存"></a>直接内存（堆外）和堆内内存</h1><p>堆内和堆外的堆是指 JVM 堆，堆内内存就是指 JVM 堆内部的内存空间，堆外就是指除了 JVM 堆以外的内存空间。堆内内存加上堆外内存等于总内存。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230807103548870.png" alt="image-20230807103548870" style="zoom:80%;" /><p>如何选择堆外内存和堆内内存：</p><ol><li>当需要申请大块的内存时，堆内内存会受到限制，可以尝试分配堆外内存</li><li>堆外内存适用于生命周期中等或较长的对象</li><li>堆内内存刷盘的过程中，还需要复制一份到堆外内存，多了一步，会降低性能</li><li>创建堆外内存的消耗要大于创建堆内内存的消耗，所以当分配了堆外内存之后，要尽可能复用它</li><li>可以使用池化 + 堆外内存的组合方式，比如代码中如果需要频繁  new byte[]，就可以研究一下 ThreadLocal 和  ThreadLocal&lt;byte[]&gt; 的使用机制。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PageCache-调优和-Direct-IO&quot;&gt;&lt;a href=&quot;#PageCache-调优和-Direct-IO&quot; class=&quot;headerlink&quot; title=&quot;PageCache 调优和 Direct IO&quot;&gt;&lt;/a&gt;PageCache 调优和 Dir</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="Java" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Java/"/>
    
    <category term="并发" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Java/%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ的设计</title>
    <link href="http://example.com/2023/07/24/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ%E7%9A%84%E8%AE%BE%E8%AE%A1/"/>
    <id>http://example.com/2023/07/24/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ%E7%9A%84%E8%AE%BE%E8%AE%A1/</id>
    <published>2023-07-24T12:16:13.000Z</published>
    <updated>2023-07-24T12:42:32.898Z</updated>
    
    <content type="html"><![CDATA[<p>下图是RabbitMQ的系统架构：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724201809821.png" alt="image-20230724201809821"></p><p>RabbitMQ 由 Producer、Broker、Consumer 三个大模块组成。</p><p>生产者将数据发送到 Broker，Broker 接收到数据后，将数据存储到对应的 Queue 里面，消费者从不同的 Queue 消费数据。它有 Exchange、Bind、Route 这几个独有的概念。</p><p>Exchange 称为交换器，它是一个逻辑上的概念，用来做分发，本身不存储数据。流程上生产者先将消息发送到 Exchange，而不是发送到数据的实际存储单元 Queue 里面。然后 Exchange 会根据一定的规则将数据分发到实际的 Queue 里面存储。</p><p>这个分发过程就是 Route（路由），设置路由规则的过程就是 Bind（绑定）。即 Exchange 会接收客户端发送过来的 route_key，然后根据不同的路由规则，将数据发送到不同的 Queue 里面。</p><h1 id="协议和网络模块"><a href="#协议和网络模块" class="headerlink" title="协议和网络模块"></a>协议和网络模块</h1><p>在网络通信协议层面，RabbitMQ 数据流是基于四层 TCP 协议通信的，跑在 TCP 上的应用层协议是 AMQP。</p><p>RabbitMQ 的网络层有 Connectoion 和 Channel 两个概念需要注意。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724202241340.png" alt="image-20230724202241340"></p><p>Connection 是指 TCP 连接，Channel 是 Connection 中的虚拟连接。两者的关系是：一个客户端和一个 Broker 之间只会建立一条 TCP 连接，就是指 Connection。Channel（虚拟连接）的概念在这个连接中定义，一个 Connection 中可以创建多个 Channel。</p><p><strong>客户端和服务端的实际通信都是在 Channel 维度通信的。</strong></p><p>RabbitMQ 服务端通过 tcp_listener 监听端口，tcp_acceptor 接收请求，rabbit_reader 处理和返回请求。本质上来看是也是一个多线程的网络模型。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724202504119.png" alt="image-20230724202504119"></p><h1 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h1><p>RabbitMQ 的存储模块也包含元数据存储与消息数据存储两部分。RabbitMQ 的两类数据都是存储在 Broker 节点上的。</p><h2 id="元数据存储"><a href="#元数据存储" class="headerlink" title="元数据存储"></a>元数据存储</h2><p>RabbitMQ 的元数据都是存在于 Erlang 自带的分布式数据库 Mnesia 中的。即每台 Broker 都会起一个 Mnesia 进程，用来保存一份完整的元数据信息。Mnesia是一个分布式数据库，自带了多节点自动同步机制。</p><h2 id="消息数据存储"><a href="#消息数据存储" class="headerlink" title="消息数据存储"></a>消息数据存储</h2><p>RabbitMQ 消息数据的最小存储单元是 Queue，即消息数据是按顺序写入存储到 Queue 里面的。</p><p>在底层的数据存储方面，所有的 Queue 数据是存储在同一个“文件”里面的。这个“文件”是一个虚拟的概念，表示所有的 Queue 数据是存储在一起的意思。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724202717072.png" alt="image-20230724202717072"></p><p>这个“文件”由队列索引（rabbit_queue_index）和消息存储（rabbitmq_msg_store）两部分组成。即在节点维度，所有 Queue 数据都是存储在 rabbit_msg_store 里面的，每个节点上只有一个 rabbit_msg_store，数据会依次顺序写入到 rabbit_msg_store 中。</p><p>rabbit_msg_store 是一个逻辑概念，底层的实际存储单元分为两个，msg_store_persistent 和 msg_store_transient，分别负责持久化消息和非持久化消息的存储。</p><p>这里所有的消息都会以追加的形式写入一个文件当中，当一个文件的大小超过了配置的最大大小，就会新开一个文件来存储。</p><p>队列索引负责存储、维护队列中落盘消息的信息，包括消息的存储位置、是否交付、是否 ACK 等等信息。队列索引是 Queue 维度的，每个 Queue 都有一个对应的队列索引。</p><p>删除消息时，不会立即删除数据，只是从 Erlang 中的 ETS 表删除指定消息的相关信息，同时更新消息对应的存储文件的相关信息。此时文件中的消息不会立即被删除，会被标记为已删除数据，直到一个文件中都是可以删除的数据时，再将这个文件删除，这个动作就是常说的延时删除。另外内核有检测机制，会检查前后两个文件中的数据是否可以合并，当符合合并规则时，会进行段文件的合并。</p><h1 id="生产者和消费者"><a href="#生产者和消费者" class="headerlink" title="生产者和消费者"></a>生产者和消费者</h1><p>当生产者和消费者连接到 Broker 进行生产消费的时候，是直接和 Broker 交互的，不需要客户端寻址。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724203444673.png" alt="image-20230724203444673" style="zoom:80%;" /><p>RabbitMQ 集群部署后，为了提高容灾能力，就需要在集群前面挂一层负载均衡来进行灾备。但是一个客户端拿到负载均衡ip的时候，去对应的Broker去消费数据，可能会出现该条消息并不存储于该Broker而导致消费失败。</p><p>为了解决这个问题，每个 Broker 上会设置有转发的功能。在实现上，每台 Broker 节点都会保存集群所有的元数据信息。当 Broker 收到请求后，根据本地缓存的元数据信息判断 Queue 是否在本机上，如果不在本机，就会将请求转发到 Queue 所在的目标节点。</p><p>生产端发送数据不是直接发送到 Queue，而是直接发送到 Exchange。即发送时需要指定 Exchange 和 route_key，服务端会根据这两个信息，将消息数据分发到具体的 Queue。</p><p>在消费端，RabbitMQ 支持 Push（推）和 Pull（拉）两种模式，如果使用了 Push 模式，Broker 会不断地推送消息给消费者（如果有消息的情况下）。推送消息的个数会受到 channel.basicQos 的限制，不能无限推送，在消费端会设置一个缓冲区来缓冲这些消息。</p><p>拉模式是指客户端不断地去服务端拉取消息，RabbitMQ 的拉模式只支持拉取单条消息。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;下图是RabbitMQ的系统架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724201809821.png&quot; alt=&quot;image-2023072</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消费客户端的SDK（下）</title>
    <link href="http://example.com/2023/07/22/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E8%B4%B9%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84SDK%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
    <id>http://example.com/2023/07/22/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E8%B4%B9%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84SDK%EF%BC%88%E4%B8%8B%EF%BC%89/</id>
    <published>2023-07-22T02:32:37.000Z</published>
    <updated>2023-07-22T03:14:35.444Z</updated>
    
    <content type="html"><![CDATA[<p>这里介绍上篇剩下的三部分，也就是消费分组（订阅）、消费确认、消费失败处理。</p><h1 id="消费分组"><a href="#消费分组" class="headerlink" title="消费分组"></a>消费分组</h1><p>消费分组是用来组织消费者、分区、消费进度关系的逻辑概念。</p><p>在没有消费分组直接消费 Topic 的场景下，如果希望不重复消费 Topic 中的数据，那么就<strong>需要有一个标识来标识当前的消费情况，比如记录进度。</strong>这个唯一标识就是消费分组。</p><p>消费分组主要有管理消费者和分区的对应关系、保存消费者的消费进度、实现消息可重复被消费三类功能。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230722104248529.png" alt="image-20230722104248529" style="zoom:80%;" /><p>因为 Topic 不存储真实数据，分区才存储消息数据，所以就需要解决消费者和分区的分配关系，即<strong>哪个分区被哪个消费者消费，这个分配的过程就叫做消费重平衡（Rebalance）</strong>。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230722104350416.png" alt="image-20230722104350416" style="zoom:80%;" /><p>由上图可以看出，当新增一个消费分组时，为了使得消费平衡，就需要重新分配消费关系。</p><h2 id="协调者"><a href="#协调者" class="headerlink" title="协调者"></a>协调者</h2><p>如果要对消费者和分区进行分配，肯定需要有一个模块拥有消费分组、所有的消费者、分区信息三部分信息，这个模块我们一般命名为<strong>协调者。</strong>协调者主要的工作就是执行消费重平衡，并记录消费分组的消费进度。</p><p>分区分配的操作可以在协调者内部或者消费者上完成。这两种，一种是协调者获得所有的信息，然后进行分配，分配完同步给其他的消费者。一种是一个消费者获取所有其他消费者和分区的信息，进行分配操作，之后同步给其他消费者。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230722105108840.png" alt="image-20230722105108840" style="zoom:80%;" /><h2 id="消费分区分配策略"><a href="#消费分区分配策略" class="headerlink" title="消费分区分配策略"></a>消费分区分配策略</h2><p>分区分配策略的制定一般遵循以下三个原则：</p><ol><li>各个分区的数据能均匀地分配给每个消费者，保证所有消费者的负载最大概率是均衡的。</li><li>在每次重新分配的时候，尽量减少分区和消费者之间的关系变动，这样有助于加快重新分配的速度，并且保持数据处理的连续性，降低处理切换成本。</li><li>可以允许灵活地根据业务特性制定分配关系</li></ol><p>所有消息队列的默认策略都是相对通用的，一般都会包含有轮询、粘性、自定义三种类型的策略。</p><p><strong>轮询</strong>就是指用轮询的方式将分区分配给各个消费者，保证每个消费者的分区数量是尽量相同的，从而保证消费者的负载最大概率上是均衡的。但是这种方案可能导致几个流量较高的分区分给了同一个消费者，为了解决这个问题，在随机的基础上，将 Topic 的不同分区尽量打散到不同的消费者，从而保证整体消费者之间的分区是均衡的（即同一个topic下的不同partition分给不同的消费者）。</p><p><strong>粘性</strong>是指尽量减少分区分配关系的变动，进而减少重平衡所耗费的时间和资源损耗。即当有新的分区加入，或者老的分区挂掉，在重新分配时，应尽可能减少变动。</p><p>自定义就是提供接口，用户自己实现。</p><h1 id="消费确认"><a href="#消费确认" class="headerlink" title="消费确认"></a>消费确认</h1><p>当消息被消费时，就必须进行消费确认，即告诉服务端这条消息已经被消费了，也就是常说的ACK。</p><p>一般情况下，消息确认分为确认后删除数据和确认后保存消费进度数据两种形式。</p><p><strong>确认后删除数据</strong>是指集群的每条消息只能被消费一次，只要数据被消费成功，就会回调服务端的 ACK 接口，服务端就会执行数据删除操作。这种方案不利于回溯，所以用的不多。</p><p><strong>消费成功保存消费进度</strong>是指当消费数据成功后，调用服务端的消费进度接口来保存消费进度。这种方式一般都是配合消费分组一起用的，服务端从消费分组维度来保存进度数据。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230722110620707.png" alt="image-20230722110620707"></p><p>为了保证消息的回溯和多次消费，一般都采用这种方案。<strong>数据的删除交由数据过期策略去执行。</strong></p><p>保存消费进度一般分为服务端保存和客户端自定义保存两种实现机制。</p><p><strong>服务端保存</strong>是指服务端提供一个接口用于保存数据，客户端调用即可。服务端一般会通过内置的 Topic 或者文件来持久保存该数据。</p><p>在提交位点信息的时候，底层一般支持自动提交和手动提交两种实现。</p><ul><li><strong>自动提交</strong>一般是根据时间批次或数据消费到客户端后就自动提交，提交过程客户无感知。</li><li><strong>手动提交</strong>是指业务根据自己的处理情况，手动提交进度信息，以避免业务处理异常导致的数据丢失。</li></ul><p>优缺点如下：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230722111121025.png" alt="image-20230722111121025" style="zoom:80%;" /><p><strong>客户端自定义保存</strong>是指当消费完成后，客户端自己管理保存消费进度。</p><h1 id="消费失败处理"><a href="#消费失败处理" class="headerlink" title="消费失败处理"></a>消费失败处理</h1><p>一个完整的消费流程包括消费数据、本地业务处理、消费进度提交三部分，那么从消费失败的角度来看，就应该分为从服务端拉取数据失败、本地业务数据处理失败、提交位点信息失败三种情况。</p><p><strong>从服务端拉取数据失败</strong>，和客户端的错误逻辑处理是一致的，根据可重试错误和不可重试错误的分类，进行重复消费或者向上抛错。</p><p><strong>本地业务数据处理失败</strong>，如果是偶尔失败，那么在业务层做好重试处理逻辑，配合手动提交消费进度的操作即可解决。如果是一直失败，即使重试多次也无法被解决，此时如果一直重试，就会出现消费卡住的情况，这就需要配合死信队列的功能，将无法被处理的数据投递到死信队列中，从而保存异常数据并保证消费进度不阻塞。</p><p><strong>提交位点信息失败</strong>，其处理方法通常是一直重试，重复提交，如果持续失败就向上抛错。因为如果提交进度失败，即使再从服务端拉取数据，还是会拉到同一批数据，出现重复消费的问题。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这里介绍上篇剩下的三部分，也就是消费分组（订阅）、消费确认、消费失败处理。&lt;/p&gt;
&lt;h1 id=&quot;消费分组&quot;&gt;&lt;a href=&quot;#消费分组&quot; class=&quot;headerlink&quot; title=&quot;消费分组&quot;&gt;&lt;/a&gt;消费分组&lt;/h1&gt;&lt;p&gt;消费分组是用来组织消费者、分区、消</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消费客户端的SDK（上）</title>
    <link href="http://example.com/2023/07/21/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E8%B4%B9%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84SDK%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <id>http://example.com/2023/07/21/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E8%B4%B9%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84SDK%EF%BC%88%E4%B8%8A%EF%BC%89/</id>
    <published>2023-07-21T02:46:22.000Z</published>
    <updated>2023-07-21T03:35:06.107Z</updated>
    
    <content type="html"><![CDATA[<p>从实现来看，消费相关功能包括<strong>消费模型</strong>、<strong>分区消费模式</strong>、<strong>消费分组（订阅）</strong>、<strong>消费确认</strong>、<strong>消费失败处理</strong>五个部分。</p><p>这里只涉及到前两个部分。</p><h1 id="消费模型的选择"><a href="#消费模型的选择" class="headerlink" title="消费模型的选择"></a>消费模型的选择</h1><p>为了满足不同场景的业务需求，从实现机制上来看，主流消息队列一般支持 Pull、Push、Pop 三种消费模型。</p><h2 id="Pull-模型"><a href="#Pull-模型" class="headerlink" title="Pull 模型"></a>Pull 模型</h2><p>Pull（拉）模型是指客户端通过不断轮询的方式向服务端拉取数据。它是消息队列中使用最广泛和最基本的模型，主流的消息队列都支持这个模型。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721105121747.png" alt="image-20230721105121747"></p><p>它的好处是客户端根据自身的处理速度去拉取数据，不会对客户端和服务端造成额外的风险和负载压力。缺点是可能会出现大量无效返回的 Pull 调用（服务端没有数据可以拉去时），另外消费及时性不够。</p><p>为了提高性能，Pull是可以指定一次拉去多少条数据，然后传递给服务端，即批量拉取。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721105516142.png" alt="image-20230721105516142" style="zoom:80%;" /><p>如上图，如果Topic1的数据已经被消费完，但是客户端还是不断的发请求拉数据，那么就会导致资源的浪费。</p><p>为了解决这个问题，一般服务端会协助处理，有如下两个思路：</p><h3 id="1-服务端-hold-住请求"><a href="#1-服务端-hold-住请求" class="headerlink" title="1. 服务端 hold 住请求"></a>1. 服务端 hold 住请求</h3><p>当客户端根据策略拉取数据时，如果没有足够的数据，就先在服务端等一段时间，等有数据后一起返回给客户端。</p><p>好处是可以尽可能提高吞吐率，而且不会有太多的空请求。</p><p>缺点是如果长时间没有消息，则会导致消费者请求超时，而且如果数据长时间不够，则会提高消费时延。</p><h3 id="2-服务端有数据的时候通知客户端"><a href="#2-服务端有数据的时候通知客户端" class="headerlink" title="2. 服务端有数据的时候通知客户端"></a>2. 服务端有数据的时候通知客户端</h3><p>当服务端不 hold 住请求，立刻返回空数据，客户端收到空数据时则不再发起请求，会等待服务端的通知。当服务端有数据的时候，再主动通知客户端来拉取。</p><p>这种方案的好处是可以及时通知客户端来拉取数据，从而降低消费延时。</p><p>缺点是因为客户端和服务端一般是半双工的通信，此时服务端是不能主动向客户端发送消息的。</p><p>所以在 Pull 模型中，比较合适的方案是客户端告诉服务端：<strong>最多需要多少数据、最少需要多少数据、未达到最小数据时可以等多久</strong>三个信息。然后服务端首先判断是否有足够的数据，有的话就立即返回，否则就根据客户端设置的等待时长 hold 住请求，如果超时，无论是否有数据，都会直接给客户端返回当前的结果。</p><h2 id="Push-模型"><a href="#Push-模型" class="headerlink" title="Push 模型"></a>Push 模型</h2><p>Push（推）模型是为了解决消费及时性而提出来的。这个模型的本意是指当服务端有数据时会主动推给客户端，让数据的消费更加及时。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721110037813.png" alt="image-20230721110037813" style="zoom:80%;" /><p>在实际的 Push 模型的实现上，一般有 Broker 内置 Push 功能、Broker 外独立实现 Push 功能的组件、在客户端实现伪 Push 功能三种思路。</p><p><strong>第一种，Broker内置Push功能是指在 Broker 中内置标准的 Push的能力，由服务端向客户端主动推送数据。</strong></p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721110202222.png" alt="image-20230721110202222" style="zoom:80%;" /><p>优点：Broker 自带 Push 能力，无需重复开发和部署。Broker 内部可以感知到数据堆积情况，可以保证消息被及时消费。</p><p>缺点：当消费者很多时，内核需要主动维护很多与第三方的长连接，并且需要处理各种客户端异常，推送数据，异常处理等比较耗费系统资源，可能会导致Broker不稳定。</p><p><strong>第二种，Broker 外独立实现 Push 功能的组件是指独立于 Broker 提供一个专门实现推模型的组件。</strong></p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721110409783.png" alt="image-20230721110409783" style="zoom:80%;" /><p>好处是将push组件独立了出来，可以保证Broker的稳定。</p><p>缺点是需要先pull拉去数据，然后再push，会存在较高的时延。</p><p><strong>第三种，在客户端实现伪 Push 功能是指在客户端内部维护内存队列，SDK 底层通过 Pull 模型从服务端拉取数据存储到客户端的内存队列中。</strong>然后通过回调的方式，触发用户设置的回调函数，将数据推送给应用程序，在使用体验上看就是 Push 的效果。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721110735383.png" alt="image-20230721110735383" style="zoom: 80%;" /><p>这种方案的好处在于通过客户端底层的封装，从用户体验看是 Push 模型的效果，解决用户代码层面的不断轮询问题。</p><p>缺点是底层依旧是 Pull 模型，还是得通过不断轮询的方式去服务端拉取数据，就会遇到 Pull 模型遇到的问题。</p><p>因为 Push 模型需要先分配分区和消费者的关系，客户端就需要感知分区分配、分区均衡等操作，从而在客户端就需要实现比较重的逻辑。并且当客户端和订阅的分区数较多时，容易出现需要很长的重平衡时间的情况。此时为了解决这个问题，业界提出了 Pop 模型。</p><h2 id="Pop-模型"><a href="#Pop-模型" class="headerlink" title="Pop 模型"></a>Pop 模型</h2><p>Pop 模型想解决的是客户端实现较重，重平衡会暂停消费并且可能时间较长，从而出现消费倾斜的问题。</p><p>它的思路是客户端不需要感知到分区，直接通过 Pop 模型提供的 get 接口去获取到数据，消费成功后 ACK 数据。就跟我们发起 HTTP 请求去服务端拉取数据一样，不感知服务端的数据分布情况，只需要拉到数据。</p><p>这种方案的好处是简化了消费模型，同时服务端可以感知到消费的堆积情况，可以根据堆积情况返回那些分区的数据给客户端，这样也简化了消息数据的分配策略。</p><p>从实现上来看，它将分区分配的工作移到了服务端，在服务端完成了消费者的分区分配、进度管理，然后暴露出了新的 Pop 和 ACK 接口。客户端调用 Pop 接口去拿取数据，消费成功后调用 ACK 去确认数据。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721112049239.png" alt="image-20230721112049239" style="zoom:80%;" /><h1 id="分区消费模式的设计"><a href="#分区消费模式的设计" class="headerlink" title="分区消费模式的设计"></a>分区消费模式的设计</h1><p>消息队列的数据是在 Partition&#x2F;Queue 维度承载的。所以消费过程中一个重要的工作就是消费者和分区的消费模式问题，即分区的数据能不能被多个消费者并发消费，一条数据能不能被所有消费者消费到，分区的数据能不能被顺序消费等等。</p><p>从技术上看，在数据的消费模式上主要有<strong>独占消费</strong>、<strong>共享消费</strong>、<strong>广播消费</strong>、<strong>灾备消费</strong>四个思路。</p><h2 id="独占消费"><a href="#独占消费" class="headerlink" title="独占消费"></a>独占消费</h2><p><strong>独占消费是指一个分区在同一个时间只能被一个消费者消费。</strong>在消费者启动时，会分配消费者和分区之间的消费关系。当消费者数量和分区数量都没有变化的情况下，两者之间的分配关系不会变动。</p><p>如果消费者数量大于分区数量，则会有消费者被空置；</p><p>反之，如果分区数量大于消费者数量，一个消费者则可以同时消费多个分区。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721112545785.png" alt="image-20230721112545785" style="zoom:80%;" /><p>独占消费的好处是可以保证分区维度的消费是有序的。缺点是当数据出现倾斜、单个消费者出现性能问题或 hang 住时，会导致有些分区堆积严重。</p><h2 id="共享消费"><a href="#共享消费" class="headerlink" title="共享消费"></a>共享消费</h2><p><strong>共享消费是指单个分区的数据可以同时被多个消费者消费。</strong>即分区的数据会依次投递给不同的消费者，一条数据只会投递给一个消费者。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721112658334.png" alt="image-20230721112658334" style="zoom:80%;" /><p>这种方式的好处是，可以避免单个消费者的性能和稳定性问题导致分区的数据堆积。缺点是无法保证数据的顺序消费。这种模式一般用在对数据的有序性无要求的场景，比如日志。</p><h2 id="广播消费"><a href="#广播消费" class="headerlink" title="广播消费"></a>广播消费</h2><p><strong>广播消费是指一条数据要能够被多个消费者消费到。</strong>即分区中的一条数据可以投递给所有的消费者，这种方式是需要广播消费的场景。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721112908668.png" alt="image-20230721112908668"></p><p>实现广播消费一般有内核实现广播消费的模型、使用不同的消费分组消费和指定分区消费三种技术思路。</p><ol><li>内核实现广播消费的模型，指在 Broker 内核中的消息投递流程实现广播消费模式，即 Broker 投递消息时，可以将一条消息吐给不同的消费者，从而实现广播消费。</li><li>使用不同的消费分组对数据进行消费，指通过创建不同的消费者组消费同一个 Topic 或分区，不同的消费分组管理自己的消费进度，消费到同一条消息，从而实现广播消费的效果。</li><li>指定分区消费，是指每个消费者指定分区进行消费，在本地记录消费位点，从而实现不同消费者消费同一条数据，达到广播消费的效果。</li></ol><p>优缺点如下：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230721113216520.png" alt="image-20230721113216520"></p><h2 id="灾备消费"><a href="#灾备消费" class="headerlink" title="灾备消费"></a>灾备消费</h2><p><strong>灾备消费是独占消费的升级版，在保持独占消费可以支持顺序消费的基础上，同时加入灾备的消费者****。</strong>当消费者出现问题的时候，灾备消费者加入工作，继续保持独占顺序消费。</p><p>好处是既能保持独占顺序消费，又能保证容灾能力。缺点是无法解决消费倾斜的性能问题，另外还需要准备一个消费者来做灾备，使用成本较高。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从实现来看，消费相关功能包括&lt;strong&gt;消费模型&lt;/strong&gt;、&lt;strong&gt;分区消费模式&lt;/strong&gt;、&lt;strong&gt;消费分组（订阅）&lt;/strong&gt;、&lt;strong&gt;消费确认&lt;/strong&gt;、&lt;strong&gt;消费失败处理&lt;/strong&gt;五个部分。&lt;</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>生产者的SDK需要哪些设计</title>
    <link href="http://example.com/2023/07/20/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84SDK%E9%9C%80%E8%A6%81%E5%93%AA%E4%BA%9B%E8%AE%BE%E8%AE%A1/"/>
    <id>http://example.com/2023/07/20/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84SDK%E9%9C%80%E8%A6%81%E5%93%AA%E4%BA%9B%E8%AE%BE%E8%AE%A1/</id>
    <published>2023-07-20T06:44:31.000Z</published>
    <updated>2023-07-21T02:46:59.418Z</updated>
    
    <content type="html"><![CDATA[<p>生产模块包含<strong>客户端基础功能和生产相关功能</strong>两部分，如下图：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230720144646902.png" alt="image-20230720144646902"></p><p>基础功能是蓝色部分，生产功能是黄色部分。</p><h1 id="客户端基础功能"><a href="#客户端基础功能" class="headerlink" title="客户端基础功能"></a>客户端基础功能</h1><h2 id="连接管理"><a href="#连接管理" class="headerlink" title="连接管理"></a>连接管理</h2><p>客户端和服务端之间基本都是创建 TCP 长连接进行通信的，为了避免连接数膨胀，每个客户端实例和每台 Broker 只会维护一条 TCP 连接。</p><p>分为两种：</p><ul><li><strong>初始化创建连接</strong>，指在实例初始化时就创建到各个 Broker 的 TCP 连接，等待数据发送。这种可能会导致连接空跑，会消耗一定的资源。</li><li><strong>使用时创建链接</strong>，指在实例初始化时不建立连接，当需要发送数据时再建立。可能出现连接冷启动，会增加一点本次请求的耗时。</li></ul><h2 id="心跳检测"><a href="#心跳检测" class="headerlink" title="心跳检测"></a>心跳检测</h2><p>消息队列一般都是基于 TCP 协议通信的，所以客户端和服务端之间的心跳检测机制的实现，一般有基于 TCP 的 KeepAlive 保活机制和应用层主动探测两种形式。</p><p><strong>基于 TCP 的 KeepAlive 保活机制</strong>是 TCP&#x2F;IP 协议层内置的功能，需要手动打开，优点是简单，缺点是需要Server主动发出检测包，当客户端出现故障而Server没有发包时，可能会出现不可用的TCP连接占用服务器资源。</p><p><strong>应用层主动探测</strong>一般是 Client 向 Server 发起的，探测流程一般是客户端定时发送保活心跳，当服务端连续几次没收到请求，就断开连接。可以降低服务端压力。</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>从请求的角度，有些错误是重试可以恢复的，比如连接断开、Leader 切换、发送偶尔超时、服务端某些异常等；有些错误是不可恢复的，比如 Topic&#x2F; 分区不存在、服务端 Broker 不存在、集群和 Broker 长时间无响应等。</p><p>所以，在客户端的处理中也会将错误分为可重试错误和不可重试错误两类。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230720145133022.png" alt="image-20230720145133022"></p><p>可重试指的是那些因为网络波动，Leader切换等异常，重试之后有可能解决的错误，不可重试的错误就是不管如何重试都无法恢复的异常。</p><h2 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h2><p>重试策略一般会支持重试次数和退避时间的概念。当消息失败，超过设置的退避时间后，会继续重试，当超过重试次数后，就会抛弃消息或者将消息投递到配置好的重试队列中。</p><p>退避策略影响的是重试的成功率，因为网络抖动正常是 ms 级，某些异常可能会抖动十几秒。此时，如果退避策略设置得太短，在退避策略和重试次数用完后，可能消息还没生产成功；如果退避时间设置太长，可能导致客户端发送堵塞消息堆积。</p><h1 id="生产相关功能"><a href="#生产相关功能" class="headerlink" title="生产相关功能"></a>生产相关功能</h1><h2 id="客户端寻址机制"><a href="#客户端寻址机制" class="headerlink" title="客户端寻址机制"></a>客户端寻址机制</h2><p>消息队列作为一个分布式系统，分区会分布在集群的不同节点上。那么客户端给服务端发送数据时，要发给哪台节点呢？</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230720145523867.png" alt="image-20230720145523867" style="zoom:80%;" /><p>一种思路是：手动指定目标 Broker 的 IP，就是说在生产者写数据到 Broker 的时候，在代码里面手动指定分区对应的对端的 Broker 地址，然后将数据写到目标 Broker。</p><p>为了解决查找分区在Broker上的对应关系，业界提出了 Metadata（元数据）寻址机制和服务端内部转发两个思路。</p><h3 id="1-Metadata（元数据）寻址机制"><a href="#1-Metadata（元数据）寻址机制" class="headerlink" title="1. Metadata（元数据）寻址机制"></a>1. Metadata（元数据）寻址机制</h3><p>服务端会提供一个获取全量的 Metadata 的接口，客户端在启动时，首先通过接口拿到集群所有的元数据信息，本地缓存这部分数据信息。然后，客户端发送数据的时候，会根据元数据信息的内容，得到服务端的地址是什么，要发送的分区在哪台节点上。最后根据这两部分信息，将数据发送到服务端。</p><p>简而言之，通过接口查到对应的数据，下次请求时带上就可以了。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230720150122612.png" alt="image-20230720150122612"></p><p>消息队列的元数据是指 Topic、分区、Group、节点、配置等集群维度的信息。比如 Topic 有几个分区，分区的 Leader 和 Follower 在哪些节点上，节点的 IP 和端口是什么，有哪些 Group 等等。</p><h3 id="2-服务端内部转发机制"><a href="#2-服务端内部转发机制" class="headerlink" title="2. 服务端内部转发机制"></a>2. 服务端内部转发机制</h3><p>另外一种服务端内部转发机制，客户端不需要经过寻址的过程，写入的时候是随机把数据写入到服务端任意一台 Broker。</p><p>具体思路是服务端的每一台 Broker 会缓存所有节点的元数据信息，生产者将数据发送给 Broker 后，Broker 如果判断分区不在当前节点上，会找到这个分区在哪个节点上，然后把数据转发到目标节点。</p><p>简单来说就是随便发到任意一个Broker中，然后他们之间有类似路由信息，Broker之间再进行转发。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230720150320170.png" alt="image-20230720150320170"></p><h2 id="生产分区分配策略"><a href="#生产分区分配策略" class="headerlink" title="生产分区分配策略"></a>生产分区分配策略</h2><p>数据可以直接写入分区或者写入 Topic。写入 Topic 时，最终数据还是要写入到某个分区。这个数据选择写入到哪个分区的过程，就是生产数据的分区分配过程。过程中的分配策略就是生产分区分配策略。</p><p>一般情况下，消息队列默认支持轮询、按 Key Hash、手动指定、自定义分区分配策略四种分区分配策略。</p><h3 id="轮询"><a href="#轮询" class="headerlink" title="轮询"></a>轮询</h3><p><strong>轮询</strong>是所有消息队列的默认选项。消息通过轮询的方式依次写入到各个分区中，这样可以保证每个分区的数据量是一样的，不会出现分区数据倾斜。</p><p>但是如果我们需要保证数据的写入是有序的，轮询就满足不了。因为在消费模型中，每个分区的消费是独立的，如果数据顺序依次写入多个分区，在消费的时候就无法保持顺序。所以为了保证数据有序，就需要保证 Topic 只有一个分区。这是另外两种分配策略的思路。</p><h3 id="按-Key-Hash"><a href="#按-Key-Hash" class="headerlink" title="按 Key Hash"></a>按 Key Hash</h3><p><strong>按 Key Hash</strong> 是指根据消息的 Key 算出一个 Hash 值，然后跟 Topic 的分区数取余数，算出一个分区号，将数据写入到这个分区中。</p><p>这种方案的好处是可以根据 Key 来保证数据的分区有序。比如某个用户的访问轨迹，以客户的 AppID 为 Key，按 Key Hash 存储，就可以确保客户维度的数据分区有序。（因为key是一样的，所以该用户的所有消息会被分到一个分区当中）</p><p>缺点是分区数量不能变化，变化后 Hash 值就会变，导致消息乱序。并且因为每个 Key 的数据量不一样，容易导致数据倾斜。</p><h3 id="手动指定"><a href="#手动指定" class="headerlink" title="手动指定"></a>手动指定</h3><p>在生产数据的时候，手动指定数据写入哪个分区。</p><h3 id="自定义分区分配策略"><a href="#自定义分区分配策略" class="headerlink" title="自定义分区分配策略"></a>自定义分区分配策略</h3><p>用户实现消息队列提供的接口，自定义分区策略。</p><h2 id="批量语义"><a href="#批量语义" class="headerlink" title="批量语义"></a>批量语义</h2><p>客户端支持批量写入数据的前提是，需要在协议层支持批量的语义。否则就只能在业务中自定义将多条消息组成一条消息。</p><p>批量发送的实现思路一般是在客户端内存中维护一个队列，数据写入的时候，先将其写到这个内存队列，然后通过某个策略从内存队列读取数据，发送到服务端。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230720150820416.png" alt="image-20230720150820416"></p><h2 id="数据发送方式"><a href="#数据发送方式" class="headerlink" title="数据发送方式"></a>数据发送方式</h2><p>消息队列一般也会提供同步发送、异步发送、发送即忘三种形式。</p><p>同步异步好理解，不再过多阐述。</p><p>发送即忘指消息发送后不关心请求返回的结果，立即发送下一条。这种方式因为不用关心发送结果，发送性能会提升很多。缺点是当数据发送失败时无法感知，可能有数据丢失的情况。</p><h1 id="集群管控操作"><a href="#集群管控操作" class="headerlink" title="集群管控操作"></a>集群管控操作</h1><p>集群管控操作一般是用来完成资源的创建、查询、修改、删除等集群管理动作。资源包括主题、分区、配置、消费分组等等。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;生产模块包含&lt;strong&gt;客户端基础功能和生产相关功能&lt;/strong&gt;两部分，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-2023072014464</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消息队列如何保证存储的高性能</title>
    <link href="http://example.com/2023/07/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%AD%98%E5%82%A8%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD/"/>
    <id>http://example.com/2023/07/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%AD%98%E5%82%A8%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD/</id>
    <published>2023-07-19T02:39:03.000Z</published>
    <updated>2023-07-19T03:31:38.079Z</updated>
    
    <content type="html"><![CDATA[<p>存储模块的优化主要是基于以下四点：</p><ul><li>内存读写的效率高于硬盘读写</li><li>批量读写的效率高于单条读写</li><li>顺序读写的效率高于随机读写</li><li>数据复制次数越多，效率越低</li></ul><h1 id="提升写入操作的性能"><a href="#提升写入操作的性能" class="headerlink" title="提升写入操作的性能"></a>提升写入操作的性能</h1><p>数据需要先写入内存，然后才会落盘，所以写入操作的性能优化就要从内存和磁盘入手。写入性能的提高主要有缓存写、批量写、顺序写三个思路。</p><h2 id="1-缓存写和批量写"><a href="#1-缓存写和批量写" class="headerlink" title="1. 缓存写和批量写"></a>1. 缓存写和批量写</h2><p>物理硬件的写入速度如下图：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719104418089.png" alt="image-20230719104418089"></p><p>所以，写入优化的主要思路之一是：<strong>将数据写入到速度更快的内存中，等积攒了一批数据，再批量刷到硬盘中。</strong></p><p>平时可以看到的一种说法，数据先写入 PageCache，再批量刷到硬盘，就是这种思路。PageCache 指操作系统的页缓存，简单理解就是内存，通过缓存读写数据可以避免直接对硬盘进行操作，从而提高性能。</p><p>把缓存数据刷回到硬盘，一般有“按照空间占用比例”、“时间周期扫描”和“手动强制刷新”三种策略。操作系统内核提供了前两种处理策略，不需要应用程序感知。</p><p><strong>按空间占用比例刷新</strong>是指当系统内存中的“脏”数据大于某个阈值时会将数据刷新到硬盘。操作系统提供了两个配置项：</p><ul><li><p>“脏”数据在内存中的占比（dirty_background_ratio）</p></li><li><p>“脏”数据的绝对的字节数（dirty_background_bytes）</p></li></ul><p><strong>按时间周期刷新</strong>是指根据配置好的时间，周期性刷新数据到硬盘。主要通过脏页存活时间（dirty_expire_seconds) 和刷新周期（dirty_writeback_centisecs）两个参数来配置。</p><p>两个配置默认都是 1&#x2F;100，也就说时间间隔为每秒 100 次，根据刷新周期的配置周期性执行刷新，刷新会检查脏页的存活时间是否超过配置的最大存活时间，如果是则刷入硬盘。</p><p>同时，操作系统也提供了第三种方法<strong>程序手动强制刷新</strong>，你可以通过系统提供的 sync()&#x2F;msync()&#x2F;fsync() 调用来强制刷新缓存。</p><p>消息队列一般会同时提供：是否同步刷盘、刷盘的时间周期、刷盘的空间比例三个配置项，让业务根据需要调整自己的刷新策略。从性能的角度看，异步刷新肯定是性能最高的，同步刷新是可靠性最高的。</p><h2 id="2-随机写和顺序写"><a href="#2-随机写和顺序写" class="headerlink" title="2. 随机写和顺序写"></a>2. 随机写和顺序写</h2><p>首先，随机写和顺序写都是针对硬盘的，是整个操作系统和硬盘的关系，而不是单文件和硬盘的关系。搞清楚这一点，就需要考虑<strong>单文件顺序写入硬盘</strong>和<strong>多文件顺序写入硬盘</strong>，从硬盘角度看，他们都是顺序的吗？</p><p>单文件顺序写入硬盘很简单，硬盘控制器只需在连续的存储区域写入数据，对硬盘来讲，数据就是顺序写入的。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719105647355.png" alt="image-20230719105647355" style="zoom: 80%;" /><p>多文件顺序写入硬盘，系统中有很多文件同时写入，这个时候从硬盘的视角看，你会发现操作系统同时对多个不同的存储区域进行操作，硬盘控制器需要同时控制多个数据的写入，所以从硬盘的角度是随机写的。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719105709022.png" alt="image-20230719105709022"></p><p>所以，在消息队列中，实现随机写和顺序写的核心就是<strong>数据存储结构的设计</strong>。</p><p>在上一篇博客中写过，数据存储结构设计有两个思路：每个 Partition&#x2F;Queue 单独一个存储文件，每台节点上所有 Partition&#x2F;Queue 的数据都存储在同一个文件。</p><p>第一种方案，对单个文件来说读和写都是顺序的，性能最高，但当文件很多且都有读写，在硬盘层面就会退化为随机读写，性能会下降很多。</p><p>第二种方案，因为只有一个文件，不存在文件过多的情况，写入层面一直都会是顺序的，性能一直很高。所以为了提高写的性能，可以采用第二种方案。</p><h1 id="提升写入操作的可靠性"><a href="#提升写入操作的可靠性" class="headerlink" title="提升写入操作的可靠性"></a>提升写入操作的可靠性</h1><p>因为数据是先写入内存，然后刷到磁盘，那么没刷之前就有丢失的风险。</p><p>为了提高数据可靠性，在消息队列的存储模块中，一般会通过三种处理手段：同步刷盘、WAL 预写日志、多副本备份，进一步提升数据的可靠性。</p><h2 id="1-同步刷盘"><a href="#1-同步刷盘" class="headerlink" title="1. 同步刷盘"></a>1. 同步刷盘</h2><p>同步刷盘指每条数据都同步刷盘，等于回到了直接写硬盘的逻辑，一般通过写入数据后调用 force() 操作来完成数据刷盘。这种办法相当于省略了内存那一步，直接写入磁盘，效率比较低。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719110348072.png" alt="image-20230719110348072" style="zoom: 80%;" /><h2 id="2-WAL"><a href="#2-WAL" class="headerlink" title="2. WAL"></a>2. WAL</h2><p>WAL（预写日志）指在写数据之前先写日志，当出现数据丢失时通过日志来恢复数据，避免数据丢失。但是WAL 日志需要写入持久存储，业务数据也要写入缓存，多了一步，性能会不会降低呢？</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719110506254.png" alt="image-20230719110506254" style="zoom:80%;" /><p>从理论来看，WAL 机制肯定会比直接写入缓存中的性能低。但我们实际落地的时候往往可以通过一些手段来优化，降低影响，达到性能要求。</p><p>在消息队列中，消息的量很大，我们不可能采用性能很高的存储设备，但是日志的量比较小，而且可顺序存储。所以<strong>在实际落地中，我们可以采取 WAL 日志盘和实际数据盘分离的策略，提升 WAL 日志的写入速度</strong>。</p><p>具体就是让 WAL 数据盘是高性能、低容量的数据盘，存储消息的数据盘是性能较低、容量较大的数据盘，如果出现数据异常，就通过 WAL 日志进行数据恢复。</p><h2 id="3-多副本的备份"><a href="#3-多副本的备份" class="headerlink" title="3. 多副本的备份"></a>3. 多副本的备份</h2><p>多副本的备份就是将数据拷贝到多台节点，每台节点都写入到内存中，从而完成数据的可靠性存储。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719111128096.png" alt="image-20230719111128096" style="zoom:80%;" /><p>好处是可以在分布式存储的基础上做优化，通过多台缓存的手段来降低数据丢失的概率。但是如果所有节点在同一时刻重启，数据还是有可能丢失的，无法保证百分百的数据高可靠。</p><p>从消息队列业界的存储方案来看，方案一所有产品都会支持，方案二和方案三一般会选一种支持，Kakfa、RabbitMQ、RocketMQ 用的是第三种，Pulsar 用的是第二种。</p><h1 id="提升读取操作的性能"><a href="#提升读取操作的性能" class="headerlink" title="提升读取操作的性能"></a>提升读取操作的性能</h1><p>提高读取的性能主要有读热数据、顺序读、批量读、零拷贝四个思路。</p><h2 id="1-冷读和热读"><a href="#1-冷读和热读" class="headerlink" title="1. 冷读和热读"></a>1. 冷读和热读</h2><p>热读是指消息数据本身还在缓存中，读取数据是从内存中获取，此时性能最高，不需要经过硬盘。冷读是指消息数据刷到硬盘中了，并且数据已经被换页换出缓存了，此时读取数据需要从硬盘读取。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719111256980.png" alt="image-20230719111256980" style="zoom: 80%;" /><p>理想情况，肯定全部是热读最好，因为性能最高。但是在代码层面，我们是无法控制冷读或热读的，只能通过配置更大的内存，尽量保证缓存中保留更多的数据，从而提高热读的概率。</p><h2 id="2-顺序读、随机读、批量读"><a href="#2-顺序读、随机读、批量读" class="headerlink" title="2. 顺序读、随机读、批量读"></a>2. 顺序读、随机读、批量读</h2><p>为了实现大吞吐，在消费的时候服务端都会支持批量读的能力。为了能尽快返回数据给客户端，服务端都会实现数据的预读机制。在读取数据的时候，也读取客户下一步可能会用的数据，预先加载到内存中，以便更快返回数据。</p><p>数据的预读分为两种：硬盘层面预读、应用程序的预读。</p><p>硬盘层面的预读，是在连续的地址空间中读取数据。<strong>但具体实现，我们在程序中无法控制，这和数据目录存储结构设计有关。</strong></p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719111635117.png" alt="image-20230719111635117"></p><p>上图是两种数据存储结构的设计，第一种由于每个分区一个文件，读取一个分区时数据都是连续的，预读很方便，只要在硬盘上读取连续的数据块即可。而第二种设计方案，需要根据分区的索引，在具体存储文件的不同位置进行读取，预读有很大的随机成分，效率不如第一种。</p><h2 id="3-零拷贝原理和使用方式"><a href="#3-零拷贝原理和使用方式" class="headerlink" title="3. 零拷贝原理和使用方式"></a>3. 零拷贝原理和使用方式</h2><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719111938059.png" alt="image-20230719111938059" style="zoom:67%;" /><p>如上图所示，在正常读取数据的过程中，数据要经过五步，硬盘 -&gt; ReadBuffer -&gt; 应用程序 -&gt; SocketBuffer -&gt; 网卡设备，四次复制。因为数据在复制过程耗费资源和时间，会降低性能，所以优化流程最重要的是减少数据复制的次数和资源损耗。</p><p>零拷贝指的是数据在<strong>内核空间</strong>和<strong>用户空间</strong>之间的拷贝次数，即图中的第 2 步和第 3 步。</p><p>如果只有 1 和 4 两步，没有执行 2 和 3 的话，那么内核空间和用户空间之间的拷贝次数就是零，“零拷贝”的零指的是这个次数“零”，因此是零拷贝。</p><p><strong>主要思路是通过减少数据复制次数、减少上下文（内核态和用户态）切换次数、通过 DMA（直接内存）代替 CPU 完成数据读写，来解决复制和资源损耗的问题。</strong></p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719112126032.png" alt="image-20230719112126032" style="zoom:80%;" /><p>红色的线即为零拷贝优化后的结果。</p><p>优化后，数据链路赋值变为了硬盘 -&gt; ReadBuffer -&gt; 网卡设备，从4次变为了2次，而且减少用户态和核心态的切换，并且使用DMA来搬运数据，释放了CPU。</p><p>零拷贝主要用于在消费的时候提升性能，具体有两种实现方式：<strong>mmap+write 和 sendfile</strong>。</p><p>mmap 是一种内存映射文件的方法，把文件或者其他对象映射到进程的地址空间，修改内存文件也会同步修改，这样就减少了一次数据拷贝。所以，我们不需要把数据拷贝到用户空间，修改后再回写到内核空间。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719112520577.png" alt="image-20230719112520577" style="zoom:80%;" /><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 正常的“读取数据并发送”流程是通过 read + write 完成的</span><br><span class="line">read(file, tmp_buf, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br><span class="line"></span><br><span class="line"># 而操作系统层面的 read()，系统在调用的过程中，会把内核缓冲区的数据拷贝到用户的缓冲区里，为了减少这一步开销，我们可以用 mmap() # 替换 read() 系统调用函数。</span><br><span class="line">buf = mmap(file, len);</span><br><span class="line">write(sockfd, buf, len);</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用 Java NIO 包的 FileChannel 的 map 方法</span></span><br><span class="line"><span class="type">FileChannel</span> <span class="variable">fc</span> <span class="operator">=</span> f.getChannel();</span><br><span class="line"><span class="type">MappedByteBuffer</span> <span class="variable">buf</span> <span class="operator">=</span> fc.map(FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, <span class="number">200</span>)</span><br></pre></td></tr></table></figure><p>在 Java 中也可以使用零拷贝技术，主要是在 NIO FileChannel 类中。</p><ul><li><p>transferTo() 方法：可以将数据从 FileChannel 直接传输到另外一个 Channel。</p></li><li><p>transferFrom() 方法：可以将数据从 Channel 传输到 FileChannel。</p></li></ul><h1 id="通过硬件和系统优化提升性能"><a href="#通过硬件和系统优化提升性能" class="headerlink" title="通过硬件和系统优化提升性能"></a>通过硬件和系统优化提升性能</h1><p>从硬件和系统优化提升性能的角度，主要可以通过提升硬件配置（如内存或硬盘）、配置多盘读写、配置硬盘阵列三个手段来提高集群的性能。</p><h2 id="1-提升硬件配置"><a href="#1-提升硬件配置" class="headerlink" title="1. 提升硬件配置"></a>1. 提升硬件配置</h2><h2 id="2-配置多盘读写"><a href="#2-配置多盘读写" class="headerlink" title="2. 配置多盘读写"></a>2. 配置多盘读写</h2><p>这种方案要内核支持这个机制，在部署的时候进行相关配置才能生效。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719112927310.png" alt="image-20230719112927310" style="zoom:80%;" /><p>一般实现思路是在消息队列的内核支持多目录读写的能力，将不同的文件或者不同的数据段调度存放在不同硬盘设备对应的挂载目录中。此时在数据的写入和读取的过程中，就可以同时利用到多块盘的吞吐和存储。</p><h2 id="3-配置-RAID-和-LVM-硬盘阵列"><a href="#3-配置-RAID-和-LVM-硬盘阵列" class="headerlink" title="3. 配置 RAID 和 LVM 硬盘阵列"></a>3. 配置 RAID 和 LVM 硬盘阵列</h2><p>多目录读写的问题是多块盘之间无法共享 IO 能力和存储空间，当遇到数据倾斜时，在单机层面会出现性能和容量瓶颈。Linux 提供了 RAID 硬盘阵列和 LVM 逻辑卷管理两种方式，通过串联多块盘的读写能力和容量，提升硬盘的性能和吞吐能力。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230719113032364.png" alt="image-20230719113032364" style="zoom:80%;" /><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;存储模块的优化主要是基于以下四点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内存读写的效率高于硬盘读写&lt;/li&gt;
&lt;li&gt;批量读写的效率高于单条读写&lt;/li&gt;
&lt;li&gt;顺序读写的效率高于随机读写&lt;/li&gt;
&lt;li&gt;数据复制次数越多，效率越低&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;提升写入</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消息队列存储之功能实现</title>
    <link href="http://example.com/2023/07/18/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%AD%98%E5%82%A8%E4%B9%8B%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0/"/>
    <id>http://example.com/2023/07/18/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%AD%98%E5%82%A8%E4%B9%8B%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0/</id>
    <published>2023-07-18T02:54:50.000Z</published>
    <updated>2023-08-06T03:02:59.678Z</updated>
    
    <content type="html"><![CDATA[<p>存储模块的主流程是数据的写入、存储、读取、过期，因为消息队列本质是做一个缓冲，它的持久化在一定时间或者数据被消费后需要删除。</p><p>消息队列中的数据一般分为<strong>元数据和消息数据</strong>。元数据是指 Topic、Group、User、ACL、Config 等集群维度的资源数据信息，消息数据指客户端写入的用户的业务数据。</p><h1 id="元数据信息的存储"><a href="#元数据信息的存储" class="headerlink" title="元数据信息的存储"></a>元数据信息的存储</h1><p>元数据信息的特点是数据量比较小，不会经常读写，但是需要保证数据的强一致和高可靠，不允许出现数据的丢失。同时，元数据信息一般需要通知到所有的 Broker 节点，Broker 会根据元数据信息执行具体的逻辑。比如创建 Topic 并生成元数据后，就需要通知对应的 Broker 执行创建分区、创建目录等操作。</p><p>所以元数据信息的存储，一般有两个思路：</p><ul><li><p>基于第三方组件来实现元数据的存储。</p></li><li><p>在集群内部实现元数据的存储。</p></li></ul><p><strong>基于第三方组件来实现元数据的存储是目前业界的主流选择。</strong>比如 Kakfa 和 Pulsar 的元数据存储在 ZooKeeper 中，RocketMQ 存储在 NameServer 中。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718110010031.png" alt="image-20230718110010031"></p><p>优点是集成方便，而且第三方软件已经保证了一致性，高性能等需求，可以降低开发成本。</p><p>但也有缺点。引入第三方组件会增加系统部署和运维的复杂度，而且第三方组件自身的稳定性问题会增加系统风险，第三方组件和多台 Broker 之间可能会出现数据信息不一致的情况，导致读写异常。</p><h1 id="消息数据的存储"><a href="#消息数据的存储" class="headerlink" title="消息数据的存储"></a>消息数据的存储</h1><p>消息队列的存储主要是指消息数据的存储，分为存储结构、数据分段、数据存储格式、数据清理四个部分。</p><h2 id="数据存储结构设计"><a href="#数据存储结构设计" class="headerlink" title="数据存储结构设计"></a>数据存储结构设计</h2><p>在消息队列中，跟存储有关的主要是 Topic 和分区两个维度。用户可以将数据写入 Topic 或直接写入到分区。</p><p>如果写入 Topic，数据也是分发到多个分区去存储的。所以从实际数据存储的角度来看，<strong>Topic 和 Group 不承担数据存储功能，承担的是逻辑组织的功能，实际的数据存储是在在分区维度完成的</strong>。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718110640501.png" alt="image-20230718110640501"></p><p>而数据的罗盘也有两种思路：</p><ol><li>每个分区单独一个存储“文件”。</li><li>每个节点上所有分区的数据都存储在同一个“文件”。</li></ol><p>这里的“文件”是一个虚指，即表示所有分区的数据是存储在一起，还是每个分区的数据分开存储的意思。</p><h3 id="第一种思路"><a href="#第一种思路" class="headerlink" title="第一种思路"></a>第一种思路</h3><p>每个分区的数据对应一个文件去存储，在实现上每个分区的数据是顺序写入到同一个磁盘文件中，数据是连续的，所以读写性能上效率最高。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718112210221.png" alt="image-20230718112210221"></p><p>但如果分区太多，会占用太多的系统 FD 资源，极端情况下有可能把节点的 FD 资源耗完，并且硬盘层面会出现大量的随机写情况，导致写入的性能下降很多，另外管理起来也相对复杂。（fd是是<strong>内核为了高效管理这些已经被打开的文件所创建的一种索引</strong>，如果太多分区，相当于很多个文件在同时读写，虽然每个分区内文件是顺序读写的，但是分区之间并不是顺序，而是随机的，所以会导致磁盘层面大量的随机读写）</p><p>具体的磁盘组织结构：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718111845083.png" alt="image-20230718111845083"></p><h3 id="第二种思路"><a href="#第二种思路" class="headerlink" title="第二种思路"></a>第二种思路</h3><p>每个节点上所有分区的数据都存储在同一个文件中，这种方案需要为每个分区维护一个对应的索引文件，索引文件里会记录每条消息在 File 里面的位置信息，以便快速定位到具体的消息内容。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718112137877.png" alt="image-20230718112137877"></p><p>因为<strong>所有文件都在一份文件上，管理简单，也不会占用过多的系统 FD 资源，单机上的数据写入都是顺序的，写入的性能会很高</strong>。</p><p>缺点是同一个分区的数据一般会在文件中的不同位置，或者不同的文件段中，无法利用到顺序读的优势，读取的性能会受到影响。</p><h2 id="消息数据的分段实现"><a href="#消息数据的分段实现" class="headerlink" title="消息数据的分段实现"></a>消息数据的分段实现</h2><p>数据分段的规则一般是根据大小来进行的，比如默认 1G 一个文件，同时会支持配置项调整分段数据的大小。从技术上来看，当数据段到达了规定的大小后，就会新创建一个新文件来保存数据。</p><p>如果进行了分段，消息数据可能分布在不同的文件中。所以我们在读取数据的时候，需要先定位消息数据在哪个文件中。为了满足这个需求，技术上一般有根据<strong>偏移量定位</strong>或根据<strong>索引定位</strong>两种思路。</p><h3 id="偏移量"><a href="#偏移量" class="headerlink" title="偏移量"></a>偏移量</h3><p>根据偏移量（Offset）来定位消息在哪个分段文件中，是指通过记录每个数据段文件的起始偏移量、中止偏移量、消息的偏移量信息，来快速定位消息在哪个文件。</p><p>当消息数据存储时，通常会用一个自增的数值型数据（比如 Long）来表示这条数据在分区或 commitlog 中的位置，这个值就是消息的偏移量。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718112847872.png" alt="image-20230718112847872" style="zoom:80%;" /><p>在实际的编码过程中，记录文件的起始偏移量一般有两种思路：单独记录每个数据段的起始和结束偏移量，在文件名称中携带起始偏移量信息。因为数据是顺序存储的，每个文件记录了本文件的起始偏移量，那么下一个文件的起始偏移量就是上一个文件的结束偏移量。</p><h3 id="索引定位"><a href="#索引定位" class="headerlink" title="索引定位"></a>索引定位</h3><p>如果用索引定位，会直接存储消息对应的文件信息，而不是通过偏移量来定位到具体文件。</p><p>具体是通过维护一个单独的索引文件，记录消息在哪个文件和文件的哪个位置。读取消息的时候，先根据消息 ID 找到存储的信息，然后找到对应的文件和位置，读取数据。</p><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><p><strong>这两种方案所面临的场景不一样。</strong></p><p>根据偏移量定位数据，通常用在每个分区各自存储一份文件的场景；根据索引定位数据，通常用在所有分区的数据存储在同一份文件的场景。</p><p>因为在前一种场景，每一份数据都属于同一个分区，那么通过位点来二分查找数据的效率是最高的。</p><p>第二种场景，这一份数据属于多个不同分区，则通过二分查找来查找数据效率很低，用哈希查找效率是最高的。</p><h2 id="消息数据存储格式"><a href="#消息数据存储格式" class="headerlink" title="消息数据存储格式"></a>消息数据存储格式</h2><p>消息数据存储格式一般包含消息写入文件的格式和消息内容的格式两个方面。</p><p><strong>消息写入文件的格式指消息是以什么格式写入到文件中的</strong>，比如 JSON 字符串或二进制。从性能和空间冗余的角度来看，消息队列中的数据基本都是以二进制的格式写入到文件的。</p><p><strong>消息内容的格式是指写入到文件中的数据都包含哪些信息。</strong>对于一个成熟的消息队列来说，消息内容格式不仅关系功能维度的扩展，还牵涉性能维度的优化。</p><h2 id="消息数据清理机制"><a href="#消息数据清理机制" class="headerlink" title="消息数据清理机制"></a>消息数据清理机制</h2><p>消息队列的数据过期机制一般有手动删除和自动删除两种形式，从实现上看主要有三种思路。</p><ul><li>消费完成执行 ACK 删除数据</li><li>根据时间和保留大小删除</li><li>ACK 机制和过期机制相结合</li></ul><h3 id="方案1"><a href="#方案1" class="headerlink" title="方案1"></a>方案1</h3><p><strong>消费完成执行 ACK 删除数据，技术上的实现思路一般是</strong>：当客户端成功消费数据后，回调服务端的 ACK 接口，告诉服务端数据已经消费成功，服务端就会标记删除该行数据，以确保消息不会被重复消费。ACK 的请求一般会有单条消息 ACK 和批量消息 ACK 两种形式。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718113808956.png" alt="image-20230718113808956" style="zoom: 80%;" /><p>因为消息队列的 ACK 一般是顺序的，如果前一条消息无法被正确处理并 ACK，就无法消费下一条数据，导致消费卡住。此时就需要死信队列的功能，把这条数据先写入到死信队列，等待后续的处理。然后 ACK 这条消息，确保消费正确进行。</p><p>这个方案，优点是不会出现重复消费，一条消息只会被消费一次。缺点是 ACK 成功后消息被删除，无法满足需要消息重放的场景。</p><h3 id="方案2"><a href="#方案2" class="headerlink" title="方案2"></a>方案2</h3><p><strong>根据时间和保留大小删除指消息在被消费后不会被删除，只会通过提交消费位点的形式标记消费进度。</strong></p><p>实现思路一般是服务端提供偏移量提交的接口，当客户端消费成功数据后，客户端会回调偏移量提交接口，告诉服务端这个偏移量的数据已经消费成功了，让服务端把偏移量记录起来。然后服务端会根据消息保留的策略，比如保留时间或保留大小来清理数据。一般通过一个常驻的异步线程来清理数据。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718114135696.png" alt="image-20230718114135696" style="zoom:67%;" /><p>这个方案，一条消息可以重复消费多次。不管有没有被成功消费，消息都会根据配置的时间规则或大小规则进行删除。优点是消息可以多次重放，适用于需要多次进行重放的场景。缺点是在某些情况下（比如客户端使用不当）会出现大量的重复消费。</p><h3 id="方案3"><a href="#方案3" class="headerlink" title="方案3"></a>方案3</h3><p>我们结合前两个方案，就有了 <strong>ACK 机制和过期机制相结合的方案</strong>。实现核心逻辑跟方案二很像，但保留了 ACK 的概念，不过 ACK 是相对于 Group 概念的。</p><p>当消息完成后，在 Group 维度 ACK 消息，此时消息不会被删除，只是这个 Group 也不会再重复消费到这个消息，而新的 Group 可以重新消费订阅这些数据。所以在 Group 维度避免了重复消费的情况，也可以允许重复订阅。（说白了，一条消息在一个Group消费后会发送一个ACK确认，然后此Group就不会再消费该消息了，但是其他的Group还是可以重复的消费该消息，如果超过时间，则该消息被删除，其他Group也无法订阅）</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230718114619550.png" alt="image-20230718114619550" style="zoom:67%;" /><p>我们知道消息数据是顺序存储在文件中的，会有很多分段数据，一个文件可能会有很多行数据。</p><p>那么在 ACK 或者数据删除的时候，一个文件中可能既存在可删除数据，也存在不可删除数据。</p><p>如果我们每次都立即删除数据，需要不断执行“读取文件、找到记录、删除记录、写入文件”的过程，即使批量操作，降低频率，还是得不断地重复这个过程，会导致性能明显下降。</p><p>当前主流的思路都是<strong>延时删除，以段数据为单位清理</strong>，降低频繁修改文件内容和频繁随机读写文件的操作。</p><p>只有该段里面的数据都允许删除后，才会把数据删除。而删除该段数据中的某条数据时，会先对数据进行标记删除，比如在内存或 Backlog 文件中记录待删除数据，然后在消费的时候感知这个标记，这样就不会重复消费这些数据。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/1090617-20190626173042073-147043337.jpg" alt="img"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;存储模块的主流程是数据的写入、存储、读取、过期，因为消息队列本质是做一个缓冲，它的持久化在一定时间或者数据被消费后需要删除。&lt;/p&gt;
&lt;p&gt;消息队列中的数据一般分为&lt;strong&gt;元数据和消息数据&lt;/strong&gt;。元数据是指 Topic、Group、User、ACL、Co</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
</feed>
