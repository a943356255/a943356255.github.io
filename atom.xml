<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>随便起个名字吧</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-10-04T07:56:20.299Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Guo Junhao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>多主复制</title>
    <link href="http://example.com/2023/10/04/%E5%A4%9A%E4%B8%BB%E5%A4%8D%E5%88%B6/"/>
    <id>http://example.com/2023/10/04/%E5%A4%9A%E4%B8%BB%E5%A4%8D%E5%88%B6/</id>
    <published>2023-10-04T07:50:22.000Z</published>
    <updated>2023-10-04T07:56:20.299Z</updated>
    
    <content type="html"><![CDATA[<h1 id="多主复制"><a href="#多主复制" class="headerlink" title="多主复制"></a>多主复制</h1><p>在主从复制的场景中，只有一个主节点，所有的写入操作都要先经过主节点，主节点压力大的问题还是没能解决。而且单主节点的容灾效果也不是很好。</p><p>为了达到好的容灾效果，各个机房的距离应该足够远，尽可能的分布在不同的地区，那么这种场景下，用户直接读写自己最近的数据中心，网络延迟最小，效果最好。因此就出现了多住复制。</p><h2 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h2><p>它是指在一个数据系统中，存在多个主从 复制单元，每一个主从复制单元都可以处理读写请求，一个主从复制单元的主副本处理了写请 求后，需要复制到其他的主从复制单元的主副本，具体的流程见下图：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231004112141400.png" alt="image-20231004112141400" style="zoom: 80%;" /><p>有几点需要注意：</p><p>首先，每一个主从复制单元内部是一个常规的主 从复制模式，这里的主副本、从副本之间的复制可以是同步的，也可以是异步的。</p><p>其次，多个主从复制单元之间，每一个主副本都会将自己的修改复制到其他的主副本，主副本 之间的复制可以是同步的，也可以是异步的。</p><p>如果主副本之间的复制是同步的，那么一个主副本的写入，需要等待复制到其他的主副本成功 后，才能返回给用户，但是，这样却失去了多主复制最重要的一个优点，即多个主副本都可以独立处理写入，这就导致整个模式 退化为主从复制的形式。所以一般来说，多主复制的主副本之间，大多采用异步模式。</p><p>但采用异步复制也会出现问题，如果多个主副本同时成功修 改一个数据，当主副本之间复制这个数据的修改时，会出现冲突，我们就不知道以哪一个主副 本的写入结果为准了，该问题在同步复制时可以让用户决定哪个为主。</p><h2 id="冲突解决"><a href="#冲突解决" class="headerlink" title="冲突解决"></a>冲突解决</h2><p>冲突主要由两种形式，</p><p>首先是由于更新导致的冲突，多个主副本同时更新了一个数据，导致这个数据的版本是非线性的，出现了分叉，具体见下图：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231004124557885.png" alt="image-20231004124557885">其次，由于新增导致的冲突，多个主副本同时新增了一个含有唯一性约束的数据，导致数据的唯一性约束被破坏。例如，在酒店预订业务中，一个时段内一个房间只能预订给一个用户，如 果多个用户在多个主副本上，同时发起预订操作，就可能出现同一个时段内，一个房间被多个 用户预定成功的情况。</p><h3 id="避免冲突"><a href="#避免冲突" class="headerlink" title="避免冲突"></a>避免冲突</h3><p>由上可知，冲突是多个主副本同时 修改了一个数据，或者破坏了数据的唯一性约束导致的，那么我们就对数据进行分片，让不同的主数据负责不同的数据分片，这个方式可以在一定程度上避免冲突，但是会导致两个问题：</p><p>首先，一个修改操作可能会修改多个分片数据，这样我们就没有办法通过分片来隔离修改了。</p><p>其次，由于就近接入和故障等原因，我们会将出现故障的主副本流量切换到其他的主副本，这 时也会出现写入冲突的情况。</p><p>注意：这里的分片，并不是每个主副本只保留一部分数据，而是每个主副本仍然保留全量的数据，但是只负责主动的修改某一部分，其他部分等待其他主副本进行同步。</p><h4 id="写时解决冲突"><a href="#写时解决冲突" class="headerlink" title="写时解决冲突"></a>写时解决冲突</h4><p>写时解决冲突有两种实现，预定义解决冲突和自定义解决冲突。</p><p>预定义解决冲突，是指由存储系统预先定义好规则，在冲突发生时依据预先定义好的规则，自动来解决冲突，主要有以下几种：</p><ol><li>从操作维度来处理，最后写入获胜。也就是为每一个写操作分配一个时间戳，如果发生 冲突，只保留时间戳最大的版本数据，其他的修改都丢弃，但是这个方法会导致修改丢失。</li><li>从副本维度来处理，最高优先级写入获胜。也就是为每一个副本都排好优先级，如果发 生冲突，只保留优先级最高的副本修改数据，其他的修改都丢弃。</li><li>从数据结构和算法的维度来处理，通过研究一些可以自动解决冲突的数据结构来解决问题。目前不成熟。</li></ol><p>自定义解决冲突，它是由业务系统来定义冲突的解决方式，如果发生冲突 了，存储系统就依据业务系统定义的方式执行。</p><p>自定义冲突解决的处理逻辑是，在主副本之间复制变更日志时，如果检测到冲突，就调用用户 自定义的冲突处理程序来进行处理。由于主副本之间的数据复制是异步的，所以一般都是后台 执行，不会提示用户。</p><h4 id="读时解决冲突"><a href="#读时解决冲突" class="headerlink" title="读时解决冲突"></a>读时解决冲突</h4><p>读时解决冲突的思路和写时解决冲突的思路正好相反，即在写入数据时，如果检测到冲突，不 用立即进行处理，只需要将所有冲突的写入版本都记录下来。当下一次读取数据时，会将所有的数据版本都返回给业务层，在业务层解决冲突，那么读时解决冲突的方式有下面两种：</p><ol><li>由用户来解决冲突。业务层将冲突提示给用户，让用户来解决。</li><li>自定义解决冲突。业务层先依据业务情况，自定义好解决冲突的处理程序，当检 测到冲突时，直接调用处理程序来解决。</li></ol><h2 id="多主复制的关键问题"><a href="#多主复制的关键问题" class="headerlink" title="多主复制的关键问题"></a>多主复制的关键问题</h2><p>1、正确解决冲突的难度非常大。</p><p>2、异步模式的多主复制会存在数据一致性的问题。因为多个主副本都是独立写入的，而他们之间是通过异步复制的方式。</p><p>3、多个主副本之间的复制拓扑结构问题。一般来说，多主复制的主副本之间的复制拓扑结 构主要有三种：环形拓扑、星形拓扑以及全部至全部拓扑，具体见下图：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231004155403956.png" alt="image-20231004155403956" style="zoom:80%;" /><p>前两种，如果一个主副本出现问题，则会导致整个副本的数据无法同步，而第三种虽然一个挂了不影响，但是他们主副本之间同步的时延却要大很多。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;多主复制&quot;&gt;&lt;a href=&quot;#多主复制&quot; class=&quot;headerlink&quot; title=&quot;多主复制&quot;&gt;&lt;/a&gt;多主复制&lt;/h1&gt;&lt;p&gt;在主从复制的场景中，只有一个主节点，所有的写入操作都要先经过主节点，主节点压力大的问题还是没能解决。而且单主节点的容灾效果也</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>数据分片</title>
    <link href="http://example.com/2023/10/02/%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87/"/>
    <id>http://example.com/2023/10/02/%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87/</id>
    <published>2023-10-02T11:31:22.000Z</published>
    <updated>2023-10-02T11:32:46.868Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h2><p>对数据进行分片的策略，主要有三种：水平分片、垂直分片和混合分片，具体如下图所示。水平分片和垂直分片是通过数据切分的操作方向来区分的，而混合分片 是它们的组合体。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002105033499.png" alt="image-20231002105033499" style="zoom: 67%;" /><h3 id="水平分片"><a href="#水平分片" class="headerlink" title="水平分片"></a>水平分片</h3><p>水平分片有点类似于负载均衡，从流量角度来看，是负载均衡，从数据存储角度来看，是水平分片。</p><p>水平分片算法有两个最关键的因素，一是，如何对数据进行划分，即数据划分，二是，分片是 否支持动态分裂与合并，即数据平衡。</p><h4 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h4><p>数据划分主要有两种方案，一种是基于模运算，一种是基于范围划分。基于模运算比较简单，不再阐述。而基于范围划分，又分为基于关键词划分和基于关键词的 Hash 值划分两种方式。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002110024878.png" alt="image-20231002110024878" style="zoom:67%;" /><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002110040276.png" alt="image-20231002110040276" style="zoom:67%;" /><p>这两种分片都是给每一个分片分配一个固定的范围，两者的不同区别在于一个是直接拿关键词进行划分，另一个是利用了关键词的Hash值进行划分。看似区别不大，但是会影响数据的分布。</p><h5 id="基于关键词划分"><a href="#基于关键词划分" class="headerlink" title="基于关键词划分"></a>基于关键词划分</h5><p>基于<strong>关键词划分</strong>的好处是，分片后数据的分布依然保留了关键词的顺序，我们可以方便地进行区间查询，因为某个关键词区间的数据都是连续存储的。</p><p>但是基于关键词划分也会带来问题，即<strong>数据分布不均匀和访问的热度不均匀</strong>。比如说按照地区进行划分，那么某些省份人数多，这个分片的数据就会多，人数少，分片数据就少。而且数据分布不均时，数据多的分片被访问到的概率也会变大。</p><p>如果基于自增 ID 或者时间等关键词对数据进行分片的时候，即使数据是均匀分布的，对于一般的业务场景来说，往往新产生数据的访问热度，也是远远大于历史数据的，这也会导致访问的热度不均匀。</p><p>很明显，数据的分布与关键词的分布是一致的。</p><h5 id="基于关键词的hash值"><a href="#基于关键词的hash值" class="headerlink" title="基于关键词的hash值"></a>基于关键词的hash值</h5><p>基于关键词的 Hash 值划分就可以上述问题，它通过对关键词进行 Hash 运算，然后基于计算后的 Hash 值范围对数据进行划分，一个好的 Hash 算法可以处理数据倾斜并让它均匀分布。这样可以解决数据分布和访问热度不均的问题。</p><p>但导致的问题就是无法高效的进行范围查询。</p><h4 id="数据平衡"><a href="#数据平衡" class="headerlink" title="数据平衡"></a>数据平衡</h4><p>根据数据分片是否支持<strong>动态的分裂与合并</strong>，我们可以将水平分片的数据平衡方式分为<strong>静态分片</strong>和<strong>动态分片</strong>。</p><p>静态分片是指在系统设计之初，数据分片的数目和区间就预估好了，数据划分后不能再变化。</p><p>动态分片则可以在运行时，根据分片的负载和容量做调整。</p><p>因为动态分片在运行时分区时可以进行分裂与合并的，不需要担心数据分布的问题，所以动态分片与基于关键词的划分，往往是一个 比较好的组合方式，它避免了基于关键词划分的问题，还保留了数据基于关键词有序的优点。</p><p>但是，在基于关键词的划分中，基于自增 ID 或者时间戳等原因，导致的访问冷热不均匀的问题，即使是在动态分片中也不能很好地解决，因为数据的热点往往集中在最新的一个分片区间上。而基于关键词的 Hash 值划分的方式，则可以很方便地将最新的热点数据分布到多个分片 上，很好地解决这个问题。</p><p>动态分片存在冷启动的问题。当一个基于动态分片的存储系统启动时，通常是从一个分片开始，当数据量不断增长后，再动态进行分裂。在第一次进行分裂前，所有的读写请求都由 第一个分片来进行处理，而其他的节点则都属于空闲状态。关于这个问题，一个比较好的解决 方式是，动态分片在冷启动时，预分裂为多个分片来缓解。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002112557636.png" alt="image-20231002112557636" style="zoom:67%;" /><h3 id="垂直分片"><a href="#垂直分片" class="headerlink" title="垂直分片"></a>垂直分片</h3><p>水平分片策 略将整个数据集的条数作为划分的对象，每一个分片负责处理一定的数据条数。而垂直分片策略则是将数据 Schema 的字段集个数作为划分的对象，每一个分片负责处理一个或几个字段 的全部数据，具体如下图所示。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002164951470.png" alt="image-20231002164951470" style="zoom: 80%;" /><p>如果垂直分片策略的处理方式为一个字段一个分片，那么垂直分片策略就等价于列式存储了，所以列式存储是垂直分片策略的一种特殊情况，也是最常见的情况。</p><p>列式存储往往用于大数据分析当中，这类数据的特点是一次写入，多次查询（从不修改），而且是按列读取，每次只关心一列或者几列，每张表都很宽，比如上百列。而且查询无规律，不能索引覆盖。</p><h4 id="列式存储"><a href="#列式存储" class="headerlink" title="列式存储"></a>列式存储</h4><p>如果是行式存储，当我们只需要读取一列时，有两种方案，第一个是挨个读取每一行的数据，但是只取出自己要的那一列，这会导致读取数据的量放大很多。如果我们只读取那一列，这会导致我们读取时不是按顺序读取，会对读取造成性能影响。</p><p>读多写少的场景，会减少列式存储对写性能的影响。一般来说，数据写入存储系统是以 行的形式写入的，而列式存储会导致一行数据的写入操作，按字段拆分为多个写入操作，使写入放大。</p><p>大数据场景，采用列式存储非常适合压缩存储，比如下图：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002192207839.png" alt="image-20231002192207839" style="zoom:67%;" /><p>好处是使用压缩会大大减小存储成本，提高了存储效率，但是在存储和读取数据时，需要多一步，即找到数据的编码，需要消耗额外的CPU资源。</p><h3 id="混合分片策略"><a href="#混合分片策略" class="headerlink" title="混合分片策略"></a>混合分片策略</h3><p>根据水平分片和垂直分片的策略，混合分片可以分为<strong>垂直水平分片</strong>策略和<strong>水平垂直分片</strong>策略。前者先 进行垂直分片，再进行水平分片，而后者先进行水平分片，然后再进行垂直分片。具体如下图：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002192630321.png" alt="image-20231002192630321" style="zoom: 80%;" /><p>垂直水平分片看着不怎么滴，不过多介绍。</p><p>水平垂直分片更像是两者的结合提。先水平划分，划分完后在每一个分片内部再采用列式存储，这样可以保留水平分片和垂直分片的优点。</p><h3 id="行列存储比较"><a href="#行列存储比较" class="headerlink" title="行列存储比较"></a>行列存储比较</h3><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20231002193058865.png" alt="image-20231002193058865" style="zoom:80%;" /><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;分片&quot;&gt;&lt;a href=&quot;#分片&quot; class=&quot;headerlink&quot; title=&quot;分片&quot;&gt;&lt;/a&gt;分片&lt;/h2&gt;&lt;p&gt;对数据进行分片的策略，主要有三种：水平分片、垂直分片和混合分片，具体如下图所示。水平分片和垂直分片是通过数据切分的操作方向来区分的，而混合分</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Spring的IoC</title>
    <link href="http://example.com/2023/09/30/Spring%E7%9A%84IoC/"/>
    <id>http://example.com/2023/09/30/Spring%E7%9A%84IoC/</id>
    <published>2023-09-30T06:54:11.000Z</published>
    <updated>2023-09-30T07:30:30.177Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大致流程"><a href="#大致流程" class="headerlink" title="大致流程"></a>大致流程</h1><p>1、解析xml文件，将xml中读取到的内容利用<code>ClassPathXmlResource</code>来进行存储。</p><p>2、初始化一个工厂，该工厂可以自由选择，比如<code>SimpleBeanFactory</code>或者<code>AutowireCapableBeanFactory</code>，又或者是<code>BeanFactory</code>，取决于场景需要。</p><p>3、实例化一个<code>XmlBeanDefinitionReader</code>，该类需要传入第二步生成的工厂，它的主要作用就是解析存储在<code>ClassPathXmlResource</code>中的属性，将它封装为一个<code>BeanDefinition</code>，然后存储在一个map中，map的key为对象的名字，value就是<code>BeanDefinition</code>。用于后续创建bean时，根据名称取到<code>BeanDefinition</code>，然后<code>BeanDefinition</code>中取得属性。</p><p>4、到此为止，上面的三步是为了初始化并且存储一些对象的信息，这些信息都来自xml中的配置。之后，调用<code>refresh()</code>来进行具体的创建。</p><p>5、在单例模式下，<code>refresh()</code>会先从存放了所有bean实例的map中根据名字取该元素，如果不为空，则直接返回，如果为空，则从毛坯实例中尝试获取该元素（存储毛坯实例是为了解决循环依赖的问题，创建一个空的对象，所有属性都不赋值，用于注入），如果还是为空，则执行创建。</p><p>6、创建的流程就是获取到之前存储的<code>BeanDefinition</code>，然后先创建一个毛坯实例，这里是利用Java的反射以及<code>BeanDefinition</code>中存储的<code>getConstructorArgumentValues</code>信息，来进行创建，只创建空的类，类的所有属性都不赋值。之后将毛坯实例进行存储。</p><p>7、这一步是将上一步创建的毛坯实例属性进行赋值，从<code>BeanDefinition</code>中获取到<code>PropertyValues</code>，然后遍历，调用<code>setXXX</code>方法进行赋值。</p><p>8、创建完后，将bean存储到第五步刚开始取元素的那个map当中，并返回本次创建的实例。如果没有采用注解，到这里就已经创建结束了。</p><p>9、如果创建的元素当中有属性使用了注解，则会调用<code>AutowiredAnnotationBeanPostProcessor</code>的<code>postProcessBeforeInitialization</code>方法，该方法会遍历传入实例的所有属性，如果发现带有@Autowired注解，那么就去工厂中获取到对应的实例，并进行注入，然后返回该对象。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;大致流程&quot;&gt;&lt;a href=&quot;#大致流程&quot; class=&quot;headerlink&quot; title=&quot;大致流程&quot;&gt;&lt;/a&gt;大致流程&lt;/h1&gt;&lt;p&gt;1、解析xml文件，将xml中读取到的内容利用&lt;code&gt;ClassPathXmlResource&lt;/code&gt;来进行存储。</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="设计模式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="设计模式" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>降级</title>
    <link href="http://example.com/2023/09/27/%E9%99%8D%E7%BA%A7/"/>
    <id>http://example.com/2023/09/27/%E9%99%8D%E7%BA%A7/</id>
    <published>2023-09-27T02:16:37.000Z</published>
    <updated>2023-09-27T02:18:44.244Z</updated>
    
    <content type="html"><![CDATA[<h1 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h1><p>上面的熔断，是为了在系统过载时不发生雪崩，限流是为了流量较大时，系统不发生过载。但是这两者都不会区分该服务是核心业务还是非核心业务。而降级，则是为了减少或者停掉一些非核心业务，来确保核心业务收到的影响最小。</p><h2 id="为什么需要降级"><a href="#为什么需要降级" class="headerlink" title="为什么需要降级"></a>为什么需要降级</h2><ol><li>降级机制能从全局角度对资源进行调配，通过牺牲非核心服务来保障核心服务的稳定性。降级是主动停掉一些非核心业务，而限流则是被动的将一些请求拒绝。</li><li>降级可以提高系统的用户体验性和可用性。在一些场景中，如果正常调用出现了非业务层错误后，我们可以不返回错误，而是执行接口的B计划，进行降级，虽然可能和正常流程不太一样，但是比直接返回错误要好。</li></ol><h2 id="如何实现降级"><a href="#如何实现降级" class="headerlink" title="如何实现降级"></a>如何实现降级</h2><h3 id="手动降级"><a href="#手动降级" class="headerlink" title="手动降级"></a>手动降级</h3><p>手动降级是指在分布式系统中提前设置好降级开关，然后通过类似配置中心的集中式降级平 台，来管理降级开关的配置信息，在系统需要降级的时候，通过降级平台手动启动降级开关， 对系统进行降级处理。</p><p>该方案需要注意的是，往往服务有成千上百个，如果全部手动操作，则很麻烦。一个解决办法是：通过对降级分级，利用服务的等级信息和业务信息进行批量降级，比如一次直接把p1,p2,p3的服务全部降级。</p><h3 id="自动降级"><a href="#自动降级" class="headerlink" title="自动降级"></a>自动降级</h3><p>自动降级是指在分布式系统中，当系统的某些指标或者接口调用出现错误时，直接启动降级逻辑。一个降级的例子如下：</p><p>我们在网关中调用鉴权服务进行鉴权，每一 个调用鉴权服务的鉴权接口，需要执行如下的两个校验逻辑，不论哪一个失败，都会导致鉴权失败。</p><ol><li>校验 Token 是否合法。</li><li>校验 UID 是否被管理员封禁。</li></ol><p>在这个情况下，我们可以将 Token 设计为可以自校验的，在鉴权服务出现故障的时候，则启动降级逻辑，直接在网关中校验 Token 是否合法，如果合法就返回鉴权成功。</p><h2 id="降级机制的关键问题"><a href="#降级机制的关键问题" class="headerlink" title="降级机制的关键问题"></a>降级机制的关键问题</h2><p>一般来 说，我们使用降级都是在系统已经出现过载的场景下，这时我们需要考虑，降级的配置信息是 否能正常下发。并且，降级通常会与熔断和限流一起出现，我们应该如何处理它们三者之间的关系。</p><h3 id="配置信息下发的问题"><a href="#配置信息下发的问题" class="headerlink" title="配置信息下发的问题"></a>配置信息下发的问题</h3><p>对于熔断和限流来说，其阈值相关的配置信息在系统正常运行的时候，就已经下发到实例上了，所以在系统出现故障的时候，这些配置信息会直接生效。但是对于手动降级，我们需要在系统出问题时，通过降级平台下发配置来启动降级。</p><p>针对于配置无法正常下发的情况，我们可以考虑，由服务直接暴露出修改降级配置的 HTTP 接口，在必要的时候，可以手动通过 HTTP 接口，来启动服务的降级逻辑。</p><h3 id="熔断、限流和降级之间的关系"><a href="#熔断、限流和降级之间的关系" class="headerlink" title="熔断、限流和降级之间的关系"></a>熔断、限流和降级之间的关系</h3><p>首先，因为熔断机制是系统稳定性保障的最后一道防线，并且它是自适应的，所以我们应该在系统全局默认启用；</p><p>其次，限流是用来保障被限流服务稳定性的，一般在系统的核心链路和核心服务上，默认启用限流机制；</p><p>最后，降级是通过牺牲被降级的接口或者服务，来保障其他的接口和服务正常运行的，可以通过降级直接停用非核心服务，然后对于核心接口和服务，在必要的时候，可以提供一个“ B 计划”。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;降级&quot;&gt;&lt;a href=&quot;#降级&quot; class=&quot;headerlink&quot; title=&quot;降级&quot;&gt;&lt;/a&gt;降级&lt;/h1&gt;&lt;p&gt;上面的熔断，是为了在系统过载时不发生雪崩，限流是为了流量较大时，系统不发生过载。但是这两者都不会区分该服务是核心业务还是非核心业务。而降级，</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>限流</title>
    <link href="http://example.com/2023/09/26/%E9%99%90%E6%B5%81/"/>
    <id>http://example.com/2023/09/26/%E9%99%90%E6%B5%81/</id>
    <published>2023-09-26T05:48:45.000Z</published>
    <updated>2023-09-26T05:50:25.563Z</updated>
    
    <content type="html"><![CDATA[<p>如果系统只有熔断机制，当流量激增的时候，就相当于被动的等待熔断机制的触发，此时就需要另外的手段来防止系统负载过高，限流就是一个很好的方案，要主动出击，防止服务挂掉。</p><h1 id="为什么需要限流"><a href="#为什么需要限流" class="headerlink" title="为什么需要限流"></a>为什么需要限流</h1><ol><li>熔断处理的方式不够优雅。熔断是等到系统过载之后才触发的，即先发生过载，等系统故障后才会介入，让系统恢复。这样的处理方式会导致系统的不必要抖动。</li><li>熔断机制是最后的底线。虽然熔断可以解决雪崩问题，但是它应该作为系统稳定性保障的 最后一道防线，正确使用熔断的思路应该是，在其他方法用尽 之后，如果过载问题依旧存在，这时熔断才会被动触发。</li><li>在快速失败的时候，需要能考虑调用方的重要程度。熔断是调用方依据响应结果自适应来触发的，在被调用方出现过载的时候，所有的调用方都将受到影响。但是不同接口的重要程度不一样，需要保证有些接口优先处理。</li><li>在多租户的情况下，不能让一个租户的问题影响到其他的租户，我们需要对每一个租户分配一定的配额，谁超过了就对谁进行限流，保证租户之间的隔离性。</li></ol><h1 id="如何实现限流"><a href="#如何实现限流" class="headerlink" title="如何实现限流"></a>如何实现限流</h1><p>限流一般有固定的限流算法，有以下几种：</p><h2 id="固定窗口和滑动窗口"><a href="#固定窗口和滑动窗口" class="headerlink" title="固定窗口和滑动窗口"></a>固定窗口和滑动窗口</h2><p>固定窗口就是定义一个“固定”的统计周期，比如 10 秒、30 秒或者 1 分钟，然后在每个周 期里，统计当前周期中被接收到的请求数量，经过计数器累加后，如果超过设定的阈值就触发 限流，直到进入下一个周期后，计数器清零，流量接收再恢复正常状态，如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230926104828548.png" alt="image-20230926104828548" style="zoom:80%;" /><p>存在的问题：</p><ol><li><p>抗抖动性差。由于流量突增使请求超过预期，导致流量可能在一个统计周期的前 10 ms 内就达到了 100 次，给服务的处理能力造成一定压力，同时后面的 1990 ms 将会触发限流。 </p><p>这个问题虽然可以通过减小统计周期来改善，但是因为统计周期变小，每个周期的阈值也会变 小，一个小的流量抖动就会导致限流的发生，所以系统的抗抖动能力就变得更差了。</p></li><li><p>如果上一个统计周期的流量集中在最后 10 ms ，而现在这个统计周期的流量集中在前 10 ms ，那么这 20 ms 的时间内会出现 200 次调用，这就超过了我们预期的 2 秒内不能超 过 100 次请求的目的了。这时候，我们就需要使用“滑动窗口”算法来改善这个问题了。</p></li></ol><p>滑动窗口就是固定窗口的优化，它对固定窗口做了进一步切分，将统计周期的粒度切分 得更细，比如 1 分钟的固定窗口，切分为 60 个 1 秒的滑动窗口，然后统计的时间范围随着时 间的推移同步后移，如下图所示。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230926110157298.png" alt="image-20230926110157298" style="zoom:80%;" /><p>但是这里要注意一个问题，如果滑动窗口的统计窗口切分得过细，会增加系统性能和资源损耗 的压力。同时，滑动窗口和固定窗口一样面临抗抖动性差的问题。</p><h2 id="漏桶"><a href="#漏桶" class="headerlink" title="漏桶"></a>漏桶</h2><p>如下图所示，“漏桶”就像一个漏斗，进来的水量就像访问流量一样，而出去的水量 就像是我们的系统处理请求一样。当访问流量过大时，这个漏斗中就会积水，如果水太多了就会溢出。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230926110501239.png" alt="image-20230926110501239"></p><p>该算法相对于滑动窗口和固定窗口做了两个改进点，第一，增加了一个桶来缓存请求，在流量突增的时候，可以先缓存起来，直到超过桶的容量才触发限流；第二，对出口的流量上限做了限制，使上游流量的抖动不会扩散到下游服务。</p><p>漏桶提供流量整形能力有一定的代价，超过漏桶流出速率的请求，需要先在漏桶中排队等待，其中流出速率是漏桶限流的防线，一般会设置得相对保守，可是这样就无法完全利用系 统的性能，就增加了请求的排队时间。</p><h2 id="令牌桶"><a href="#令牌桶" class="headerlink" title="令牌桶"></a>令牌桶</h2><p>令牌桶算法的核心是固定“进口”速率，限流器在一个一定容量的桶内，按照一定的速率放入 Token ，然后在处理程序去处理请求的时候，需要拿到 Token 才能处理；如果拿不到，就进行限流。</p><p>因此，当大量的流量进入时，只要令牌的生成速度大于等于请求被处理的速度，那么此时系统处理能力就是极限的。<img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230926112343201.png" alt="image-20230926112343201" style="zoom:80%;" /></p><p>令牌桶算法相对于漏桶，虽然提高了系统的资源利用率，但是却放弃了一定的流量整形能力，也就是当请求流量突增的时候，上游流量的抖动可能会扩散到下游服务。</p><h1 id="单节点限流"><a href="#单节点限流" class="headerlink" title="单节点限流"></a>单节点限流</h1><p>单节点限流比较简单，可以基于内存来做，需要注意两点：</p><ol><li><p>限流机制作用的位置是客户端还是服务端，即选择客户端限流还是服务端限流。一般来说，熔断机制作用的位置是客户端，限流机制作用的位置更多是服务端，因为熔断更强调自适应，让作用点分散在客户端是没有问题的，而限流机制则更强调控制，它的作用点在服务端的控制能力会更强。</p><p>将作用点放置在服务端，会给服务端带来性能压力。如果将作用点放置在客户端，这就是一个天然的分布式模式，每一个调用方的客户端执行自己的限流逻辑，而将作用点放置在服务端时，服务端要执行所有请求的限流逻辑， 就需要更多的内存来缓存请求，以及更多的 CPU 来执行限流逻辑。</p></li><li><p>如果触发限流后，我们应该直接抛弃请求还是阻塞等待，即否决式限流和阻塞式限流。一般来说，如果我们可以控制流量产生的速率，那么阻塞式限流就是一个更好的选择，因为它既可以实现限流的目的，又不会抛弃请求；</p><p>如果我们不能控制流量产生的速率，那么阻塞式限流将会因为请求积压，出现大量系统资源占用的情况，很容易引发雪崩，这时否决式限流将是 更好的选择。</p></li></ol><h1 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h1><p>为了系统的高可用，一般每个服务都会有多个实例，所以在进行限流时，需要协调该服务的多个实例，进行统一限流。主要方案有以下几点。</p><p>1、进行集中限流。该方案可以借助一个外部存储，比如Redis，然后采用令牌桶算法。但是会带来问题，每次请求都需要先去Redis获取令牌，会导致Redis成为性能瓶颈，并且限流器故障会导致所有请求都被拒绝，而且每次请求都多了一次网络调用，增加时延。</p><p>2、将分布式限流进行本地化处理。限流器在获得一个服务限额的总阈值后， 将这个总阈值按一定的策略分配给服务的实例，每一个实例依据分配的阈值进行单节点限流。这里要考虑如果每个服务器的配置不一样，那么分配的流量就需要不同.</p><p>一个折中的方案：该方案建立在集中式限流的基础上，为了解决每次请求 都需要，通过网络访问限流器获取令牌的问题，客户端只有在令牌数不足时，才会通过限流器 获取令牌，并且一次获取一批令牌。即令牌由集中式限流器生成，但是具体的限流策略是在每个客户端本地处理。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如果系统只有熔断机制，当流量激增的时候，就相当于被动的等待熔断机制的触发，此时就需要另外的手段来防止系统负载过高，限流就是一个很好的方案，要主动出击，防止服务挂掉。&lt;/p&gt;
&lt;h1 id=&quot;为什么需要限流&quot;&gt;&lt;a href=&quot;#为什么需要限流&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>服务熔断</title>
    <link href="http://example.com/2023/09/25/%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/"/>
    <id>http://example.com/2023/09/25/%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/</id>
    <published>2023-09-25T05:18:00.000Z</published>
    <updated>2023-09-25T05:19:15.260Z</updated>
    
    <content type="html"><![CDATA[<h1 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h1><p>熔断机制：当服务之间发起调用的时候，如果被调用方返回的 指定错误码的比例超过一定的阈值，那么后续的请求将不会真正发起，而是由调用方直接返回错误。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230925125355151.png" alt="image-20230925125355151" style="zoom:67%;" /><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230925125408532.png" alt="image-20230925125408532"></p><p>首先是闭合状态，此时可以处理请求，但是需要一个计数器，来统计调用失败的次数，如果失败的次数达到阈值，则将状态改为闭合。</p><p>在闭合状态下，可以直接拒绝后续的请求，也可以对请求做一个降级（后续介绍）。此时会启动一个超时计时器，当计时器超时后，会转变为半打开状态。</p><p>在半打开状态下，允许一定数量的请求发往被调用的服务，如果这些调用正常，则就可以认为被调用服务已经恢复正常，此时熔断器切换为闭合状态，同时重置计数器。如果仍有部分调用失败的情况，则认为被调用方仍然没有恢复，熔断器会切换到断开状态，然后重置计数器。半打开状态是为了防止恢复中的服务被大量请求再次打垮的情况。</p><h2 id="熔断的关键点"><a href="#熔断的关键点" class="headerlink" title="熔断的关键点"></a>熔断的关键点</h2><p>有以下五个关键点：粒度控制、错误类型、存活与过载的区别、重试和熔断的关系和熔断机制的适应范围。</p><h3 id="粒度控制"><a href="#粒度控制" class="headerlink" title="粒度控制"></a>粒度控制</h3><p>该问题是指我们想将监控资源过载的粒度控制在一个什么样的范围内，这个范围可以由<strong>服务、实例和接口</strong>这三个维度的组合来得到。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230925130518335.png" alt="image-20230925130518335" style="zoom: 80%;" /><p>建议使用基于实例接口的熔断，这样的粒度最小，假如说一个实例有10个接口，只有一个接口请求超时，那么熔断该接口即可，其他接口仍然可以提供服务，将熔断的错误率讲到最低。</p><h3 id="错误类型"><a href="#错误类型" class="headerlink" title="错误类型"></a>错误类型</h3><p>由于熔断机制是用来消除系统过载的，所以，我们需要识别出与系统过载相关的错误，来进行 熔断处理，一般来说，主要有下面两个错误类型。</p><ol><li>系统被动对外表现出来的过载错误，一般来说，如果一个接口过载了，那么它的响应时间就会变长，熔断器捕获到的错误类型就是“响应超时”之类的超时错误。</li><li>系统主动对外表现出来的过载错误，对于这种情况，一般是请求的流量触发了限流等机制返回的错误码，这个是我们在程序开发过程中主动设计的。</li></ol><h3 id="过载与存活的区别"><a href="#过载与存活的区别" class="headerlink" title="过载与存活的区别"></a>过载与存活的区别</h3><p>熔断机制关心系统是否过载，最好的判断方式为利用队列中的平均等待时间来计算服务的负载。不利用服务的处理时间是为了考虑下游任务的处理时间，有时可能是因为下游处理太慢而导致的当前服务处理时间较长。</p><p>在熔断场景中，我们对过载判断进行了简化，直接通过接口请求的结果进行判断，如果发生请求错误，并且错误为超时或者限流等错误的比例超过一定的阈值，我们就可以认为系统过载，然后进行熔断。</p><p>而存活一般是指机器或者服务是否存活，对于机器是否存活，一般是通过定期 ping 机器的 IP ，如果超过一定时间不能 ping 通，则认为该机器不存活了。</p><h3 id="熔断与重试的关系"><a href="#熔断与重试的关系" class="headerlink" title="熔断与重试的关系"></a>熔断与重试的关系</h3><p>熔断和重试都会对服务之间的调用请求进行额外的处理，不同的是，重试是指我们认为该次调用失败是因为系统临时错误导致的，所以重发一次请求。而熔断是指我们已经认为系统过载了，为了保证系统不发生雪崩，为了使接口快速处理，而直接返回失败。</p><h3 id="熔断机制的适应范围"><a href="#熔断机制的适应范围" class="headerlink" title="熔断机制的适应范围"></a>熔断机制的适应范围</h3><p>只要是过载问题的场景， 我们都可以考虑利用熔断机制来解决，不论是分布式系统中服务之间的调用，还是服务与数据 库之间等其他场景的调用</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;熔断&quot;&gt;&lt;a href=&quot;#熔断&quot; class=&quot;headerlink&quot; title=&quot;熔断&quot;&gt;&lt;/a&gt;熔断&lt;/h1&gt;&lt;p&gt;熔断机制：当服务之间发起调用的时候，如果被调用方返回的 指定错误码的比例超过一定的阈值，那么后续的请求将不会真正发起，而是由调用方直接返回错</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>路由选择算法</title>
    <link href="http://example.com/2023/09/22/%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2023/09/22/%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95/</id>
    <published>2023-09-22T13:01:14.000Z</published>
    <updated>2023-09-26T07:53:24.653Z</updated>
    
    <content type="html"><![CDATA[<p>路由选择算法是为了选出从一个点发出的数据报，该如何经过各个路由器，以最小的成本或最快的速度到达目的ip的一种算法，可以理解为图中的最短路径问题。</p><p>一般而言，路由选择算法的一种分类方式是根据该算法是集中式还是分散式来划分。</p><h1 id="集中式还是分散式"><a href="#集中式还是分散式" class="headerlink" title="集中式还是分散式"></a>集中式还是分散式</h1><h2 id="集中式路由选择算法"><a href="#集中式路由选择算法" class="headerlink" title="集中式路由选择算法"></a>集中式路由选择算法</h2><p>该算法以所有节点的连通性以及所有链路的开销为输入，这就要求算法在开始之前获得这些信息。该算法可以在一个集中的控制器或者在每台路由器的路由选择组件中重复进行。</p><p>集中式算法具有关于连通性和链路开销方面的完整信息。具有全局状态信息的算法常被称作链路状态（Link State, LS）算法, 因为该算法必须知道网络中每条链路的开销。</p><h2 id="分散式路由选择算法"><a href="#分散式路由选择算法" class="headerlink" title="分散式路由选择算法"></a>分散式路由选择算法</h2><p>该算法中，路由器以迭代、分布式的方式计算出最低开销路径。没有节点拥有关于所有网络链路开销的完整信息。 相反，每个节点仅有与其直接相连链路的开销知识即可开始工作。</p><p>然后，通过迭代计算过程以及与相邻节点的信息交换，一个节点逐渐计算出到达某目的节点或一组目的节点的最低开销路径。</p><h1 id="静态的还是动态"><a href="#静态的还是动态" class="headerlink" title="静态的还是动态"></a>静态的还是动态</h1><p>路由选择算法的第二种分类是基于算法是静态的还是动态的进行分类。</p><p>在静态路由选择算法（static routing algorithm）中，路由随时间的变化非常缓慢，通常是人工进行调整。</p><p>动态路由选择算法（dynamic routing algorithm） 随着网络流量负载或拓扑发生变化而改变路由选择路径。一个动态算法可周期性地运行或 直接响应拓扑或链路开销的变化而运行。虽然动态算法易于对网络的变化做岀反应，但也 更容易受诸如路由选择循环、路由振荡之类问题的影响。</p><h1 id="负载敏感的还是负载迟钝"><a href="#负载敏感的还是负载迟钝" class="headerlink" title="负载敏感的还是负载迟钝"></a>负载敏感的还是负载迟钝</h1><p>负载敏感算法（load-sensitive algorithm）中，链路开销会动态地变化以反映出底层链路的当前拥塞水平。如果当前拥塞的一条链路与高开销相联系，则路由选择算法趋向于绕开该 拥塞链路来选择路由。</p><p>负载迟钝的并不会选择性的避开。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《计算机网络自顶向下》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;路由选择算法是为了选出从一个点发出的数据报，该如何经过各个路由器，以最小的成本或最快的速度到达目的ip的一种算法，可以理解为图中的最短路径问题。&lt;/p&gt;
&lt;p&gt;一般而言，路由选择算法的一种分类方式是根据该算法是集中式还是分散式来划分。&lt;/p&gt;
&lt;h1 id=&quot;集中式还是分散</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="网络层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>分布式场景下的CAP理论</title>
    <link href="http://example.com/2023/09/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84CAP%E7%90%86%E8%AE%BA/"/>
    <id>http://example.com/2023/09/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84CAP%E7%90%86%E8%AE%BA/</id>
    <published>2023-09-21T06:42:13.000Z</published>
    <updated>2023-09-21T07:44:01.508Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="CAP 理论"></a>CAP 理论</h1><p>CAP理论是关于数据一致性（ C：Consistency ）、服务可用性（ A：Availability ）、分区容错性（ P：Partition-tolerance ）。</p><p>CAP 理论告诉我们，一个分布式系统不可能同时满足数据一致性、服务可用性和分区容错性 这三个基本需求，最多只能同时满足其中的两个。</p><h1 id="一致性（-C-）"><a href="#一致性（-C-）" class="headerlink" title="一致性（ C ）"></a>一致性（ C ）</h1><p>这里的一致性是指强一致性，又叫线性一致性，它要求多节点组成的分布式系统，能像单节点一样运作，如果一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有的读操作都不能读到这个数据。</p><p>一致性中除了强一致性之外，还有其他的一致性级别，比如序列一致性（ Sequential Consistency ）和最终一致性（ Eventual Consistency ）等。</p><h1 id="可用性（-A-）"><a href="#可用性（-A-）" class="headerlink" title="可用性（ A ）"></a>可用性（ A ）</h1><p>可用性指的是要求系统提供的服务必须处于 100% 可用的状态，对于用 户的每一个操作请求，系统总能够在有限的时间内返回结果。</p><h1 id="分区容错性（-P-）"><a href="#分区容错性（-P-）" class="headerlink" title="分区容错性（ P ）"></a>分区容错性（ P ）</h1><p>分区指的是在整个分布式系统中，因为网络原因，系统被分隔成多个单独的部分，这里，不同系统之间在正常情况下应该是一个整体，因为网络原因不能通信才会被划分为不同的分区。在现实的分布式系统中，我们面对的就是一个不可靠的网络和有一定概率宕机的设备，这两个 因素都会导致分区出现，因此在分布式系统实现中，分区容错性 P 是一个必须项。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;CAP-理论&quot;&gt;&lt;a href=&quot;#CAP-理论&quot; class=&quot;headerlink&quot; title=&quot;CAP 理论&quot;&gt;&lt;/a&gt;CAP 理论&lt;/h1&gt;&lt;p&gt;CAP理论是关于数据一致性（ C：Consistency ）、服务可用性（ A：Availability ）</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式锁</title>
    <link href="http://example.com/2023/09/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://example.com/2023/09/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2023-09-19T07:11:08.000Z</published>
    <updated>2023-09-23T13:00:59.883Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>锁存在的意义是为了保证在多CPU，多个线程的环境中，某一个时间点上，只能由一个线程进入临界区代码，从而保证临界区操作数据的一致性。</p><p>进程内的锁，是操作系统直接提供的，对于同一台机器上的多进程，可以直接通过操作系统的锁来实现，只不过是协调了多个进程，需要将锁放在所有进程都可以访问的共享内存中，所有进程通过共享内存中的 锁来进行加锁和解锁。</p><p>但是分布式是在不同机器上，通过操作系统的锁已经无法实现。</p><h1 id="怎么实现分布式锁"><a href="#怎么实现分布式锁" class="headerlink" title="怎么实现分布式锁"></a>怎么实现分布式锁</h1><p>实现分布式锁，需要满足以下几个特性：</p><ol><li><p>互斥：保证不同节点、不同线程的互斥访问。</p></li><li><p>超时机制：即超时设置，防止死锁。因为锁服务和请求锁的服务分散在不同的机器上面，它们之间是通过网络来通信 的，所以我们需要用超时机制，来避免获得锁的节点故障或者网络异常，导致它持有的锁不能 归还，出现死锁的情况。</p><p>同时还要确保留有线程不断延长锁的时间，防止事务还没处理完，而时间到了，导致释放了锁。</p></li><li><p>完备的锁接口：比如说lock接口和trylock接口等。</p></li><li><p>可重入性：即一个节点的一个线程已经获取了锁，那么该节点持有锁的这个线程 可以再次成功获取锁。我们在加锁时，记录好当前获取锁的节点+线程组合的唯一标识，后续如果标识相同，直接返回加锁成功即可，否则按照正常流程处理。</p></li><li><p>公平性：即对于 Lock 接口获取锁失败被阻塞等待的加锁请求，在锁被释放后，如果按 先来后到的顺序，将锁颁发给等待时间最长的一个加锁请求，那么就是公平锁，否则就是非公 平锁。</p></li></ol><h1 id="分布式锁的挑战"><a href="#分布式锁的挑战" class="headerlink" title="分布式锁的挑战"></a>分布式锁的挑战</h1><p>分布式锁面临的挑战有：正确性、高可用和高性能。</p><p>首先考虑进程内的锁，如果一个线程持有锁，只要它不释放，就只有它能操作临界区的资源。同时，因为进程内锁的场景中，不会出现部分失败的情况，所以它崩溃无法释放锁时，会导致整个进程崩溃，不会出现死锁（这里不包括业务逻辑出错而导致的死锁）。</p><p>另一个方面，进程内锁的解锁操作是进程内部的函数调用，这个过程是同步的。只要发起加锁操作，就会成功（这个操作会成功，但是加锁不一定），解锁操作同样。</p><p>当存在多个进程时，加锁操作仍然是函数调用，和上边一样，但是存在一个进程获取锁后崩溃，导致无法释放锁，出现死锁。但是可以通过操作系统来判断一个进程是否存活，并查看它是否获取锁，从而解决问题。</p><p>但是在分布式场景下，发起获取锁的操作需要利用不可靠的网络，意味着发起获取锁的这个操作就有可能失败（这里称为获取锁的时延），而且获取锁后，该进程与服务器通信出现了问题，导致无法释放锁，造成死锁。这就需要设置一个超时时间，如果获取锁的进程超时，就自动释放锁。</p><p>在获取锁的时延上，如果采用超时加心跳，可能会导致服务端给客户端分发了锁，但是由于响应超时，导致客户端以为自己没有获取到锁。</p><p>为了解决这个问题，我们可以在生成锁的时候一并生成一个全局唯一且递增的版本号，当操作共享数据时，会检查版本号，如果出现版本号倒退的现象，则说明出了问题，拒绝该次请求即可。</p><h1 id="分布式锁的权衡"><a href="#分布式锁的权衡" class="headerlink" title="分布式锁的权衡"></a>分布式锁的权衡</h1><p>我们无法保证分布式锁100%的有效，而且正确性要求越高，它的性能会越低。一般来说，会在成本可接受的范围内，提供性能最好的分布式锁服务，如果性能不佳，则需要告知。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;p&gt;锁存在的意义是为了保证在多CPU，多个线程的环境中，某一个时间点上，只能由一个线程进入临界区代码，从而保证临界区操作数据的一</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>负载均衡</title>
    <link href="http://example.com/2023/09/17/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>http://example.com/2023/09/17/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</id>
    <published>2023-09-17T06:18:17.000Z</published>
    <updated>2023-09-22T06:19:23.417Z</updated>
    
    <content type="html"><![CDATA[<h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><p>在分布式的环境下，单个模块往往会部署多个，当调用方通过注册发现组件获得了被调用方的网络地址时，会获得多个地址，这时候就要通过负载均衡组件来确定是调用哪一个具体的组件。</p><p>我们可以根据负载均衡策略是否关心请求中携带的信息，即请求是否有状态，将负载均衡策略分为无状态的负载均衡、半状态的负 载均衡和全状态的负载均衡。</p><h2 id="负载均衡的关键点"><a href="#负载均衡的关键点" class="headerlink" title="负载均衡的关键点"></a>负载均衡的关键点</h2><p>负载均衡需要考虑到各个实例性能差异的情况， 让每一个实例都能充分发挥它的能力，不要出现一些实例负载比较高，而另一些实例的负载却 非常低的情况，这样会造成资源浪费。所以负载均衡的第一个关键点是<strong>公平性</strong>。即要关注被调用服务组之间的公平性，不能旱的旱死，涝的涝死。</p><p>负载均衡需要确保外部对后端服务的请求，一定能被路由到可以提供正确服务的实例上。如果后端是有状态的，那么我们就要考虑在请求上携带状态信息，然后根据状态将请求发送到对应的路由上，所以第二个关键点是<strong>正确性</strong>，即对于有状态的服务来说，负载均 衡需要关心请求的状态，将请求调度到能处理它的后端实例上，不要出现不能处理和错误处理 的情况。</p><h2 id="无状态的负载均衡"><a href="#无状态的负载均衡" class="headerlink" title="无状态的负载均衡"></a>无状态的负载均衡</h2><p>无状态的负载均衡指的是所有后端实例都是对等的，不管请求发送到哪个实力上，都会得到正确的结果，所以无状态的负载均衡不需要关心请求的状态。</p><p>如果这些无状态的实例需要处理像存储数据这种状态，则需要将这些状态信息都交由一个中心存储负责，比如MySQL或者Redis，他们不会在本地磁盘存储任何状态信息。以下是两种具体的方案</p><h3 id="轮询"><a href="#轮询" class="headerlink" title="轮询"></a>轮询</h3><p>轮询的负载均衡策略非常简单，只需要将请求按顺序分配给多个实例，不用再做其他的处理。轮询在路由时，不利用请求的状态信息，属于无状态的负载均衡策略，所以它不能用于有状态 实例的负载均衡器。</p><h3 id="权重轮询"><a href="#权重轮询" class="headerlink" title="权重轮询"></a>权重轮询</h3><p>权重轮询的负载均衡策略是将每一个后端实例分配一个权重，分配请求的数量和实例的权重成 正比轮询。例如有两个实例 A，B，假设我们设置 A 的权重为 20，B 的权重为 80，那么负载 均衡会将 20% 的请求数量分配给 A，80 % 的请求数量分配给 B。</p><h2 id="半状态的负载均衡"><a href="#半状态的负载均衡" class="headerlink" title="半状态的负载均衡"></a>半状态的负载均衡</h2><p>半状态的负载均衡指的是，虽然负载均衡策略利用请求的状态信息进行路由，但是仅仅进行简单的规则处理，比如 Hash 运算加求模来路由请求，它不保证路由的正确性，这个正确性由后端实例来保证。</p><p>一些实例会在内存中存储一些状态数据来提升系统性能，如果一个请求被分配到错误的路由中，可以通过中心存储来读取所需要的数据。</p><p>半状态的负载均衡将请求按一定的策略进行路由，后端实例可以利用路 由规则来进行优化。</p><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>Hash 负载均衡策略是指将请求的状态信息，按一定的 Hash 算法固定分配到一个实例上，例 如，按请求的来源 IP 地址或者用户的 ID，将同一个来源 IP 地址或者用户 ID 的请求固定到一 个实例上。</p><p>存在的问题：如果机器数量发生改变，则请求和实例的分配关系则会发生变化，影响正确性。</p><h3 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h3><p>一致性 Hash可以解决Hash模式下的问题。</p><p>假设Hash环的大小为2^32，那么我们先将0~2^32均匀的分布在Hash环上，然后将所有的实例按照唯一标识来计算他们在环上的位置。</p><p>对于每个请求，也采用同样的方式，都是对2^32取模，然后计算位置。如果该位置没有节点，那么就顺时针往下走，知道找到第一个有节点的位置，该请求就交由该节点执行。</p><p>这样的好处是始终对2^32取模，不管有多少个节点变动，始终不影响结果。</p><h2 id="全状态的负载均衡"><a href="#全状态的负载均衡" class="headerlink" title="全状态的负载均衡"></a>全状态的负载均衡</h2><p>全状态的负载均衡是指，负载均衡策略不仅利用请求的状态信息进行路由，并且在后端实例有 状态的情况下，依然会保证路由的正确性。</p><p>全状态的负载均衡一般以路由服务的形式存在，在路由服务里面，都会存储后端实例 ID 和状 态信息的索引，在进行请求路由的时候，路由服务从请求的状态信息中获得索引的标识，通过 查询索引获得后端实例的 ID，然后再进行路由。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;负载均衡&quot;&gt;&lt;a href=&quot;#负载均衡&quot; class=&quot;headerlink&quot; title=&quot;负载均衡&quot;&gt;&lt;/a&gt;负载均衡&lt;/h1&gt;&lt;p&gt;在分布式的环境下，单个模块往往会部署多个，当调用方通过注册发现组件获得了被调用方的网络地址时，会获得多个地址，这时候就要通过</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>路由器结构</title>
    <link href="http://example.com/2023/09/15/%E8%B7%AF%E7%94%B1%E5%99%A8%E7%BB%93%E6%9E%84/"/>
    <id>http://example.com/2023/09/15/%E8%B7%AF%E7%94%B1%E5%99%A8%E7%BB%93%E6%9E%84/</id>
    <published>2023-09-15T06:19:49.000Z</published>
    <updated>2023-09-21T06:41:23.193Z</updated>
    
    <content type="html"><![CDATA[<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><h1 id="路由器结构"><a href="#路由器结构" class="headerlink" title="路由器结构"></a>路由器结构</h1><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230511101229903.png" alt="image-20230511101229903" style="zoom:80%;" /><p>路由器由输入端口，交换结构，路由选择处理器以及输出端口组成。输入端口负责接收数据报，并且在这里决定好要怎么进行转发，然后经过交换结构，到达输出端口。即在输入端口这里已经找到了他的下一跳的地址，然后传送给交换结构，交换结构只需要根据数据去找对应的输出端口即可，可以大大减小路由表的大小。</p><p>而具体怎么找到该送往那个端口，最简单的是做一个map，包含了所有的映射，但是由于映射数量达到上百亿，不可取。另一种方案是：根据最长前缀匹配，比如说0000发网接口0，0001发网接口1，以此类推。</p><p>这里，输入端口查找的是数据报目的的ip，可能需要经过多个路由器来进行转发，才能到达目地地址。</p><h1 id="交换"><a href="#交换" class="headerlink" title="交换"></a>交换</h1><p>交换技术有三种，经内存的交换，经总线交换，互联网络交换。</p><h2 id="经内存的交换"><a href="#经内存的交换" class="headerlink" title="经内存的交换"></a>经内存的交换</h2><p>这种方案下，输入端口和输出端口的功能有点像传统操作系统中的I&#x2F;O，当一个分组到达端口，改端口通过中断向路由选择处理器发送信号，然后将分组复制到处理器内存当中，路由选择器从分组的首部提取到目的地址，在转发表找适当的输出端口，再将该分组复制到输出端口的缓存当中。</p><h2 id="经总线交换"><a href="#经总线交换" class="headerlink" title="经总线交换"></a>经总线交换</h2><p>这种方案下，输入端口经一根总线将分组直接发送到输出端口，不需要路由选择处理器的干预。这种方案下，输入端口需要预先计划一个交换机内部标签，指示本地输出端口，该分组可以由所有输出端口接受，但是只有标签匹配的才会保留，标签在输出端口被去除。单一总线会对性能造成影响</p><h2 id="经互联网络交换"><a href="#经互联网络交换" class="headerlink" title="经互联网络交换"></a>经互联网络交换</h2><p>这种方案是用2N条总线连接输入和输出端口，总线可以通过交换设备自由闭合，比如A发往X的数据，可以调整只打开A和X，但是如果有多个数据报都发往X，那么在X之前还是需要排队。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《计算机网络自顶向下》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;结构&quot;&gt;&lt;a href=&quot;#结构&quot; class=&quot;headerlink&quot; title=&quot;结构&quot;&gt;&lt;/a&gt;结构&lt;/h1&gt;&lt;h1 id=&quot;路由器结构&quot;&gt;&lt;a href=&quot;#路由器结构&quot; class=&quot;headerlink&quot; title=&quot;路由器结构&quot;&gt;&lt;/a&gt;路由器结</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="网络层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>如何保证幂等</title>
    <link href="http://example.com/2023/09/14/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%B9%82%E7%AD%89/"/>
    <id>http://example.com/2023/09/14/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%B9%82%E7%AD%89/</id>
    <published>2023-09-14T04:05:29.000Z</published>
    <updated>2023-09-22T06:19:49.491Z</updated>
    
    <content type="html"><![CDATA[<p> 考虑如下问题：在一个电商系统中，如果用户下单后，在模块之间及逆行远程调用的过程中，出现了问题，给用户响应了请求超时，那么会影响到用户购买，导致损失订单。</p><p>但是，如果对请求超时进行重试，那么会导致用户重复下单，用户明明点击了一次，却显示购买了两次，导致一些问题。</p><p>这里就涉及到了一个问题，接口的幂等性，即不管执行几次，它的影响都和执行一次一样。</p><h1 id="如何保证Exactly-once"><a href="#如何保证Exactly-once" class="headerlink" title="如何保证Exactly-once"></a>如何保证Exactly-once</h1><p>不能保证 Exactly-once 的原因主要有两个，一个是网络出现丢包或者分区等故障，另一个是远端服务发生了故障。</p><p>一般来说，在分布式系统中，实现消息的 Exactly-once 传递，主要有三种方式：一种是至少一次消息传递加消息幂等性，一种是分布式快照加状态回滚，一种是整体重做。</p><h2 id="一次传递加幂等"><a href="#一次传递加幂等" class="headerlink" title="一次传递加幂等"></a>一次传递加幂等</h2><p>该思路比较简单，就是当处理失败后，并不给用户返回请求超时，而是进行重试，保证至少请求一次成功，然后每次请求带上一个全局的唯一id，当失败重试的时候，该id并不会发生改变，成功后，将本次请求保存在数据库中，如果第二次发现该id后，并不会执行，直接返回。</p><h2 id="分布式快照加回滚"><a href="#分布式快照加回滚" class="headerlink" title="分布式快照加回滚"></a>分布式快照加回滚</h2><p>分布式快照加状态回滚指的是，在整个分布式系统运行的过程中，定期对整个系统的状态做快照，在系统运行时，不论系统的哪个地方出现故障，就将整个系统回滚到上一个快照状态，然 后再重放上一个快照状态之后的情况，直到所有的消息都被正常处理。</p><p>但是该方式并不适合在线业务，因为对在线业务做快照很难，而且对整个系统做快照，耗费资源，而且做快照的时候会导致当前系统不可处理新的业务。</p><p>该方案只适合针对于像流式计算的场景。</p><h2 id="整体重做"><a href="#整体重做" class="headerlink" title="整体重做"></a>整体重做</h2><p>整体重做的 Exactly-once 的方式，可以看成是分布式快照加状态回滚的一种特殊情况。</p><h1 id="Exactly-once-的挑战"><a href="#Exactly-once-的挑战" class="headerlink" title="Exactly-once 的挑战"></a>Exactly-once 的挑战</h1><h2 id="重试面临的挑战"><a href="#重试面临的挑战" class="headerlink" title="重试面临的挑战"></a>重试面临的挑战</h2><p>当采用重试策略来保证消息最少传递一次时，我们需要限制重试的次数，来确保不会因为重试导致系统雪崩。而且重试的时间间隔也会因为重试的次数而增加。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入浅出分布式技术原理》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 考虑如下问题：在一个电商系统中，如果用户下单后，在模块之间及逆行远程调用的过程中，出现了问题，给用户响应了请求超时，那么会影响到用户购买，导致损失订单。&lt;/p&gt;
&lt;p&gt;但是，如果对请求超时进行重试，那么会导致用户重复下单，用户明明点击了一次，却显示购买了两次，导致一些问题</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务</title>
    <link href="http://example.com/2023/09/13/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2023/09/13/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2023-09-13T09:08:11.000Z</published>
    <updated>2023-09-20T08:55:32.169Z</updated>
    
    <content type="html"><![CDATA[<p>分布式事务的实现，一般有三种方案：</p><ol><li>基于 XA 协议的二阶段提交协议方法； </li><li>三阶段提交协议方法； </li><li>基于消息的最终一致性方法</li></ol><h1 id="基于-XA-协议的二阶段提交方法"><a href="#基于-XA-协议的二阶段提交方法" class="headerlink" title="基于 XA 协议的二阶段提交方法"></a>基于 XA 协议的二阶段提交方法</h1><p>XA是一个分布式事务协议，规定了事务管理器和资源管理器接口，可以分为两部分：<strong>事务管理器</strong>和<strong>本地资源管理器</strong>。</p><p>大致原理是：事务管理器作为协调者，负责各个本地资源的提交和回滚，而资源管理器就是分布式事务的参与者，通常由数据库实现。</p><p>基于 XA 协议的二阶段提交方法中，二阶段提交协议（The two-phase commit protocol，2PC），用于保证分布式系统中事务提交时的数据一致性，是 XA 在全局事务中用于协调多个资源的机制。</p><h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h2><p>投票为第一阶段，协调者会向事务的参与者发起执行操作的请求，允许他们发起提交，参与者收到请求后，会执行请求中的事务，记录日志信息但不提交，待参与者执行成功后，向协调者发送yes表示同意操作，若不成功，则发送no，表示终止。</p><p>当所有的参与者都返回了yes或者no信息后，才会进入提交阶段。</p><p>在该阶段，如果所有的参与者都发送的是yes，那么协调者将通知所有参与者提交事务，参与者收到通知后，才会完成剩下的操作。如果有一个参与者提交了no，那么所有的参与者都无法提交该事务。</p><p>不足：</p><ol><li>同步阻塞问题：该算法执行过程中，所有参与者未收到协调者信息的情况下，都处于事务阻塞状态，如果占用临界资源，则其他系统也无法。</li><li>单点故障问题：如果资源管理器发生了故障，那么整个系统就会处于停滞状态。</li><li>数据不一致问题：在提交阶段，如果协调者给参与者发送确认提交的信息时网络异常，会导致一部分参与者无法提交事务，而导致数据不一致。</li></ol><h2 id="三阶段提交"><a href="#三阶段提交" class="headerlink" title="三阶段提交"></a>三阶段提交</h2><p>三阶段提交是对二阶段提交的改进，为了防止数据不一致以及同步阻塞问题，引入了超时机制和准备阶段。如果参与者或者协调者在规定的时间内没有收到信息，则选择提交或者终止整个事务。</p><p>在第一阶段和第二阶段中间引入了一个准备阶段，也就是在提交阶段之前，加入了一个预 提交阶段。在预提交阶段排除一些不一致的情况，保证在最后提交之前各参与节点的状态是一致的。</p><p>也就是说变为了三个阶段：可以提交，预提交，和提交。</p><p>可以提交和之前的一样，不过多阐述。</p><p>而<strong>预提交</strong>是协调者根据参与者的状态来决定是否可以预提交，如果所有参与者都回复yes，协调者就会执行事务的预执行：</p><p>首先是发送预提交请求，然后参与者收到后，执行事务操作，并记录Undo和Redo信息记录到事务日志，之后，参与者如果执行成功，则返回ACK响应，同时开始等待最终指令。</p><p>到了正式提交，才是真正的提交具体的事务。</p><p>不管是二阶段还是三阶段提交，都无法解决性能低，包括数据出现不一致的情况。</p><h1 id="基于分布式消息的最终一致性方案"><a href="#基于分布式消息的最终一致性方案" class="headerlink" title="基于分布式消息的最终一致性方案"></a>基于分布式消息的最终一致性方案</h1><p>这个就是引入了一个中间件，比如消息队列，用于存储消息，比如日志或者消息可以存进来，异步的去进行执行，来达到数据最终的一致性，中间还是会有部分时间的不一致。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《分布式技术原理与算法解析》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;分布式事务的实现，一般有三种方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于 XA 协议的二阶段提交协议方法； &lt;/li&gt;
&lt;li&gt;三阶段提交协议方法； &lt;/li&gt;
&lt;li&gt;基于消息的最终一致性方法&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;基于-XA-协议的二阶段提交方法&quot;&gt;&lt;a hr</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式下如何访问共享资源</title>
    <link href="http://example.com/2023/09/11/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E8%AE%BF%E9%97%AE%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90/"/>
    <id>http://example.com/2023/09/11/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E8%AE%BF%E9%97%AE%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90/</id>
    <published>2023-09-11T08:01:48.000Z</published>
    <updated>2023-09-20T08:25:56.617Z</updated>
    
    <content type="html"><![CDATA[<p>互斥资源指的是那种一次只可以一个系统访问的资源。</p><h1 id="集中式算法"><a href="#集中式算法" class="headerlink" title="集中式算法"></a>集中式算法</h1><p>该算法需要借助于一个第三方软件，或者说一个数据中心，每当有系统需要访问互斥资源时，需要先该数据中心发送请求，看是否其他的系统请求该资源。然后数据中心给系统返回是否可以访问该资源，如果同意，则系统访问互斥资源。</p><p>存在的问题：数据中心容易成为瓶颈，所有的系统都要请求数据中心，如果数据中心出现阻塞或者不可用，则有可能导致整个系统不可用。</p><h1 id="民主协商：分布式算法"><a href="#民主协商：分布式算法" class="headerlink" title="民主协商：分布式算法"></a>民主协商：分布式算法</h1><p>在该算法下，如果要访问互斥资源，则采用互相通信的形式，比如说现在有A，B，C，D四个系统，其中A想要访问某资源，它会向B，C，D三个系统发送请求，询问是否有人需要使用该资源。如果没有，则A访问该资源。假如D此时也想要访问该资源，则A，B，C会收到请求，而B，C即收到了A的请求，也受到了D的请求，由于A先到，所以会优先允许A访问资源。</p><p>而不同系统的请求会被放入一个队列当中，依次允许访问共享资源。</p><p>缺点：如果系统特别多，则访问一次资源所要发送的广播信息会消耗大量的资源，导致一定的浪费。而且部分节点可能不可用，导致一直处于等待，该问题的解决办法是忽略下线了的节点。</p><h1 id="轮值-CEO：令牌环算法"><a href="#轮值-CEO：令牌环算法" class="headerlink" title="轮值 CEO：令牌环算法"></a>轮值 CEO：令牌环算法</h1><p>该算法是产生一个令牌，令牌依次传递给每一个系统，拿到该令牌的系统，如果有访问共享资源的需求，则它可以访问共享资源，否则无法访问共享资源。</p><p>缺点：降低了系统的实时性。比如说有100个系统，系统1访问完共享资源后，其他99个系统无需访问共享资源，但令牌仍然需要转一圈才能到达系统1这里。而且令牌的传递需要忽略已经下线了的节点。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《分布式技术原理与算法解析》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;互斥资源指的是那种一次只可以一个系统访问的资源。&lt;/p&gt;
&lt;h1 id=&quot;集中式算法&quot;&gt;&lt;a href=&quot;#集中式算法&quot; class=&quot;headerlink&quot; title=&quot;集中式算法&quot;&gt;&lt;/a&gt;集中式算法&lt;/h1&gt;&lt;p&gt;该算法需要借助于一个第三方软件，或者说一个数据中心，</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>数据分区再平衡</title>
    <link href="http://example.com/2023/09/09/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1/"/>
    <id>http://example.com/2023/09/09/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1/</id>
    <published>2023-09-09T07:08:52.000Z</published>
    <updated>2023-09-20T04:06:10.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分区再平衡"><a href="#分区再平衡" class="headerlink" title="分区再平衡"></a>分区再平衡</h1><h2 id="采用取余的坏处"><a href="#采用取余的坏处" class="headerlink" title="采用取余的坏处"></a>采用取余的坏处</h2><p>如果采用取模的话，新添加节点或者删除节点，都有可能导致分区中的数据进行移动，最简单的例子，之前有10个节点，那么分区1000计算方法为1000%10 &#x3D; 0，就在第0个分区，如果此时添加一个新的节点，变为了1000%11 &#x3D; 10，此时就要将之前存在于下标为0的节点数据重新分配到下标为10的节点，导致性能损失。</p><h2 id="固定分区数量"><a href="#固定分区数量" class="headerlink" title="固定分区数量"></a>固定分区数量</h2><p>改策略是指提前规定好分区有多少个，比如说提前固定分区有1000个，然后当前有10个节点，那么每个节点就存在100个分区。这样做的好处就在于，如果存在新添加的节点，那么只需要将之前节点中存在的分区划分给新节点即可，如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230913151508491.png" alt="image-20230913151508491" style="zoom:67%;" /><p>这样可以避免采用取余的坏处，并不需要频繁的移动每个分区的数据。</p><h2 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h2><p>如果之前的分区不是很合理，导致了一个分区中存在大量的数据，而其他分区几乎是空的，就可以利用到动态分区。</p><p>他的设计方式如下：提前设置一个阈值，当某一个分区达到该值之后，就会将该分区拆分为两个分区，如果某些分区数据特别少，那么就会将相邻的两个分区进行合并。该过程类似于B树的分裂或者合并。</p><p>它的一个优点是分区数量可以自适应数据的总量，但是在一个空数据库中，一开始可能只有一个分区，当道达分裂点后，后续的写入可能还是会在一个分区中进行。</p><h2 id="按节点比例分区"><a href="#按节点比例分区" class="headerlink" title="按节点比例分区"></a>按节点比例分区</h2><p>该分区方式中，每个节点有固定数量的分区。</p><p>当节点数量不变时，每个分区的大小与数据集的大小成正比，当节点数增加时，分区则会调整变得更小。</p><p>当一个新的节点加入分区时，随机选择固定数量的分区进行分裂，然后拿走这些分区一半的数据量。</p><h1 id="路由发现"><a href="#路由发现" class="headerlink" title="路由发现"></a>路由发现</h1><p>当数据被分散到多个节点上时，我们读取数据的时候，如何知道我们想要的数据在哪里，这始终是一个问题，该问题也称为服务发现。</p><p>解决办法有以下三种：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230913155735479.png" alt="image-20230913155735479"></p><p>而该过程中，可能需要一些其他的第三方软件，比如Zookeeper。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230913155838336.png" alt="image-20230913155838336"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《数据密集型系统设计》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分区再平衡&quot;&gt;&lt;a href=&quot;#分区再平衡&quot; class=&quot;headerlink&quot; title=&quot;分区再平衡&quot;&gt;&lt;/a&gt;分区再平衡&lt;/h1&gt;&lt;h2 id=&quot;采用取余的坏处&quot;&gt;&lt;a href=&quot;#采用取余的坏处&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="分布式设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>如何实现高性能延时消息</title>
    <link href="http://example.com/2023/09/06/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF/"/>
    <id>http://example.com/2023/09/06/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF/</id>
    <published>2023-09-06T02:37:47.000Z</published>
    <updated>2023-09-06T03:14:36.965Z</updated>
    
    <content type="html"><![CDATA[<h1 id="延时消息使用场景"><a href="#延时消息使用场景" class="headerlink" title="延时消息使用场景"></a>延时消息使用场景</h1><p>需要某些事件在特定的时间点上触发时，就需要用到延时消息。</p><h1 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h1><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906104126430.png" alt="image-20230906104126430"></p><p>延时消息可以通过定时扫描来实现，但是资源浪费太多。</p><p>如果使用消息队列，可以理解为生产者生产一条消息，但是并不会被消费者看到，当到达固定的时间点后，消费者才能够看到并且消费消息。所以从技术上来看，消息队列实现延时消息主要包含<strong>数据存储、如何让消息可见、定时机制、主动推送</strong>四个部分。</p><p>以下主要介绍<strong>消息可见</strong>和<strong>定时机制</strong>。</p><h2 id="如何让消息可见"><a href="#如何让消息可见" class="headerlink" title="如何让消息可见"></a>如何让消息可见</h2><p>让消息从不可见变为可见的思路：先将数据写入到临时存储，然后根据一定机制在数据到期后让消费端可以看到该消息。</p><p>临时存储大多有以下三种选择：</p><ol><li><p>单独设计的数据结构</p></li><li><p>独立的 Topic</p></li><li><p>本地的某个存储引擎（如 RocksDB、Mnesia 等）</p></li></ol><p>延时到期后，消费者如何得知该消息可以消费，有以下两种实现：</p><ol><li>定时检测写入</li><li>消费时判断是否可见</li></ol><p>定时检测写入：指的是先将消息写入某个地方，同时有独立的线程去判断数据是否到期，如果到期则将数据写入真正的存储当中。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906104734666.png" alt="image-20230906104734666"></p><p>消费时判断数据是否可见：是指每次消费时判断是否有到期的延时消息，如果有则从第三方存储中拉取，供消费者消费。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906104931264.png" alt="image-20230906104931264"></p><p>实际上，大多采用第一种方案。因为每次消费时都去判断一下是否有消息可见，则会对性能造成一定的影响。</p><h2 id="定时机制的实现"><a href="#定时机制的实现" class="headerlink" title="定时机制的实现"></a>定时机制的实现</h2><p>定时机制的核心：随着时间的推移，拿出到期的延时消息进行处理。从技术上看，定时机制可以拆解为<strong>定时器</strong>和<strong>延时消息定位处理</strong>两部分。</p><p>定时器就是按照时间推进，说白了就是记录一下时间。</p><p>延时消息定位是指随着定时器的推进，在每个时间刻度可以高效定位，获取到该时刻需要处理的延时消息。</p><h1 id="延时消息的技术方案"><a href="#延时消息的技术方案" class="headerlink" title="延时消息的技术方案"></a>延时消息的技术方案</h1><p>延时消息的实现主要有基于轮询检测机制的实现和基于时间轮机制的实现两种方案。</p><h2 id="基于轮询检测机制的实现"><a href="#基于轮询检测机制的实现" class="headerlink" title="基于轮询检测机制的实现"></a>基于轮询检测机制的实现</h2><p>核心思路：将消息写入到独立的存储当中，利用类似于while + sleep的定时器，来推进时间，通过独立线程检测数据是否到期，然后取出到期数据，存入正式存储。</p><p>我们可以将独立存储根据时间划分，大致结构如下：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906110914110.png" alt="image-20230906110914110"></p><p>这样可以减小每个队列的长度。而每个队列采用什么结构，则可以根据实际的应用场景决定。</p><h2 id="基于时间轮机制的实现"><a href="#基于时间轮机制的实现" class="headerlink" title="基于时间轮机制的实现"></a>基于时间轮机制的实现</h2><p>核心思路：将延时消息写入到独立的存储中，然后通过构建多级时间轮，在每个时间刻度上挂载需要处理的延时消息的索引列表。再依赖时间轮的推进，获取到需要处理的延时消息列表，进行后续的处理。</p><p>时间轮是一个很成熟的算法，分为<strong>单级时间轮</strong>和<strong>多级时间轮</strong>，具体结构如下：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230906111154935.png" alt="image-20230906111154935"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;延时消息使用场景&quot;&gt;&lt;a href=&quot;#延时消息使用场景&quot; class=&quot;headerlink&quot; title=&quot;延时消息使用场景&quot;&gt;&lt;/a&gt;延时消息使用场景&lt;/h1&gt;&lt;p&gt;需要某些事件在特定的时间点上触发时，就需要用到延时消息。&lt;/p&gt;
&lt;h1 id=&quot;如何实现&quot;</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消息队列分布式限流方案</title>
    <link href="http://example.com/2023/09/01/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81%E6%96%B9%E6%A1%88/"/>
    <id>http://example.com/2023/09/01/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81%E6%96%B9%E6%A1%88/</id>
    <published>2023-09-01T12:09:16.000Z</published>
    <updated>2023-09-01T12:15:10.618Z</updated>
    
    <content type="html"><![CDATA[<h1 id="限流分类"><a href="#限流分类" class="headerlink" title="限流分类"></a>限流分类</h1><p>1、单机限流</p><p>限制每一台broker的流量，如下图所示：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230901201114249.png" alt="image-20230901201114249"></p><p>2、全局限流</p><p>限制所有broker的流量和，这种方案往往需要一个第三方的平台来统计目前所有Broker的总流量，如下图所示：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230901201158231.png" alt="image-20230901201158231"></p><h1 id="对什么限流"><a href="#对什么限流" class="headerlink" title="对什么限流"></a>对什么限流</h1><p>主要对流量、连接数、请求数三类资源进行限流。</p><p><strong>流量限制</strong>指对生产、消费的流量限制。</p><p><strong>连接数限制</strong>指对客户端连接到服务端的 TCP 连接数量进行限制。因为 TCP 连接的建立和关闭需要消耗 CPU、内存等资源，限制是为了保护服务端不会因为连接数太多，耗尽资源，导致服务不可用，主要从一下三个方面：</p><ul><li><p>服务端单机可承载的最大连接数限制。</p></li><li><p>客户端单个 IP 可建立的连接数。</p></li><li><p>单个集群可建立的总链接数。</p></li></ul><p><strong>请求数限制</strong>指对单个接口的访问频次进行限制，来保护集群自身的可用性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;限流分类&quot;&gt;&lt;a href=&quot;#限流分类&quot; class=&quot;headerlink&quot; title=&quot;限流分类&quot;&gt;&lt;/a&gt;限流分类&lt;/h1&gt;&lt;p&gt;1、单机限流&lt;/p&gt;
&lt;p&gt;限制每一台broker的流量，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/09/Java/Mybatis%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A4%8D%E6%9D%82%E5%86%99%E6%B3%95/"/>
    <id>http://example.com/2023/08/09/Java/Mybatis%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A4%8D%E6%9D%82%E5%86%99%E6%B3%95/</id>
    <published>2023-08-09T05:16:01.853Z</published>
    <updated>2023-08-09T06:33:13.794Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Mybatis的一些复杂写法"><a href="#Mybatis的一些复杂写法" class="headerlink" title="Mybatis的一些复杂写法"></a>Mybatis的一些复杂写法</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 这里拿到的是key</span><br><span class="line">&lt;foreach collection=<span class="string">&quot;columns.keys&quot;</span> item=<span class="string">&quot;key&quot;</span> separator=<span class="string">&quot;,&quot;</span> open=<span class="string">&quot;(&quot;</span> close=<span class="string">&quot;)&quot;</span>&gt;</span><br><span class="line">    #&#123;key&#125;</span><br><span class="line">&lt;/foreach&gt;</span><br><span class="line"># 这里拿到的也是value</span><br><span class="line">&lt;foreach collection=<span class="string">&quot;columns.keys&quot;</span> item=<span class="string">&quot;key&quot;</span> separator=<span class="string">&quot;,&quot;</span> open=<span class="string">&quot;(&quot;</span> close=<span class="string">&quot;)&quot;</span>&gt;</span><br><span class="line">    #&#123;columns[$&#123;key&#125;]&#125;</span><br><span class="line">&lt;/foreach&gt;</span><br><span class="line"># 这里拿到的是value</span><br><span class="line">&lt;foreach collection=<span class="string">&quot;columns.values&quot;</span> item=<span class="string">&quot;key&quot;</span> separator=<span class="string">&quot;,&quot;</span> open=<span class="string">&quot;(&quot;</span> close=<span class="string">&quot;)&quot;</span>&gt;</span><br><span class="line">    #&#123;key&#125;</span><br><span class="line">&lt;/foreach&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Mybatis的一些复杂写法&quot;&gt;&lt;a href=&quot;#Mybatis的一些复杂写法&quot; class=&quot;headerlink&quot; title=&quot;Mybatis的一些复杂写法&quot;&gt;&lt;/a&gt;Mybatis的一些复杂写法&lt;/h1&gt;&lt;figure class=&quot;highlight </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Java开发分布式系统的编码技巧</title>
    <link href="http://example.com/2023/08/07/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Java%E5%BC%80%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BC%96%E7%A0%81%E6%8A%80%E5%B7%A7/"/>
    <id>http://example.com/2023/08/07/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Java%E5%BC%80%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BC%96%E7%A0%81%E6%8A%80%E5%B7%A7/</id>
    <published>2023-08-07T01:58:48.000Z</published>
    <updated>2023-08-07T02:55:28.177Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PageCache-调优和-Direct-IO"><a href="#PageCache-调优和-Direct-IO" class="headerlink" title="PageCache 调优和 Direct IO"></a>PageCache 调优和 Direct IO</h1><p>应用程序读取文件，会经过应用缓存、PageCache、DISK（硬盘）三层。</p><p>Linux内核读取到文件数据后，会把它缓存一段时间，这个文件缓存就是PageCache。它会进行适当的预读，比如用户当前只需要读取1kb的文件，但是它的算法觉得读取16k或者更多更合适，那么它就会读取16kb，加载到PageCache中，下次读取先去PageCache中查找。</p><p>但是以下三种情况没法使用PageCache：</p><ol><li><p>使用 FIleChannel 读写时，底层可能走 Direct IO，不走页缓存。</p></li><li><p>在内存有限或者不够用的时候，频繁换页，导致缓存命中率低。</p></li><li><p>大量随机读的场景，导致页缓存的数据无法命中。</p></li></ol><p>一种解决思路是：<strong>通过使用Direct IO 来模拟实现PageCahce的效果</strong>。原先PageCache的底层实现，是由操作系统实现的，比如说数据加载，缓存命中，换页，刷盘等，我们无法控制。我们可以通过自定义 Cache + Direct IO 来实现自己可控的操作。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230807102215994.png" alt="image-20230807102215994"></p><h1 id="FileChannel-和-mmap"><a href="#FileChannel-和-mmap" class="headerlink" title="FileChannel 和 mmap"></a>FileChannel 和 mmap</h1><p>Java 原生的 IO 主要可以分为普通 IO、FileChannel（文件通道）、mmap（内存映射）三种。</p><p>java.io 包中的 FileWriter 和 FileReader 属于普通 IO，java.nio 包中的 FileChannel 属于 NIO 的一种，mmap 是调用 FileChannel.map() 实例出来的一种特殊读写文件的方式，被称为内存映射。</p><h2 id="FileChannel"><a href="#FileChannel" class="headerlink" title="FileChannel"></a>FileChannel</h2><p><strong>FileChannel 大多数时候是和 ByteBuffer 打交道的</strong>，ByteBiffer是byte[]的一个封装类，ByteBuffer 是在应用内存中的，它和硬盘之间还隔着一层 PageCache。从使用上看，我们通过 filechannel.write 写入数据时，会将数据从应用内存写入到 PageCache，此时便认为完成了落盘操作。但实际上，操作系统最终帮我们将 PageCache 的数据自动刷到了硬盘。</p><h2 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h2><p>mmap 是一个把文件映射到内存的操作，因此可以像读写内存一样读写文件。它省去了用户空间到内核空间的数据复制过程，从而提高了读写性能。</p><p>从经验来看，mmap 在内存充足、数据文件较小且相对固定的场景下，性能比 FileChannel 高。<strong>但它有这样几个缺点：</strong></p><ol><li><p>使用时必须先指定好内存映射的大小，并且一次 Map 的大小限制在 1.5G 左右。</p></li><li><p>是由操作系统来刷盘的，手动刷盘时间不好掌握。</p></li><li><p>回收非常复杂，需要手动释放，并且代码和实现很复杂。</p></li></ol><p>在消息队列数据文件分段的场景下，因为每个段文件的大小是固定的，且大小还是可配置的，所以是可以使用 mmap 来提高性能的。</p><h1 id="直接内存（堆外）和堆内内存"><a href="#直接内存（堆外）和堆内内存" class="headerlink" title="直接内存（堆外）和堆内内存"></a>直接内存（堆外）和堆内内存</h1><p>堆内和堆外的堆是指 JVM 堆，堆内内存就是指 JVM 堆内部的内存空间，堆外就是指除了 JVM 堆以外的内存空间。堆内内存加上堆外内存等于总内存。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230807103548870.png" alt="image-20230807103548870" style="zoom:80%;" /><p>如何选择堆外内存和堆内内存：</p><ol><li>当需要申请大块的内存时，堆内内存会受到限制，可以尝试分配堆外内存</li><li>堆外内存适用于生命周期中等或较长的对象</li><li>堆内内存刷盘的过程中，还需要复制一份到堆外内存，多了一步，会降低性能</li><li>创建堆外内存的消耗要大于创建堆内内存的消耗，所以当分配了堆外内存之后，要尽可能复用它</li><li>可以使用池化 + 堆外内存的组合方式，比如代码中如果需要频繁  new byte[]，就可以研究一下 ThreadLocal 和  ThreadLocal&lt;byte[]&gt; 的使用机制。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PageCache-调优和-Direct-IO&quot;&gt;&lt;a href=&quot;#PageCache-调优和-Direct-IO&quot; class=&quot;headerlink&quot; title=&quot;PageCache 调优和 Direct IO&quot;&gt;&lt;/a&gt;PageCache 调优和 Dir</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="Java" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Java/"/>
    
    <category term="并发" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Java/%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ的设计</title>
    <link href="http://example.com/2023/07/24/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ%E7%9A%84%E8%AE%BE%E8%AE%A1/"/>
    <id>http://example.com/2023/07/24/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ%E7%9A%84%E8%AE%BE%E8%AE%A1/</id>
    <published>2023-07-24T12:16:13.000Z</published>
    <updated>2023-07-24T12:42:32.898Z</updated>
    
    <content type="html"><![CDATA[<p>下图是RabbitMQ的系统架构：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724201809821.png" alt="image-20230724201809821"></p><p>RabbitMQ 由 Producer、Broker、Consumer 三个大模块组成。</p><p>生产者将数据发送到 Broker，Broker 接收到数据后，将数据存储到对应的 Queue 里面，消费者从不同的 Queue 消费数据。它有 Exchange、Bind、Route 这几个独有的概念。</p><p>Exchange 称为交换器，它是一个逻辑上的概念，用来做分发，本身不存储数据。流程上生产者先将消息发送到 Exchange，而不是发送到数据的实际存储单元 Queue 里面。然后 Exchange 会根据一定的规则将数据分发到实际的 Queue 里面存储。</p><p>这个分发过程就是 Route（路由），设置路由规则的过程就是 Bind（绑定）。即 Exchange 会接收客户端发送过来的 route_key，然后根据不同的路由规则，将数据发送到不同的 Queue 里面。</p><h1 id="协议和网络模块"><a href="#协议和网络模块" class="headerlink" title="协议和网络模块"></a>协议和网络模块</h1><p>在网络通信协议层面，RabbitMQ 数据流是基于四层 TCP 协议通信的，跑在 TCP 上的应用层协议是 AMQP。</p><p>RabbitMQ 的网络层有 Connectoion 和 Channel 两个概念需要注意。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724202241340.png" alt="image-20230724202241340"></p><p>Connection 是指 TCP 连接，Channel 是 Connection 中的虚拟连接。两者的关系是：一个客户端和一个 Broker 之间只会建立一条 TCP 连接，就是指 Connection。Channel（虚拟连接）的概念在这个连接中定义，一个 Connection 中可以创建多个 Channel。</p><p><strong>客户端和服务端的实际通信都是在 Channel 维度通信的。</strong></p><p>RabbitMQ 服务端通过 tcp_listener 监听端口，tcp_acceptor 接收请求，rabbit_reader 处理和返回请求。本质上来看是也是一个多线程的网络模型。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724202504119.png" alt="image-20230724202504119"></p><h1 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h1><p>RabbitMQ 的存储模块也包含元数据存储与消息数据存储两部分。RabbitMQ 的两类数据都是存储在 Broker 节点上的。</p><h2 id="元数据存储"><a href="#元数据存储" class="headerlink" title="元数据存储"></a>元数据存储</h2><p>RabbitMQ 的元数据都是存在于 Erlang 自带的分布式数据库 Mnesia 中的。即每台 Broker 都会起一个 Mnesia 进程，用来保存一份完整的元数据信息。Mnesia是一个分布式数据库，自带了多节点自动同步机制。</p><h2 id="消息数据存储"><a href="#消息数据存储" class="headerlink" title="消息数据存储"></a>消息数据存储</h2><p>RabbitMQ 消息数据的最小存储单元是 Queue，即消息数据是按顺序写入存储到 Queue 里面的。</p><p>在底层的数据存储方面，所有的 Queue 数据是存储在同一个“文件”里面的。这个“文件”是一个虚拟的概念，表示所有的 Queue 数据是存储在一起的意思。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724202717072.png" alt="image-20230724202717072"></p><p>这个“文件”由队列索引（rabbit_queue_index）和消息存储（rabbitmq_msg_store）两部分组成。即在节点维度，所有 Queue 数据都是存储在 rabbit_msg_store 里面的，每个节点上只有一个 rabbit_msg_store，数据会依次顺序写入到 rabbit_msg_store 中。</p><p>rabbit_msg_store 是一个逻辑概念，底层的实际存储单元分为两个，msg_store_persistent 和 msg_store_transient，分别负责持久化消息和非持久化消息的存储。</p><p>这里所有的消息都会以追加的形式写入一个文件当中，当一个文件的大小超过了配置的最大大小，就会新开一个文件来存储。</p><p>队列索引负责存储、维护队列中落盘消息的信息，包括消息的存储位置、是否交付、是否 ACK 等等信息。队列索引是 Queue 维度的，每个 Queue 都有一个对应的队列索引。</p><p>删除消息时，不会立即删除数据，只是从 Erlang 中的 ETS 表删除指定消息的相关信息，同时更新消息对应的存储文件的相关信息。此时文件中的消息不会立即被删除，会被标记为已删除数据，直到一个文件中都是可以删除的数据时，再将这个文件删除，这个动作就是常说的延时删除。另外内核有检测机制，会检查前后两个文件中的数据是否可以合并，当符合合并规则时，会进行段文件的合并。</p><h1 id="生产者和消费者"><a href="#生产者和消费者" class="headerlink" title="生产者和消费者"></a>生产者和消费者</h1><p>当生产者和消费者连接到 Broker 进行生产消费的时候，是直接和 Broker 交互的，不需要客户端寻址。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724203444673.png" alt="image-20230724203444673" style="zoom:80%;" /><p>RabbitMQ 集群部署后，为了提高容灾能力，就需要在集群前面挂一层负载均衡来进行灾备。但是一个客户端拿到负载均衡ip的时候，去对应的Broker去消费数据，可能会出现该条消息并不存储于该Broker而导致消费失败。</p><p>为了解决这个问题，每个 Broker 上会设置有转发的功能。在实现上，每台 Broker 节点都会保存集群所有的元数据信息。当 Broker 收到请求后，根据本地缓存的元数据信息判断 Queue 是否在本机上，如果不在本机，就会将请求转发到 Queue 所在的目标节点。</p><p>生产端发送数据不是直接发送到 Queue，而是直接发送到 Exchange。即发送时需要指定 Exchange 和 route_key，服务端会根据这两个信息，将消息数据分发到具体的 Queue。</p><p>在消费端，RabbitMQ 支持 Push（推）和 Pull（拉）两种模式，如果使用了 Push 模式，Broker 会不断地推送消息给消费者（如果有消息的情况下）。推送消息的个数会受到 channel.basicQos 的限制，不能无限推送，在消费端会设置一个缓冲区来缓冲这些消息。</p><p>拉模式是指客户端不断地去服务端拉取消息，RabbitMQ 的拉模式只支持拉取单条消息。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《深入拆解消息队列 47 讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;下图是RabbitMQ的系统架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230724201809821.png&quot; alt=&quot;image-2023072</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
</feed>
