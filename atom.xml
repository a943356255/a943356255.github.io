<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>随便起个名字吧</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-05-05T07:58:45.441Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Guo Junhao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何保证消息仅被消费一次</title>
    <link href="http://example.com/2023/05/05/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%BB%85%E8%A2%AB%E6%B6%88%E8%B4%B9%E4%B8%80%E6%AC%A1/"/>
    <id>http://example.com/2023/05/05/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%BB%85%E8%A2%AB%E6%B6%88%E8%B4%B9%E4%B8%80%E6%AC%A1/</id>
    <published>2023-05-05T07:29:40.000Z</published>
    <updated>2023-05-05T07:58:45.441Z</updated>
    
    <content type="html"><![CDATA[<p>首先，如果要确保每个消息只被消费一次，那么就要确保每一个消息都正常到达了消费端，即不能出现消息丢失。</p><p>以下三个地方会造成消息丢失：</p><p>1、消息从生产者写入到消息队列的过程；</p><p>2、消息在消息队列中的存储场景；</p><p>3、消息被消费者消费的过程。</p><h1 id="1、在消息生产的过程中丢失消息"><a href="#1、在消息生产的过程中丢失消息" class="headerlink" title="1、在消息生产的过程中丢失消息"></a>1、在消息生产的过程中丢失消息</h1><p>生产者一般是独立部署的应用程序，而消息队列一般也是独立部署。那么生产者的消息发往消息队列需要通过网络，这就有可能丢失。这里的一个比较好的解决办法就是重试，即重新发送消息。</p><p>但是重试则会导致消息重复，比如第一条消息因为在网络中拥堵，导致超过时延，生产设判断消息丢失，重新发送消息。但是过段时间重新发送的消息和之前的消息都到达了消息队列，那么这条消息就重复了。</p><h1 id="2、在消息队列中丢失消息"><a href="#2、在消息队列中丢失消息" class="headerlink" title="2、在消息队列中丢失消息"></a>2、在消息队列中丢失消息</h1><p>拿Kafka来说，消息一般是存储在本地磁盘，而为了减少刷盘次数，消息会先写入Page Cache（操作系统提供的缓存）中，然后找合适时间刷盘。</p><p>这样设计，好处在于减少I&#x2F;O，但是如果在未刷盘时，服务器掉电，就会导致在Page Cache中的数据丢失。</p><p>这里的解决办法有，调整刷盘时机，即过一段时间，或者一定量消息强行刷盘，但是会影响性能。另一种方法，部署Kafka集群，通过多个数据备份，防止丢数据。</p><h1 id="3、在消费的过程中存在消息丢失的可能"><a href="#3、在消费的过程中存在消息丢失的可能" class="headerlink" title="3、在消费的过程中存在消息丢失的可能"></a>3、在消费的过程中存在消息丢失的可能</h1><p>在这里，消费端接收消息有可能失败，而正确接受完消息后，在处理的过程中也可能失败。所以这里需要注意，消费端一定要等到处理消息的逻辑执行完后，再给消息队列返回。</p><h1 id="如何保证消息只被消费一次"><a href="#如何保证消息只被消费一次" class="headerlink" title="如何保证消息只被消费一次"></a>如何保证消息只被消费一次</h1><h2 id="1、保证幂等性"><a href="#1、保证幂等性" class="headerlink" title="1、保证幂等性"></a>1、保证幂等性</h2><p>幂等性指的是不论执行多少次，最终的结果都是一致的。</p><p>比如说下面语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update table set a = 1 where id = 2;</span><br></pre></td></tr></table></figure><p>这条语句不论执行多少次，结果都不会变（不考虑其他语句穿插），也就是说不论执行多少次，都不会影响最终结果的正确性。</p><p>这样就保证了消息重复时，虽然被执行了多次，但是不影响最终结果的正确性。</p><h2 id="2、在生产、消费过程中增加消息幂等性的保证"><a href="#2、在生产、消费过程中增加消息幂等性的保证" class="headerlink" title="2、在生产、消费过程中增加消息幂等性的保证"></a>2、在生产、消费过程中增加消息幂等性的保证</h2><p>生产者这边，可以通过给每一个消息增加一个全局唯一的id，这样消息队列接收到重复的id时，就知道消息是重复的，丢弃即可。</p><p>在消费端，可以通过给每一个消息一个全局id，如果消费完该消息，就将id存储起来，每次消费前查看是否已经消费该id，以此来确保每条消息只被消费一次。</p><p>另外一种做法就是通过增加一个类似于乐观锁的版本号，每次消费时，就把版本号增加。这样的话，第二次消费该消息时，就会发现版本号对不上，就会放弃消费该消息。</p><p>类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update table set a = 1 , controler_version = controler_version + 1 where control_version = 1</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《消息队列高手课》</p><p>《高并发系统设计40问》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;首先，如果要确保每个消息只被消费一次，那么就要确保每一个消息都正常到达了消费端，即不能出现消息丢失。&lt;/p&gt;
&lt;p&gt;以下三个地方会造成消息丢失：&lt;/p&gt;
&lt;p&gt;1、消息从生产者写入到消息队列的过程；&lt;/p&gt;
&lt;p&gt;2、消息在消息队列中的存储场景；&lt;/p&gt;
&lt;p&gt;3、消息被消</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Kafka如何实现高性能I/O</title>
    <link href="http://example.com/2023/05/05/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDI-O/"/>
    <id>http://example.com/2023/05/05/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDI-O/</id>
    <published>2023-05-05T04:58:33.000Z</published>
    <updated>2023-05-05T05:13:30.587Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用批量消息提升服务端处理能力"><a href="#使用批量消息提升服务端处理能力" class="headerlink" title="使用批量消息提升服务端处理能力"></a>使用批量消息提升服务端处理能力</h1><p>Kafka提供了单词发送一条消息的send方法，但实际上，Kafka的客户端在实现消息发送时，采用了异步批量发送的机制。也就是说，当你调用send时，它并不会立即将消息发出去，而是放在缓存当中，到合适的时机把缓存中消息组成一批一次性发送给Broker。</p><p>而接收端，Kafka不会把一批消息还原成多条，而是每条消息都当作批消息来处理，在Broker整个处理流程中，这些被组合在一起的消息始终都是一个整体，不会被拆开。</p><h1 id="使用顺序读写提升磁盘-I-x2F-O性能"><a href="#使用顺序读写提升磁盘-I-x2F-O性能" class="headerlink" title="使用顺序读写提升磁盘 I&#x2F;O性能"></a>使用顺序读写提升磁盘 I&#x2F;O性能</h1><p>对于磁盘来说，它有一个特性，就是顺序读写的性能要远远好于随机读写。因为操作系统每次从磁盘读写数据的时候，需要先寻址，也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写。所以随机读写会花费大量时间在寻址上，而顺序读写只需要找到第一个位置，接着往下写久可以了。</p><p>Kafka存储设计非常简单，对于每个分区，它把从Producer 收到的消息，顺序地写入对应的 log 文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也是从某个全局的位置开始，也就是某一个 log 文件中的某个位置开始，顺序地把消息读出来。</p><h1 id="利用PageCache-加速消息读写"><a href="#利用PageCache-加速消息读写" class="headerlink" title="利用PageCache 加速消息读写"></a>利用PageCache 加速消息读写</h1><p>PageCache 就是操作系统在内存中给磁盘上的文件建立的缓存。无论我们使用什么语言编写的程序，在调用系统的 API 读写文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的都是 PageCache，也就是文件在内存中缓存的副本。</p><p>Kafka 在读写消息文件的时候，充分利用了 PageCache 的特性。一般来说，消息刚刚写入到服务端就会被消费，按照 LRU 的“优先清除最近最少使用的页”这种策略，读取的时候，对于这种刚刚写入的 PageCache，命中的几率会非常高。</p><h1 id="ZeroCopy：零拷贝技术"><a href="#ZeroCopy：零拷贝技术" class="headerlink" title="ZeroCopy：零拷贝技术"></a>ZeroCopy：零拷贝技术</h1><p>服务端处理消费的逻辑大致如下：</p><p>1、找到消息所在的文件，然后读入内存当中。</p><p>2、把消息通过网络发送给客户端。</p><p>这个过程中，数据实际上做了 2 次或者 3 次复制：</p><p>1、如果PageCache中没有，则需要将消息从文件复制到PageCache。</p><p>2、从PageCache读取到应用程序的内存空间中。</p><p>3、从应用程序复制到Socket的缓冲区。</p><p>而Kafka采用的是直接从PageCache复制到Socket中，这样可以省略一次复制。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《消息队列高手课》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用批量消息提升服务端处理能力&quot;&gt;&lt;a href=&quot;#使用批量消息提升服务端处理能力&quot; class=&quot;headerlink&quot; title=&quot;使用批量消息提升服务端处理能力&quot;&gt;&lt;/a&gt;使用批量消息提升服务端处理能力&lt;/h1&gt;&lt;p&gt;Kafka提供了单词发送一条消息的s</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消息队列问题答疑</title>
    <link href="http://example.com/2023/05/03/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91/"/>
    <id>http://example.com/2023/05/03/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91/</id>
    <published>2023-05-03T07:58:21.000Z</published>
    <updated>2023-05-03T08:30:43.588Z</updated>
    
    <content type="html"><![CDATA[<h1 id="网关如何接收服务端的秒杀结果"><a href="#网关如何接收服务端的秒杀结果" class="headerlink" title="网关如何接收服务端的秒杀结果"></a>网关如何接收服务端的秒杀结果</h1><p>这里只是一个很简单的例子，省去了很多的细节，不同的系统也有不同的设计，思路仅供参考。</p><p>网关在收到 APP 的秒杀请求后，直接给消息队列发消息。如果发送消息失败，可以直接给 APP 返回秒杀失败结果，成功发送消息之后，线程就阻塞等待秒杀结果。这里不会无限等待，会设置一个超时事件。等待结束之后，去存放秒杀结果的 Map 中查询是否有返回的秒杀结果，如果有就构建Response，给 APP 返回秒杀结果，如果没有，按秒杀失败处理。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230503160946737.png" alt="image-20230503160946737"></p><h1 id="RocketMQ-和-Kafka-的消息模型"><a href="#RocketMQ-和-Kafka-的消息模型" class="headerlink" title="RocketMQ 和 Kafka 的消息模型"></a>RocketMQ 和 Kafka 的消息模型</h1><p>现在，假如有一个主题 MyTopic，我们为主题创建 5 个队列，分布到 2 个 Broker 中。有三个生产者Produer0，Produer1 和Producer2。</p><p>这三个生产者与2个Broker可以随便对应，也就是说可以轮询发消息，或者说一个生产者的消息全部发送到一个Broker中。</p><p>至于消费端，有消费组、消费者和队列这几个概念。</p><p>每个消费组就是一份订阅，它要消费主题 MyTopic 下，所有队列的全部消息。这里要注意，消费了的消息并不会从队列中删除，只是从队列中读取了消息。</p><p>多个消费组在消费同一个主题时，消费组之间是互不影响的。比如我们有 2 个消费组：G0和 G1。G0 消费了哪些消息，G1 是不知道的，也不用知道。G0 消费过的消息，G1 还可以消费。即使 G0 积压了很多消息，对 G1 来说也没有任何影响。</p><p>而一个消费组中可以包含多个消费者的实例。比如说消费组G1，包含了 2 个消费者 C0 和 C1。这里有一个原则，即同一个消费组里面，每个队列只能被一个消费者实例占用。我们可以让消费者 C0 消费 Q0，Q1 和 Q2，C1 消费Q3 和 Q4，如果 C0 宕机了，会触发重新分配，这时候 C1 同时消费全部 5 个队列。</p><p>队列占用只是针对消费组内部来说的，对于其他的消费组来说是没有影响的。比如队列 Q2 被消费组 G1 的消费者 C1 占用了，对于消费组 G2 来说，是完全没有影响的，G2 也可以分配它的消费者来占用和消费队列 Q2。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230503162810577.png" alt="image-20230503162810577"></p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230503162822904.png" alt="image-20230503162822904"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;网关如何接收服务端的秒杀结果&quot;&gt;&lt;a href=&quot;#网关如何接收服务端的秒杀结果&quot; class=&quot;headerlink&quot; title=&quot;网关如何接收服务端的秒杀结果&quot;&gt;&lt;/a&gt;网关如何接收服务端的秒杀结果&lt;/h1&gt;&lt;p&gt;这里只是一个很简单的例子，省去了很多的细节，</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>如何处理消息积压</title>
    <link href="http://example.com/2023/05/03/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B/"/>
    <id>http://example.com/2023/05/03/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B/</id>
    <published>2023-05-03T06:55:44.000Z</published>
    <updated>2023-05-03T07:58:05.053Z</updated>
    
    <content type="html"><![CDATA[<h1 id="优化性能来避免消息积压"><a href="#优化性能来避免消息积压" class="headerlink" title="优化性能来避免消息积压"></a>优化性能来避免消息积压</h1><p>在使用消息队列时，我们主要考虑消息的发送方和接收方这两部分的处理，而不需要关注消息队列的处理能力，因为业务逻辑往往复杂于消息队列的处理，而且这两者并不是一个量级。</p><p>所以，对于消息队列的性能优化，我们更关注的是，<strong>在消息的收发两端，我们的业务代码怎么和消息队列配合，达到一个最佳的性能</strong>。</p><h2 id="1-发送端性能优化"><a href="#1-发送端性能优化" class="headerlink" title="1. 发送端性能优化"></a><strong>1.</strong> 发送端性能优化</h2><p>发送端可能存在发送速率没有设置好，从而导致消息处理太慢。这里的一个解决办法就是并发的进行消息发送，或者说批量的进行发送，都可以提高发送端的性能。</p><h2 id="2-消费端性能优化"><a href="#2-消费端性能优化" class="headerlink" title="2. 消费端性能优化"></a>2. 消费端性能优化</h2><p>当消费端的处理能力长时间低于发送端的发送能力时，就会导致消息积压。会导致两种结果，消息队列填满，无法对外服务，或者消息丢失，这都是比较严重的事故。</p><p>消费端的优化，除了优化业务逻辑外，还可以水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是，<strong>在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。</strong>如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。因为对于消费者来说，在每个分区上实际上只能支持单线程消费。</p><h1 id="消息积压了该如何处理"><a href="#消息积压了该如何处理" class="headerlink" title="消息积压了该如何处理"></a>消息积压了该如何处理</h1><p>这里需要注意一种情况，如果通过监控系统发现消息的发送方和处理方的速度都没什么变化，但还是出现了消息积压，就要考虑是否是一个消息处理失败，被反复执行，导致后续的消息无法处理。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《消息队列高手课》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;优化性能来避免消息积压&quot;&gt;&lt;a href=&quot;#优化性能来避免消息积压&quot; class=&quot;headerlink&quot; title=&quot;优化性能来避免消息积压&quot;&gt;&lt;/a&gt;优化性能来避免消息积压&lt;/h1&gt;&lt;p&gt;在使用消息队列时，我们主要考虑消息的发送方和接收方这两部分的处理，而</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>TCP拥塞控制</title>
    <link href="http://example.com/2023/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"/>
    <id>http://example.com/2023/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/</id>
    <published>2023-05-03T02:15:56.000Z</published>
    <updated>2023-05-03T03:28:18.060Z</updated>
    
    <content type="html"><![CDATA[<p>TCP必须使用端到端拥塞控制而不是使网络辅助的拥塞控制，因为IP层不向端系统提供显式的网络拥塞反馈。TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。如果感觉到没什么拥堵，就加快发送速度，如果有拥堵，就减少。</p><p><strong>怎么限制发送速率</strong>：TCP发送方的拥塞控制需要一个额外的变量，拥塞窗口。发送方中已发送但是未被确认的数据量不会超过拥塞窗口（cwnd）和rwnd的最小值。该约束限制了发送方中未被确认的数据量，因此间接地限制了发送方的发送速率。</p><p><strong>如何感知拥堵</strong>：TCP发送方的丢包事件定义是，要么超时，要么收到接收方3个冗余的ACK。当出现过度拥堵时，路径上的一台或多台路由器缓存会溢出，引起数据包被丢弃，然后发送方会得知丢包事件，然后就会认为出现了拥塞。</p><p>简单来说，当正确收到接收方的ACK时，会认为网络没有拥堵，慢慢调大拥塞窗口，增加发送速率。当出现丢包时，就认为网络拥堵，减小拥塞窗口，减小发送速率。</p><p><strong>TCP拥塞控制算法</strong>包括三部分：</p><ul><li>慢启动</li><li>拥塞避免</li><li>快速恢复</li></ul><h1 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h1><p>在刚开始建立连接时，拥塞窗口的大小比较小，而每当正确接收到ACK确认时，就增加拥塞窗口的大小。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230503104756403.png" alt="image-20230503104756403" style="zoom: 80%;" /><p>何时结束这种指数增长：</p><p>1、在此过程中，如果出现拥堵，即出现丢包，那就重新开始慢启动，把拥塞窗口置为1。此时阈值会被设置为出现拥堵时窗口大小的一半。比如说出现拥堵时窗口大小为50，那么就将阈值设置为25。</p><p>2、一切正常时，当拥塞窗口大小到达拥塞窗口阈值时，结束慢启动并转移到拥塞避免模式。</p><p>3、如果检测到3个冗余ACK，这时TCP执行一种快速重传，并进入快速恢复状态。</p><h1 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h1><p>一旦进入拥塞避免状态，拥塞窗口的值大约是上次遇到拥塞时的值的一半，而且在增加拥塞窗口大小时，它并不会像启动那样一次翻一倍，而是每次增加1。</p><p>合适结束这种线性增长：</p><p>1、当出现超时丢包时，就将阈值设置为拥塞窗口的一半。</p><p>2、当出现3个冗余ACK所确认的丢包时，TCP将拥塞窗口的值减半，然后将阈值设置为拥塞窗口的一半。此时拥塞窗口和阈值大小一样，将不会再增加。</p><p>之后就进入快速恢复阶段。</p><h1 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h1><p>总结：出现 网络拥塞 之后 , 拥塞窗口 不降为 1 , 而是降低到 慢开始门限值 , 即当前的 拥塞窗口大小的 1&#x2F;2 , 然后线性增加 拥塞窗口 ;</p><p>如下图：没有快速恢复时，出现拥堵窗口会将为1，然后开始增长，到达阈值每次增加1。</p><p>有快速恢复时，出现拥堵窗口大小降为之前的阈值，然后每次增加1。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230503112334911.png" alt="image-20230503112334911"></p><h1 id="三个过程的转换"><a href="#三个过程的转换" class="headerlink" title="三个过程的转换"></a>三个过程的转换</h1><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230503110841488.png" alt="image-20230503110841488"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《计算机网络：自顶向下》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;TCP必须使用端到端拥塞控制而不是使网络辅助的拥塞控制，因为IP层不向端系统提供显式的网络拥塞反馈。TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。如果感觉到没什么拥堵，就加快发送速度，如果有拥堵，就减少。&lt;/p&gt;
&lt;p&gt;&lt;str</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="运输层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
    
  </entry>
  
  <entry>
    <title>拥塞控制原理</title>
    <link href="http://example.com/2023/05/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2023/05/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/</id>
    <published>2023-05-02T02:17:31.000Z</published>
    <updated>2023-05-03T02:16:20.247Z</updated>
    
    <content type="html"><![CDATA[<h1 id="拥塞原因与代价"><a href="#拥塞原因与代价" class="headerlink" title="拥塞原因与代价"></a>拥塞原因与代价</h1><h2 id="情况1：两个发送方和一台具有无穷大缓存的路由器"><a href="#情况1：两个发送方和一台具有无穷大缓存的路由器" class="headerlink" title="情况1：两个发送方和一台具有无穷大缓存的路由器"></a>情况1：两个发送方和一台具有无穷大缓存的路由器</h2><p>两台主机（A和B）都有一条连接，且这两条连接共享源与目的地之间的单跳路由，如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230502102410352.png" alt="image-20230502102410352" style="zoom:67%;" /><p>由于路由器的缓存是无限制的，那么发送方的发送速率达到一定程度，路由器中的平均排队分组数就会无限增长，源与目的地之间的平均时延也会变成无穷大。</p><h2 id="情况2：两个发送方和一台具有有限缓存的路由器"><a href="#情况2：两个发送方和一台具有有限缓存的路由器" class="headerlink" title="情况2：两个发送方和一台具有有限缓存的路由器"></a>情况2：两个发送方和一台具有有限缓存的路由器</h2><p>这里对情况1稍微做一些修改，假定路由器的缓存容量是有限的。这种假设的结果是，当分组到达一个已满的缓存时会被丢弃。然后我们假设连接可靠，即分组在路由器中被丢弃时，会重发。</p><p>假设发送方知道路由中缓存容量，只有在路由未满时才发送，那么就不会导致分组丢失。</p><p>但一种更为真实的情况是，发送方并不知道，那么在缓存满时发送分组，带来的代价就是需要重新发送。而且存在一种情况，分组发出但是未丢失，还在排队当中，发送方因超时重新发送了分组，那么就会导致接收方需要丢弃一个重传分组，带来了不必要的开销。</p><p>这里就看出拥塞的两个代价，发送方需要重传丢失的分组，而且发送方可能重传不必要的分组。</p><h2 id="情况3：-4个发送方和具有有限缓存的多台路由器及多跳路径"><a href="#情况3：-4个发送方和具有有限缓存的多台路由器及多跳路径" class="headerlink" title="情况3： 4个发送方和具有有限缓存的多台路由器及多跳路径"></a>情况3： 4个发送方和具有有限缓存的多台路由器及多跳路径</h2><p>考虑下图的情况：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230502104741965.png" alt="image-20230502104741965" style="zoom:67%;" /><p>由于路由器R2的缓存容量是有限的 ，那么当A-C通信，B-D通信时，这两者势必会争抢缓存，一种极端的情况是A-C占据了所有的缓存，导致B-D流量几乎为0，导致分组丢失。</p><p>还会导致资源浪费的一个点是，如果R2丢弃B-D的分组，那么R3所做的转发也就成了无用功，导致资源浪费。</p><h1 id="拥塞控制方法"><a href="#拥塞控制方法" class="headerlink" title="拥塞控制方法"></a>拥塞控制方法</h1><h2 id="端到端拥寒控制"><a href="#端到端拥寒控制" class="headerlink" title="端到端拥寒控制"></a>端到端拥寒控制</h2><p>在端到端拥塞控制方法中，网络层没有为运输层拥塞控制提供显式支持。即使网络中存在拥塞，端系统也必须通过对网络行为的观察（如分组丢失与时延）来推断。</p><p>TCP采用端到端的方法解决拥塞控制，因为IP层不会向端系统提供有关网络拥塞的反馈信息。TCP报文段的丢失（通过超时或3次冗余确认而得知）被认为是网络拥塞的一个迹象，TCP会相应地减小其窗口长度。</p><h2 id="网络辅助的拥塞控制"><a href="#网络辅助的拥塞控制" class="headerlink" title="网络辅助的拥塞控制"></a>网络辅助的拥塞控制</h2><p>在网络辅助的拥塞控制中，路由器向发送方提供关于网络中拥塞状态的显式反馈信息。这种反馈可以简单地用一个比特来指示链路中的拥塞情况。</p><p>对于网络辅助的拥塞控制，拥塞信息从网络反馈到发送方通常有两种方式，如下图</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230502110906990.png" alt="image-20230502110906990" style="zoom:67%;" /><p>直接反馈信息可以由网络路由器发给发送方。这种方式的通知通常采用了一种阻塞分组(choke packet) 的形式（主要是说： “我拥塞了！”）。</p><p>更为通用的第二种形式的通知是，路由器标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生口 一旦收到一个标记的分组后，接收方就会向发送方通知该网络拥塞指示。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;拥塞原因与代价&quot;&gt;&lt;a href=&quot;#拥塞原因与代价&quot; class=&quot;headerlink&quot; title=&quot;拥塞原因与代价&quot;&gt;&lt;/a&gt;拥塞原因与代价&lt;/h1&gt;&lt;h2 id=&quot;情况1：两个发送方和一台具有无穷大缓存的路由器&quot;&gt;&lt;a href=&quot;#情况1：两个发送方和</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="运输层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
    
  </entry>
  
  <entry>
    <title>如何利用事务消息实现分布式事务</title>
    <link href="http://example.com/2023/05/01/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2023/05/01/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2023-05-01T10:19:37.000Z</published>
    <updated>2023-05-01T10:48:42.119Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是分布式事务？"><a href="#什么是分布式事务？" class="headerlink" title="什么是分布式事务？"></a>什么是分布式事务？</h1><p>首先事务是要保证我们对一系列数据进行一些操作，这些操作要么都成功，要么都失败。一个严格意义的事务实现，应该具有 4 个属性：原子性、一致性、隔离性、持久性。</p><p>但是，对于分布式系统来说，严格的实现 ACID 这四个特性几乎是不可能的。一般会采用一些“妥协”的方案，比如说顺序一致性或者最终一致性。</p><h1 id="消息队列是如何实现分布式事务的？"><a href="#消息队列是如何实现分布式事务的？" class="headerlink" title="消息队列是如何实现分布式事务的？"></a>消息队列是如何实现分布式事务的？</h1><p>一个订单和购物车的模型如下图：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230501183227849.png" alt="image-20230501183227849"></p><p>这里的半消息，并不是只发送数据信息的一半，而是说发送全部的数据，但是在事务提交之前，消费者是无法看到这条数据的。</p><p>这里，发送半消息后，就可以继续执行创建订单，如果订单创建成功，则提交事务，那么消费者，也就是购物车模块可以看到这条消息，然后从购物车删除对应订单的物品。如果订单创建失败，则消费者无法看到消息，也就不会导致创建订单失败，但是购物车删除物品这种情况。</p><p>但是还存在一个问题：如果提交事务消息失败时，还是会存在一定的问题，针对这个问题，Kafka 和 RocketMQ给出了不同的解决办法。Kafka 的解决方案比较简单粗暴，直接抛出异常，让用户自行处理。我们可以在业务代码中反复重试提交，直到提交成功，或者删除之前创建的订单进行补偿。RocketMQ 则给出了另外一种解决方案。</p><h1 id="RocketMQ-中的分布式事务实现"><a href="#RocketMQ-中的分布式事务实现" class="headerlink" title="RocketMQ 中的分布式事务实现"></a>RocketMQ 中的分布式事务实现</h1><p>在 RocketMQ 中的事务实现中，增加了事务反查的机制来解决事务消息提交失败的问题。如果 Producer 也就是订单系统，在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer 上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。</p><p>为了支撑这个事务反查机制，我们的业务代码需要实现一个反查本地事务状态的接口，告知 RocketMQ 本地事务是成功还是失败。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230501184354506.png" alt="image-20230501184354506" style="zoom:67%;" /><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《消息队列高手课》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;什么是分布式事务？&quot;&gt;&lt;a href=&quot;#什么是分布式事务？&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式事务？&quot;&gt;&lt;/a&gt;什么是分布式事务？&lt;/h1&gt;&lt;p&gt;首先事务是要保证我们对一系列数据进行一些操作，这些操作要么都成功，要么都失败。一个严</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>缓存如何做到高可用</title>
    <link href="http://example.com/2023/05/01/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E7%BC%93%E5%AD%98%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <id>http://example.com/2023/05/01/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E7%BC%93%E5%AD%98%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E9%AB%98%E5%8F%AF%E7%94%A8/</id>
    <published>2023-05-01T07:13:40.000Z</published>
    <updated>2023-05-01T07:48:35.474Z</updated>
    
    <content type="html"><![CDATA[<p> 分布式缓存的高可用方案有以下三类：</p><p>1、<strong>客户端方案</strong>：在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。</p><p>2、<strong>中间代理层方案</strong>：在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。</p><p>3、<strong>服务端方案</strong>：Redis 2.4 版本后提出的 Redis Sentinel 。</p><h1 id="客户端方案"><a href="#客户端方案" class="headerlink" title="客户端方案"></a>客户端方案</h1><p>在该方案中，需要注意缓存的读写。写需要将数据分片，而读可以用多组缓存做容错，提升系统的可用性。</p><h2 id="缓存数据分片"><a href="#缓存数据分片" class="headerlink" title="缓存数据分片"></a>缓存数据分片</h2><p>当单一机器无法存储所有的数据时，我们就需要将缓存分配到不同的机器上，每个节点上存储部分数据。</p><p><strong>一般来讲，分片算法常见的就是 Hash 分片算法和一致性 Hash 分片算法两种。</strong></p><h3 id="1、Hash分片"><a href="#1、Hash分片" class="headerlink" title="1、Hash分片"></a>1、Hash分片</h3><p>Hash分片就是对key做哈希计算，然后对总的缓存节点取余。该算法优点是简单，缺点是当增加或者减少分片节点数量时，计算的方式也要发生变化。该方案适合缓存命中率下降不敏感的业务。</p><h3 id="2、一致性Hash"><a href="#2、一致性Hash" class="headerlink" title="2、一致性Hash"></a>2、一致性Hash</h3><p><strong>一致性 Hash 算法可以很好地解决增加和删减节点时，命中率下降的问题</strong>。</p><p>该算法中，我们将整个Hash值空间组织成一个虚拟的圆环，然后将每一个分片节点的ip或者主机名做hash后放在该圆环上。当需要确定某一个key在哪个节点上时，先对key做hash，确定在换上的位置（注意，这一步做完hash后，不一定会直接落到某一个节点的下标处，所以需要顺时针往下走），然后往下走，找到第一个是节点的位置，就将数据存储在该节点中。</p><p>在该算法中，删除节点会导致节点上的数据漂移到下一个节点上，对于hash命中率并不会造成特别大的影响。</p><p>存在的问题：</p><p>1、缓存节点在圆环上分布不均匀，会造成部分节点压力很大，而且当一个节点失效，会将数据全部转移到下一个节点。</p><p>2、一致性 Hash 算法的脏数据问题。</p><p>针对于第一个问题，在某个节点出问题时，要将节点平均分配到其他的几个节点上，而不能将它全部移交到下一个节点上。</p><p>对于第二个问题，如果节点3中有一个数据，现在要修改该数据，但是节点3此时无法连接，那么修改操作就会发生到节点4，那么当节点3恢复后，客户端就会从节点3中读取到脏数据。解决办法就是增加过期时间。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《高并发系统设计》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 分布式缓存的高可用方案有以下三类：&lt;/p&gt;
&lt;p&gt;1、&lt;strong&gt;客户端方案&lt;/strong&gt;：在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。&lt;/p&gt;
&lt;p&gt;2、&lt;strong&gt;中间代理层方案&lt;/strong&gt;：在应用代码和</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="高并发系统设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="缓存篇" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E7%BC%93%E5%AD%98%E7%AF%87/"/>
    
    
    <category term="缓存" scheme="http://example.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>如何正确的选择缓存读写策略</title>
    <link href="http://example.com/2023/04/30/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E7%9A%84%E9%80%89%E6%8B%A9%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E7%AD%96%E7%95%A5/"/>
    <id>http://example.com/2023/04/30/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E7%9A%84%E9%80%89%E6%8B%A9%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E7%AD%96%E7%95%A5/</id>
    <published>2023-04-30T11:26:41.000Z</published>
    <updated>2023-05-01T07:14:01.524Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Cache-Aside（旁路缓存）策略"><a href="#Cache-Aside（旁路缓存）策略" class="headerlink" title="Cache Aside（旁路缓存）策略"></a>Cache Aside（旁路缓存）策略</h1><p>读策略为：</p><ul><li>从缓存中读取数据，命中则直接返回</li><li>缓存未命中，则从数据库查询，然后写入缓存，并返回给用户</li></ul><p>写策略为：</p><ul><li>更新数据库中的数据</li><li>删除缓存的数据</li></ul><p>先删除缓存再删数据或者先删数据库再删除缓存都会导致一定的问题，分析比较简单，不做具体说明。</p><h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><p>如果新注册了一个用户，然后立刻发起了查询（此时缓存无法命中），如果查询走的是从库，而且存在一定的时延，那么会有可能查询不到个人信息。</p><p>解决办法就是在特定的场景下，我们可以修改后将修改的信息写入缓存当中，而不是删除。</p><p>而且该策略对于频繁的修改会导致缓存中的数据被频繁的清理，造成缓存命中率低。</p><p>两种解决办法：</p><ol><li><p>一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；</p></li><li><p>另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。</p></li></ol><h1 id="Read-x2F-Write-Through（读穿-x2F-写穿）策略"><a href="#Read-x2F-Write-Through（读穿-x2F-写穿）策略" class="headerlink" title="Read&#x2F;Write Through（读穿 &#x2F; 写穿）策略"></a>Read&#x2F;Write Through（读穿 &#x2F; 写穿）策略</h1><p>这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据。</p><p><strong>Write Through 的策略</strong>是这样的：先查询要写入的数据在缓存中是否已经存在，如果已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，如果缓存中数据不存在，我们把这种情况叫做“Write Miss（写失效）”。</p><p>如果发生写失效，则解决办法有以下两种：</p><ul><li>Write Allocate（按写分配）：写入缓存相应位置，再由缓存组件同步更新到数据库中；</li><li>No-write allocate（不按写分配）：不写入缓存中，而是直接更新到数据库中。</li></ul><p><strong>Read Through 策略</strong>就简单一些，它的步骤是这样的：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库中同步加载数据。</p><h1 id="Write-Back（写回）策略"><a href="#Write-Back（写回）策略" class="headerlink" title="Write Back（写回）策略"></a>Write Back（写回）策略</h1><p>这个策略的核心思想是在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的。而脏块儿只有被再次使用时才会将其中的数据写入到后端存储中。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230430194034299.png" alt="image-20230430194034299" style="zoom:67%;" /><p><strong>如果使用 Write Back 策略的话，读的策略也有一些变化了。</strong></p><p>我们在读取缓存时如果发现缓存命中则直接返回缓存数据。</p><p>如果缓存不命中则寻找一个可用的缓存块儿，如果这个缓存块儿是“脏”的，就把缓存块儿中之前的数据写入到后端存储中，并且从后端存储加载数据到缓存块儿。</p><p>如果不是脏的，则由缓存组件将后端存储中的数据加载到缓存中，最后我们将缓存设置为不是脏的，返回数据就好了。</p><p>这个策略一般不直接在生产环境中使用，往往是计算机结构中使用，比如说操作系统层面的 Page Cache，日志的异步刷盘，消息队列中消息的异步写入磁盘等。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《高并发系统设计》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Cache-Aside（旁路缓存）策略&quot;&gt;&lt;a href=&quot;#Cache-Aside（旁路缓存）策略&quot; class=&quot;headerlink&quot; title=&quot;Cache Aside（旁路缓存）策略&quot;&gt;&lt;/a&gt;Cache Aside（旁路缓存）策略&lt;/h1&gt;&lt;p&gt;读策</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="高并发系统设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="缓存篇" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E7%BC%93%E5%AD%98%E7%AF%87/"/>
    
    
    <category term="缓存" scheme="http://example.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>TCP连接的管理</title>
    <link href="http://example.com/2023/04/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E7%AE%A1%E7%90%86/"/>
    <id>http://example.com/2023/04/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E7%AE%A1%E7%90%86/</id>
    <published>2023-04-30T02:49:26.000Z</published>
    <updated>2023-04-30T03:32:19.901Z</updated>
    
    <content type="html"><![CDATA[<h1 id="建立连接过程"><a href="#建立连接过程" class="headerlink" title="建立连接过程"></a>建立连接过程</h1><p>TCP建立连接的过程如下：</p><p><strong>第一步</strong>：客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文段。该报文段中不包含应用层数据。该报文段会将首部中的SYN置为1，这个特殊报文段被称为SYN报文段。</p><p>客户会随机地选择一个初始序号（client_isn）,并将此编号放置于该起始的TCP SYN报文段的序号字段中。该报文段会被封装在一个IP数据报中，并发送给服务器。</p><p><strong>第二步</strong>：一旦包含TCP SYN报文段的IP数据报到达服务器主机，服务器会从该数据报中提取出TCP SYN报文段，为该TCP连接分配TCP缓存和变量，并向该客户TCP发送允许连接的报文段。这个允许连接的报文段也不包含应用层数据。</p><p>在报文段的首部包含3个重要的信息。首先，SYN比特被置为1。其次，该TCP报文段首部的确认号字段被置为client _ isn + 1。最后，服务器选择自己的初始序号（server_isn）,并将其放置到TCP报文段首部的序号字段中。</p><p>这个允许连接的报文段实际上表明了： “我收到了你发起建立连接的SYN分组，该分组带有初始序号client_isn。我同意建立该连接。我自己的初始序号是server_isn。该允许连接的报文段被称为SYNACK报文段（SYNACK segment）。</p><p><strong>第三步</strong>：在收到SYNACK报文段后，客户也要给该连接分配缓存和变量。客户主机则向服务器发送另外一个报文段；这最后一个报文段对服务器的允许连接的报文段进行了确认（该客户通过将值server_isn + 1放置到TCP报文段首部的确认字段中来完成此项工作）。</p><p>该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据。 </p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230430112825050.png" alt="image-20230430112825050" style="zoom:67%;" /><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>也就是说，第一步客户端先发起一个报文段请求，用于表明我想要建立连接，不携带数据。</p><p>第二步，服务器收到请求，允许建立连接，分配缓存，然后给客户端通知该消息，也不携带数据。</p><p>第三步，客户端收到服务端同意建立连接的请求，然后给服务端回应，我收到了你的同意建立连接。第三步其实是一个确认的消息，只不过可以携带一部分数据。</p><h1 id="终止连接的过程"><a href="#终止连接的过程" class="headerlink" title="终止连接的过程"></a>终止连接的过程</h1><p>当连接结束后,主机中的“资源”（即缓存和变量）将被释放。</p><p>当客户想要关闭连接，它会向服务端发送一个特殊的报文，服务端收到后会给他一个ACK响应。然后服务端发送自己的终止报文段，客户端收到后会给该终止报文段一个确认。之后，两台主机上用于该连接的所有资源都被释放。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230430113216637.png" alt="image-20230430113216637" style="zoom:67%;" /><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《计算机网络：自顶向下方法》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;建立连接过程&quot;&gt;&lt;a href=&quot;#建立连接过程&quot; class=&quot;headerlink&quot; title=&quot;建立连接过程&quot;&gt;&lt;/a&gt;建立连接过程&lt;/h1&gt;&lt;p&gt;TCP建立连接的过程如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一步&lt;/strong&gt;：客户端的TCP首先向服务</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="运输层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
    
    <category term="-运输层" scheme="http://example.com/tags/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
  </entry>
  
  <entry>
    <title>消息模型：主题和队列区别</title>
    <link href="http://example.com/2023/04/28/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%BB%E9%A2%98%E5%92%8C%E9%98%9F%E5%88%97%E5%8C%BA%E5%88%AB/"/>
    <id>http://example.com/2023/04/28/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%BB%E9%A2%98%E5%92%8C%E9%98%9F%E5%88%97%E5%8C%BA%E5%88%AB/</id>
    <published>2023-04-28T06:51:06.000Z</published>
    <updated>2023-05-01T10:20:14.060Z</updated>
    
    <content type="html"><![CDATA[<p><strong>早期的消息队列，就是按照“队列”的数据结构来设计的。</strong>我们一起看下这个图，生产者（Producer）发消息就是入队操作，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。</p><p>以下是最初的一种消息模型：队列模型</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230428145326054.png" alt="image-20230428145326054" style="zoom:67%;" /><p>这种模型中，消费者之间是竞争关系，每个消息只能被一个消费者消费。</p><p>但是如果想要一个消息被多个消费者消费，比如说对于一个订单消息，风控系统，分析系统，支付系统都需要得到该订单的信息，那么采用这种模型的话就需要为每一个消费者创建一个队列，但是这样做就需要提前知道有多少个消费者，违背了解耦。</p><p>为了解决这个问题，演化出了另外一种消息模型：“<strong>发布 - 订阅模型（Publish-Subscribe Pattern）</strong>”。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230428145647672.png" alt="image-20230428145647672" style="zoom:67%;" /><p>以上两种模型的区别就是，<strong>一份消息数据能不能被消费多次的问题。</strong></p><h1 id="RabbitMQ-的消息模型"><a href="#RabbitMQ-的消息模型" class="headerlink" title="RabbitMQ 的消息模型"></a>RabbitMQ 的消息模型</h1><p>rabbitmq采用队列模型，它用了一个交换机来解决多个消费者消费同一条消息的问题。</p><p>生产者不关心消息发送给哪个消费者，它只需要发送给交换机，由交换机决定发送给哪个消费者。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230428145907388.png" alt="image-20230428145907388" style="zoom:67%;" /><h1 id="RocketMQ-的消息模型"><a href="#RocketMQ-的消息模型" class="headerlink" title="RocketMQ 的消息模型"></a>RocketMQ 的消息模型</h1><p>RocketMQ 使用的消息模型是标准的发布 - 订阅模型。但是它也有队列的概念。</p><p>几乎所有的消息队列都采用<strong>请求-确认机制</strong>，即生产者将消息发送给服务端，服务端收到并写入队列后，会给生产者发送确认响应。而消费端，消费者收到消息并处理完后，也会给服务端发送消息，服务端在收到确认消息后，才会判定消息被消费成功。上面两种，如果没收到确认消息，会重试。</p><p>但是这样也存在一个问题，即还没收到一个消息的确认信息时，只能等待，而不能去执行第二条消息，这样是为了保证消息的顺序性。</p><p>为了解决这个问题，RocketMQ引入了队列的概念。</p><p><strong>每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。</strong>RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。</p><p>RocketMQ 中，订阅者的概念是通过消费组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。</p><p>一个消费组中的消费者是竞争关系，一条消息只会被消费组中的一个消费者消费。</p><p>由于每一条消息需要被多个消费组消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230428150934219.png" alt="image-20230428150934219"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《消息队列高手课》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;早期的消息队列，就是按照“队列”的数据结构来设计的。&lt;/strong&gt;我们一起看下这个图，生产者（Producer）发消息就是入队操作，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。&lt;/p&gt;
&lt;p&gt;以下是最初</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>分库分表时如何保证id唯一</title>
    <link href="http://example.com/2023/04/27/MySQL/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%97%B6%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81id%E5%94%AF%E4%B8%80/"/>
    <id>http://example.com/2023/04/27/MySQL/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%97%B6%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81id%E5%94%AF%E4%B8%80/</id>
    <published>2023-04-27T13:38:43.000Z</published>
    <updated>2023-04-28T07:19:05.089Z</updated>
    
    <content type="html"><![CDATA[<h1 id="主键如何选择"><a href="#主键如何选择" class="headerlink" title="主键如何选择"></a>主键如何选择</h1><p>1、使用业务字段作为主键，比如说对于用户表来说，可以使用手机号，email 或者身份证号作为主键。</p><p>2、使用生成的唯一 ID 作为主键。</p><p>但是第一种并不是每一张表都可以使用的，一些特殊的字段可以使用，比如说身份证，邮箱，手机号，但是这些字段可能存在变更的情况，就比较麻烦，所以最好采取第二种方案。</p><p>第二种方案在单表时，可以采用简单的自增id来实现，但是在分库分表的情况下却并不能这样，因为不同库和不同表的自增id会重复。我们需要采取一些其他的办法来实现。</p><h1 id="基于-Snowflake-算法搭建发号器"><a href="#基于-Snowflake-算法搭建发号器" class="headerlink" title="基于 Snowflake 算法搭建发号器"></a>基于 Snowflake 算法搭建发号器</h1><p>首先一点是，为什么不采用uuid来当作主键 ？</p><p>1、id最好是有序的，某些场景会需要排序，如果按照id则效率高一点，而且id有序分区也会简单。</p><p>2、id有序时，将其作为主键，插入数据时效率也会高，如果采用无序的插入，可能会频繁的导致页分裂。</p><p>3、uuid作为主键可能会占用大量的空间。</p><p>4、uuid并不具备业务含义。</p><h2 id="Snowflake-算法"><a href="#Snowflake-算法" class="headerlink" title="Snowflake 算法"></a>Snowflake 算法</h2><p>Snowflake 的核心思想是将 64bit 的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230427220731511.png" alt="image-20230427220731511"></p><p>其中机器ID可以用来标识在不同的机房，12位序列号代表着每个节点每毫秒最多可以生成 4096 的 ID。也可以根据不同的业务来规定每一部分的长度。</p><h2 id="具体实现方式"><a href="#具体实现方式" class="headerlink" title="具体实现方式"></a>具体实现方式</h2><p>1、<strong>嵌入到业务代码里，也就是分布在业务服务器中。</strong></p><p>这样实现的好处是不需要跨网络调用，性能会好一点。但是业务层的部署可能存在很多分，这就要求我们用更多的机器位，来确保唯一性。</p><p>2、<strong>作为独立的服务部署，这也就是我们常说的发号器服务。</strong></p><p>这种部署方式需要业务层多一次网络请求来获取id，但是可以减少机器id的位数，留更多的位数给自增信息位。</p><p>该算法的一个缺点是依赖于子系统的时间戳，一旦系统时间不准，就有可能生成重复的id。所以当我们发现系统时钟不准时，就可以让发号器拒绝发号，一直到时钟准为止。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《高并发系统设计 40 问》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;主键如何选择&quot;&gt;&lt;a href=&quot;#主键如何选择&quot; class=&quot;headerlink&quot; title=&quot;主键如何选择&quot;&gt;&lt;/a&gt;主键如何选择&lt;/h1&gt;&lt;p&gt;1、使用业务字段作为主键，比如说对于用户表来说，可以使用手机号，email 或者身份证号作为主键。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="高并发系统设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="数据库篇" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AF%87/"/>
    
    
    <category term="分库分表" scheme="http://example.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>MySQL分库分表</title>
    <link href="http://example.com/2023/04/27/MySQL/MySQL%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    <id>http://example.com/2023/04/27/MySQL/MySQL%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</id>
    <published>2023-04-27T12:09:52.000Z</published>
    <updated>2023-04-27T13:37:30.446Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h1><p>分库分表是一种常见的数据分片方式，它不同于集群那种完全的备份数据，而是每个数据库或者每张表只存储整个数据的一部分，这样可以保证总数据量不变的情况下，每个数据库和每张表少存储一些数据。</p><p>而且在数据写入时，也会变为往一个库或者一张表写变为往多个库或者多张表写，提高并发写入能力。</p><h1 id="如何对数据库做垂直拆分"><a href="#如何对数据库做垂直拆分" class="headerlink" title="如何对数据库做垂直拆分"></a>如何对数据库做垂直拆分</h1><p>垂直拆分就是对数据库竖着拆分，也就是将<strong>数据库的表</strong>拆分到多个<strong>不同的数据库中</strong>。</p><p>垂直拆分的原则一般是按照业务类型来拆分，核心思想是专库专用，将业务耦合度比较高的表拆分到单独的库中。</p><h1 id="如何对数据库做水平拆分"><a href="#如何对数据库做水平拆分" class="headerlink" title="如何对数据库做水平拆分"></a>如何对数据库做水平拆分</h1><p>水平拆分指的是将<strong>单一数据表</strong>按照某一种规则拆分到<strong>多个数据库</strong>和<strong>多个数据表</strong>中，关注点在数据的特点。</p><h2 id="拆分规则"><a href="#拆分规则" class="headerlink" title="拆分规则"></a>拆分规则</h2><p>1、按照某一个字段的哈希值做拆分，这种拆分规则比较适用于实体表。</p><p>比如说我们想把用户表拆分成 16 个库，每个库是 64 张表，那么可以先对用户 ID 做哈希，哈希的目的是将 ID 尽量打散，然后再对 16 取余，这样就得到了分库后的索引值；对 64 取余，就得到了分表后的索引值。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230427202234676.png" alt="image-20230427202234676" style="zoom:67%;" /><p>2、按照某一个字段的区间来拆分，比较常用的是时间字段。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230427202322368.png" alt="image-20230427202322368" style="zoom:67%;" /><h1 id="分库分表带来的问题"><a href="#分库分表带来的问题" class="headerlink" title="分库分表带来的问题"></a>分库分表带来的问题</h1><p>分库分表引入的一个最大的问题就是<strong>引入了分库分表键，也叫做分区键，</strong>也就是我们对数据库做分库分表所依据的字段。</p><p>这也就要求我们后续所有的查询都要带上分区或者分库所用的字段，否则就要遍历所有的库。</p><p>一个解决办法就是，我们可以建立一个其他字段和分区字段的映射，当需要根据其他字段查找时，我们先找到它所对应的id，然后再根据id来查询这个具体的值。</p><p>另一方面，我们无法通过join来连接两个库的表，只能查询到后端然后进行处理。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《高并发系统设计 40 问》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分库分表&quot;&gt;&lt;a href=&quot;#分库分表&quot; class=&quot;headerlink&quot; title=&quot;分库分表&quot;&gt;&lt;/a&gt;分库分表&lt;/h1&gt;&lt;p&gt;分库分表是一种常见的数据分片方式，它不同于集群那种完全的备份数据，而是每个数据库或者每张表只存储整个数据的一部分，这样可以保</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="高并发系统设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="数据库篇" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AF%87/"/>
    
    
    <category term="分库分表" scheme="http://example.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>池化技术</title>
    <link href="http://example.com/2023/04/26/MySQL/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/"/>
    <id>http://example.com/2023/04/26/MySQL/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/</id>
    <published>2023-04-26T06:40:53.000Z</published>
    <updated>2023-04-26T07:32:52.245Z</updated>
    
    <content type="html"><![CDATA[<p>在后端代码操作MySQL时，需要先与MySQL建立连接， 这个连接需要使用TCP的三次握手，比较的耗时，如果在正常的系统中，每一次执行sql，都要建立连接，连接使用完毕后断开连接，那么就会带来严重的性能影响。因此，池化技术就这样诞生了。</p><h1 id="连接池基本配置"><a href="#连接池基本配置" class="headerlink" title="连接池基本配置"></a>连接池基本配置</h1><p>MySQL连接池有两个重要配置，<strong>最小连接数</strong>和<strong>最大连接数</strong>。</p><p>如果连接池中有空闲的连接，则直接使用这些已经建立好的连接，如果已有的连接数超过最小连接数，但是没有超过最大连接数，来了新的连接请求，则创建新的连接处理请求。如果当前连接数大于等于最大连接数，则让新的请求排队，如果超时则抛出错误。</p><p>还有一种情况是，当前连接池中的连接数小于最小连接数，那么新到的连接请求会直接创建新的连接，而不会使用池子中的连接。</p><p>针对于连接池中的连接，我们可以启动一个线程定期检测连接池是否可用，如果不可用就关闭该连接。</p><h1 id="用线程池预先创建线程"><a href="#用线程池预先创建线程" class="headerlink" title="用线程池预先创建线程"></a>用线程池预先创建线程</h1><p>jdk1.5中就提供了池化技术。ThreadPoolExecutor 就是其中的一种，它有两个参数coreThreadCount 和 maxThreadCount。</p><ul><li><p>如果线程池中的线程数少于 coreThreadCount 时，处理新的任务时会创建新的线程；</p></li><li><p>如果线程数大于 coreThreadCount 则把任务丢到一个队列里面，由当前空闲的线程执行；</p></li><li><p>当队列中的任务堆积满了的时候，则继续创建线程，直到达到 maxThreadCount；</p></li><li><p>当线程数达到 maxTheadCount 时还有新的任务提交，那么我们就不得不将它们丢弃了。</p></li></ul><p>流程如下图：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230426152317089.png" alt="image-20230426152317089" style="zoom:67%;" /><p>注意：JDK原生的线程池会优先把任务放进队列，而不是优先创建线程，这种就比较适合CPU密集型的任务。</p><p>因为CPU密集型的任务，如果创建过多的线程去执行任务，那么这些任务会争抢线程，导致频繁的上下文切换，造成性能的损失。</p><p>但是我们平时开发的web项目，其实属于I&#x2F;O密集型的任务，因为牵扯到数据库，所以Tomcat就没有采用JDK自带的，而是做了改进，优先创建线程去处理请求。因为I&#x2F;O密集型的大多时间都花费在去磁盘取数据，这段时间并不需要CPU，所以可以创建更多的线程去处理请求。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《高并发系统设计 40 问》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在后端代码操作MySQL时，需要先与MySQL建立连接， 这个连接需要使用TCP的三次握手，比较的耗时，如果在正常的系统中，每一次执行sql，都要建立连接，连接使用完毕后断开连接，那么就会带来严重的性能影响。因此，池化技术就这样诞生了。&lt;/p&gt;
&lt;h1 id=&quot;连接池基本配</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="高并发系统设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="数据库篇" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AF%87/"/>
    
    
    <category term="连接池" scheme="http://example.com/tags/%E8%BF%9E%E6%8E%A5%E6%B1%A0/"/>
    
  </entry>
  
  <entry>
    <title>TCP</title>
    <link href="http://example.com/2023/04/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP/"/>
    <id>http://example.com/2023/04/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP/</id>
    <published>2023-04-25T02:12:15.000Z</published>
    <updated>2023-04-30T03:01:24.414Z</updated>
    
    <content type="html"><![CDATA[<p>TCP是面向连接的。而且提供的是全双工服务，即如果两台主机A和B相连，那么A可以给B发数据，B也可以给A发数据。TCP连接是点对点的，即在单个发送方与单个接收方之间的连接。</p><h1 id="建立连接的过程"><a href="#建立连接的过程" class="headerlink" title="建立连接的过程"></a>建立连接的过程</h1><p>客户首先发送一个特殊的TCP报文段，服务器用另一个特殊的TCP报文段来响应，最后，客户再用第三个特殊报文段作为响应。</p><p>前两个报文段不承载“有效载荷” ，也就是不包含应用层数据；而第三个报文段可以承载有效载荷。</p><h1 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h1><p>一旦建立了连接之后，就需要传输数据。当应用层数据通过套接字以后，数据就交由TCP控制。TCP将这些数据引导到该连接的发送缓存里，然后不时的从发送缓存里取出一块数据，并将数据传递到网络层。</p><img src="C:\Users\郭俊豪\AppData\Roaming\Typora\typora-user-images\image-20230425102632021.png" alt="image-20230425102632021" style="zoom:67%;" /><h1 id="TCP报文段结构"><a href="#TCP报文段结构" class="headerlink" title="TCP报文段结构"></a>TCP报文段结构</h1><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230425102923389.png" alt="image-20230425102923389" style="zoom:67%;" /><p>其中，32比特的序号字段和32比特的确认号字段被TCP发送方和接收方用来实现可靠数据传输服务。</p><p>接收窗口字段用来实现流量控制。</p><p>TCP被称为累计确认是因为它的确认号也是按组确认的。比如说收到了0-500的报文段，那么它发送给发送方的确认号就是501，如果收到0-500，和600-900，而没有收到501-599，那么确认号还是501。</p><p>TCP的发送方，也使用了流水线。</p><h1 id="可靠数据传输"><a href="#可靠数据传输" class="headerlink" title="可靠数据传输"></a>可靠数据传输</h1><p>由于网络层提供的服务（IP服务）是不可靠的，无法保证数据按序交付，也无法保证完整性。而TCP则是建立在IP提供的网络服务之上，它创建了一种可靠数据传输服务。</p><h2 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h2><p>TCP有一种机制，就是延长超时时间，比如说第一个字数据经过50ms，被却认为丢失，然后重发，那么第二个就会将超时时间设置为100ms，以此类推。但是这会导致超时的时间越来越长，增加了端到端的时延。</p><p>解决办法是引入了快速重传，即通过冗余的ACK确认，来得知是数据错误，而不需要等待超时时间到达。</p><p>冗余的ACK就是再次确认已经收到的某个报文段的ACK，而发送方之前也已经收到该报文段的ACK。</p><p>一个具体的例子就是，比如说ACK &#x3D; 3是一个数据的确认，而且发送方也已经接收到了ACK &#x3D; 3的确认帧，而接收方收到了数据5和6，没有收到4，此时接收方就会重传ACK &#x3D; 3的确认帧，如果重传超过3次，则TCP就启动快速重传，立即重传3之后的数据。</p><h2 id="选择重传"><a href="#选择重传" class="headerlink" title="选择重传"></a>选择重传</h2><p>回退N帧协议，假设分组n的确认报文丢失，那么它会重传n以及n以后的所有报文，尽管只丢失了n，其他的全部已经正确接收。</p><p>而TCP则是允许接收方有选择的确认失序报文段，而不是累计的确认正确的接收最后一个。当启用重传时，它就会跳过重传那些已经被接收方选择性确认过的报文段。</p><h1 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h1><p>TCP连接的每一侧都为该连接设置了接收缓存。没当TCP接收到正确，按序的字节后，就会将这些数据放入接收缓存，相关的应用就会从接收缓存中读取数据。但是如果应用读取的比较慢，而发送方发送的比较快，则会导致缓存溢出。</p><p>所以TCP提供了流量控制服务，以消除发送方发送过快导致接收方缓存溢出的可能。</p><p>TCP通过让发送方维护一个接收窗口的变量来实现流量控制。接收窗口用于给发送方指示，表明现在接收方还有多少可用的缓存空间。因为TCP是全双工通信的，所以说连接两端都会维护一个接收窗口。</p><p>这样一来，发送方只需要根据对应接收方的窗口大小来确定此时可以发送多少数据，就能保证不溢出。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《计算机网络：自顶向下方法》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;TCP是面向连接的。而且提供的是全双工服务，即如果两台主机A和B相连，那么A可以给B发数据，B也可以给A发数据。TCP连接是点对点的，即在单个发送方与单个接收方之间的连接。&lt;/p&gt;
&lt;h1 id=&quot;建立连接的过程&quot;&gt;&lt;a href=&quot;#建立连接的过程&quot; class=&quot;hea</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="运输层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
    
    <category term="-运输层" scheme="http://example.com/tags/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
  </entry>
  
  <entry>
    <title>如何提高系统性能</title>
    <link href="http://example.com/2023/04/24/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD/"/>
    <id>http://example.com/2023/04/24/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD/</id>
    <published>2023-04-24T11:50:36.000Z</published>
    <updated>2023-04-24T12:24:03.314Z</updated>
    
    <content type="html"><![CDATA[<h1 id="性能的度量指标"><a href="#性能的度量指标" class="headerlink" title="性能的度量指标"></a>性能的度量指标</h1><p>1、平均值</p><p>平均值是把这段时间所有请求的响应时间数据相加，再除以总请求数。但是它存在一定的问题，可能这段时间有10000个请求，只有100个响应时间为100ms，其他都是1s，这样算下来平均值不太大，但是系统是有问题的。</p><p>2、最大值</p><p>即找到一段时间请求的响应时间的最大值。但是又过于敏感，如果只有一个请求响应是100ms，那么最大值就是100。</p><p>3、分位值</p><p>分位值有很多种，比如 90 分位、95 分位、75 分位。以 90 分位为例，我们把这段时间请求的响应时间从小到大排序，假如一共有 100 个请求，那么排在第 90 位的响应时间就是 90 分位值。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424200201337.png" alt="image-20230424200201337"></p><h1 id="高并发下的性能优化"><a href="#高并发下的性能优化" class="headerlink" title="高并发下的性能优化"></a>高并发下的性能优化</h1><p>加入说现在的系统中只有一个处理核心，执行的响应时间都在10ms以内，我们该如何优化呢？</p><h2 id="1-提高系统的处理核心数"><a href="#1-提高系统的处理核心数" class="headerlink" title="1. 提高系统的处理核心数"></a>1. 提高系统的处理核心数</h2><p>当提高了系统的处理核心数，那么我们就可以开更多的线程来同时处理请求。那么系统的吞吐量会变得大一点。但是并不意味着无限制的增加处理核心数可以一直的提高性能。随着并发进程数的增加，并行的任务对于系统资源的争抢也会愈发严重。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424201739627.png" alt="image-20230424201739627" style="zoom: 67%;" /><h2 id="2、减少单次任务响应时间"><a href="#2、减少单次任务响应时间" class="headerlink" title="2、减少单次任务响应时间"></a>2、减少单次任务响应时间</h2><p>想要减少任务的响应时间，首先要看你的系统是 CPU 密集型还是 IO 密集型的。不同类型的系统性能优化方式不尽相同。</p><p>CPU 密集型系统中，需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段。</p><p>IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这里 IO 指的是磁盘 IO 和网络 IO。我们熟知的系统大部分都属于 IO 密集型，比如数据库系统、缓存系统、Web 系统。</p><p>比方说，如果是数据库访问慢，那么就要看是不是有锁表的情况、是不是有全表扫描、索引加的是否合适、是否有 JOIN 操作、需不需要加缓存，等等；如果是网络的问题，就要看网络的参数是否有优化的空间，抓包来看是否有大量的超时重传，网卡是否有大量丢包等。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《高并发系统设计40问》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;性能的度量指标&quot;&gt;&lt;a href=&quot;#性能的度量指标&quot; class=&quot;headerlink&quot; title=&quot;性能的度量指标&quot;&gt;&lt;/a&gt;性能的度量指标&lt;/h1&gt;&lt;p&gt;1、平均值&lt;/p&gt;
&lt;p&gt;平均值是把这段时间所有请求的响应时间数据相加，再除以总请求数。但是它存在一</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="高并发系统设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="并发" scheme="http://example.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>临时表为什么可以重名</title>
    <link href="http://example.com/2023/04/24/MySQL/%E4%B8%B4%E6%97%B6%E8%A1%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%90%8D/"/>
    <id>http://example.com/2023/04/24/MySQL/%E4%B8%B4%E6%97%B6%E8%A1%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%90%8D/</id>
    <published>2023-04-24T08:26:40.000Z</published>
    <updated>2023-04-24T10:47:11.650Z</updated>
    
    <content type="html"><![CDATA[<p> 临时表的一些特性：</p><p>1、创建语法：create temporary table</p><p>2、只有创建该表的session才可以访问，其他线程无法访问</p><p>3、临时表可以与普通表重名</p><p>4、session中有同名的临时表和普通表时，操作的都是临时表</p><h1 id="临时表应用"><a href="#临时表应用" class="headerlink" title="临时表应用"></a>临时表应用</h1><p>在分库分表的场景下，我们现在假设某一个大表ht 按照字段f分为了1024个表，分布在32个数据库上。如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424170242139.png" alt="image-20230424170242139" style="zoom: 50%;" /><p>这种设计下，如果我们执行如下sql：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select v from ht where f = N;</span><br></pre></td></tr></table></figure><p>因为该sql使用了分表的字段f，那么我们就可以直接找到数据所在的表。</p><p>但是如果是如下sql：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select v from ht where k &gt;= M order by t_modified desc limit 100;</span><br></pre></td></tr></table></figure><p>该sql没有使用到分表的字段f，那么只能到所有的分区中去查找满足条件的所有行，然后统一做order by 的操作。</p><p>这种情况下，有两种方法：</p><p>1、把所有的数据全部查到，然后交给代理层去做排序。这种方法的优点是MySQL查询会很快，但是需要代理层多做额外的处理。</p><p>2、把各个分库拿到的数据，汇总到一个MySQL实例的一个表中，然后在这个汇总实例上做逻辑操作。流程如下图：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424171857340.png" alt="image-20230424171857340" style="zoom:67%;" /><h1 id="为什么临时表可以重名？"><a href="#为什么临时表可以重名？" class="headerlink" title="为什么临时表可以重名？"></a>为什么临时表可以重名？</h1><p>MySQL维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个table_def_key。</p><ul><li>一个普通表的table_def_key的值是由“库名+表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现table_def_key已经存在了。</li><li>而对于临时表，table_def_key在“库名+表名”基础上，又加入了“server_id+thread_id”。</li></ul><p>也就是说，session A和sessionB创建的两个临时表t1，它们的table_def_key不同，磁盘文件名也不同，因此可以并存。</p><p>在实现上，每个线程都维护了自己的临时表链表。这样每次session内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在session结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE +表名”操作。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 临时表的一些特性：&lt;/p&gt;
&lt;p&gt;1、创建语法：create temporary table&lt;/p&gt;
&lt;p&gt;2、只有创建该表的session才可以访问，其他线程无法访问&lt;/p&gt;
&lt;p&gt;3、临时表可以与普通表重名&lt;/p&gt;
&lt;p&gt;4、session中有同名的临时表和普通表时，</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="MySQL" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/MySQL/"/>
    
    <category term="其他" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/MySQL/%E5%85%B6%E4%BB%96/"/>
    
    
    <category term="MySQL45讲" scheme="http://example.com/tags/MySQL45%E8%AE%B2/"/>
    
  </entry>
  
  <entry>
    <title>流水线可靠数据传输协议</title>
    <link href="http://example.com/2023/04/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/"/>
    <id>http://example.com/2023/04/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/</id>
    <published>2023-04-24T06:24:35.000Z</published>
    <updated>2023-04-24T08:11:32.420Z</updated>
    
    <content type="html"><![CDATA[<p>rdt3.0虽然是一个正确的协议，但是很多人对于它的性能并不是很满意，因为它基于停等协议。而且是发送一个报文，就需要等待对方回复后才可以发送下一个，这很大程度上会影响性能。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424143036576.png" alt="image-20230424143036576" style="zoom:67%;" /><p>对此最简单的解决办法是，发送一个报文段后并不等待回复，而是继续发送，累计N个报文段后再等待对方回复，这样效率就会提高。如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424143059781.png" alt="image-20230424143059781" style="zoom:67%;" /><p>这种技术也被称为流水线。有如下要求：</p><p>1、必须增加序号范围，而且每个分组有一个唯一的序号，用于确认是否正确传输。</p><p>2、协议的发送方和接收方都需要缓存多个分组，发送方需最低要缓存已经发送的但是对方还没确认的报文，用于重新发送。</p><p>3、解决流水线的差错恢复有两种基本方法：回退N步和选择重传</p><h1 id="回退N步（GBN）"><a href="#回退N步（GBN）" class="headerlink" title="回退N步（GBN）"></a>回退N步（GBN）</h1><p>该协议中，允许发送方发送N个分组而不需要等待确认。这里的N一般称为窗口长度，如果窗口里面的数据都没有被确认，则无法继续发送，如果有数据确认，则窗口向前移动，继续发送数据。如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424144240644.png" alt="image-20230424144240644" style="zoom:80%;" /><p>该协议也被称为滑动窗口协议。该协议的发送方必须响应以下三类事件：</p><p>1、上层的调用。当上层调用时，发送方先检查窗口是否已满，即是否有N个数据未确认。如果没满，就产生分组并且发送，并更新变量。如果满了，就告诉上层窗口已满，让它过一段时间重试。</p><p>2、接受一个ACK。该协议中对序号为n的分组采用累计确认的方式，表明接收方已经接收到序号为n以前包括序号为n的所有分组。</p><p>3、超时事件。如果发送的数据超过一定时间还未收到回复，那么就需要重传所有已经发送但是还未确认收到的数据。</p><p>接收方也会有对应的要求：</p><p>如果接受方正确接收到一个分组为n的分组（即上一次交给应用层的分组号是n - 1），则会给发送方回复一个ACK，并将分组交给上层，其他情况都会丢弃该分组。因为接收方发送序号为n的ACK，意味着n以及n以前的数据都正确接收。</p><p>即接收方的逻辑如下图所示：</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424145709764.png" alt="image-20230424145709764" style="zoom:67%;" /><h1 id="选择重传"><a href="#选择重传" class="headerlink" title="选择重传"></a>选择重传</h1><p>上述协议虽然提升了性能，但是也存在一些问题。比如，当窗口和带宽的时延比较大的时候，中间有一个分组的差错，就会导致大量的重传。</p><p>而选择重传就是只重传错误的分组，而不是重传某一个错误分组以后的所有分组。该协议的实现需要接收方也缓存一部分的数据，而且也要有窗口。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424151809822.png" alt="image-20230424151809822" style="zoom:67%;" /><p>具体来说就是缓存那些乱序到达的数据，比如现在已经确认接收了需要为3的分组，而分组4丢失了，此时又接收到了分组5以及后续的数据。此时分组5以及以后的都会被缓存，直到接收到4后，才会从缓存中按序读取，然后交付给上层。具体过程如下：</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424151833002.png" alt="image-20230424151833002"></p><p>由上图可以看出，发送方和接收方的窗口内的数据并不总是一样的，这也就会导致以下问题：</p><h2 id="如何判断一个分组是重传还是一个新的分组呢？"><a href="#如何判断一个分组是重传还是一个新的分组呢？" class="headerlink" title="如何判断一个分组是重传还是一个新的分组呢？"></a>如何判断一个分组是重传还是一个新的分组呢？</h2><p>考虑下面例子中可能发生的情况，该例有包括4个分组序号0、1、2、3的有限序号范围且窗口长度为3。假定发送了分组0至2,并在接收方被正确接收且确认了。此时，接收方窗口落在第4、5、6个分组上，其序号分别为3、0、1。</p><p>现在考虑两种情况，第一种如下图：</p><p>对前3个分组的ACK丢失，因此发送方重传这些分组，接收方下一步要接收序号为0的分组，而他期望的分组却是序号为3的，而且它无法发现这是重传的前三个已经接收的分组，而会当作是分组3丢失，等待重传3，而接收传送过来的0和1，将他们放在缓存当中。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424152342787.png" alt="image-20230424152342787" style="zoom:67%;" /><p>下图的情况是，对前3个分组的ACK都被正确交付。因此发送方向前移动窗口并发送第4、5、6个分组，其序号分别为3、0、10序号为3的分组丢失，但序号为0的分组到达（一个包含新数据的分组）。</p><p>这时候接收方收到序号为0的分组时，他无法判断发送方是重发自己已经接收的序号0还是新发送的序号为0的分组。</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230424152417252.png" alt="image-20230424152417252" style="zoom:67%;" /><p>显然，窗口长度比序号空间小1时协议无法工作。窗口长度必须小于或等于序号空间大小的一半。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;rdt3.0虽然是一个正确的协议，但是很多人对于它的性能并不是很满意，因为它基于停等协议。而且是发送一个报文，就需要等待对方回复后才可以发送下一个，这很大程度上会影响性能。&lt;/p&gt;
&lt;img src=&quot;https://image-1314238346.cos.ap-chon</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="运输层" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
    
    <category term="运输层" scheme="http://example.com/tags/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
  </entry>
  
  <entry>
    <title>MySQL读写分离存在的问题</title>
    <link href="http://example.com/2023/04/23/MySQL/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2023/04/23/MySQL/MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2023-04-23T02:49:01.000Z</published>
    <updated>2023-04-23T05:43:57.915Z</updated>
    
    <content type="html"><![CDATA[<p>在MySQL的一主多从的架构中，往往有以下两种设计方案：</p><p>1、由客户端决定连接哪个数据库</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230423105127688.png" alt="image-20230423105127688" style="zoom:67%;" /><p>2、由代理决定请求分发到哪一个数据库</p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230423105207833.png" alt="image-20230423105207833" style="zoom:67%;" /><p>但不管是哪种方案，都存在过期读的问题，即主库和从库存在一定的时延，用户刚做一个修改，然后立马发起查询，就有可能查到过期数据。以下给出几种解决方案。</p><h1 id="强制走主库"><a href="#强制走主库" class="headerlink" title="强制走主库"></a>强制走主库</h1><p>该方案将请求分为了两类：</p><p>1、必须拿到最新数据的，就强制走主库查询。</p><p>2、对于可以读取到旧数据的，就走从库查询。</p><h1 id="Sleep-方案"><a href="#Sleep-方案" class="headerlink" title="Sleep 方案"></a>Sleep 方案</h1><p>该方案的设计很简单，读从库之前先sleep一段时间。</p><p>它假设大多情况下主备延迟在1秒之内，所以简单的sleep可以拿到最新的数据。</p><h1 id="判断主备无延迟方案"><a href="#判断主备无延迟方案" class="headerlink" title="判断主备无延迟方案"></a>判断主备无延迟方案</h1><p>这里有几种办法，第一种是从库查询前，先判断seconds_behind_master是否已经等于0。如果还不等于0 ，那就必须等到这个参数变为0才能执行查询请求。</p><p>第二种和第三种方案，都是通过对比主库和从库的日志执行位点来判断是否有延迟，即通过对比主库和从库执行的日志，来判断，要比对比时间准确。</p><p>但是这里也存在问题，主库存在一部分日志刚刚提交，而从库还没收到该日志，也会导致有一定的延迟。</p><h1 id="配合semi-sync"><a href="#配合semi-sync" class="headerlink" title="配合semi-sync"></a>配合semi-sync</h1><p>这里引入了半同步复制，semi-sync做了这样的设计：</p><ol><li>事务提交的时候，主库把binlog发给从库；</li><li>从库收到binlog以后，发回给主库一个ack，表示收到了；</li><li>主库收到这个ack以后，才能给客户端返回“事务完成”的确认。</li></ol><p>这样可以保证如果从库发送过确认消息，就代表收到了日志。这样，semi-sync配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。</p><p>但是该方案适合一主一从的架构，如果一主多从，那么一个从库响应，就默认已经同步成功，但是其他从库不确定。如果此时查询走的是其他从库，则还是会有问题。</p><p>而且存在一种情况，如果高峰期日志写的很快，可能会导致主库位点一直不一致的情况，就出现从库迟迟无法响应的问题。</p><h1 id="等主库位点方案"><a href="#等主库位点方案" class="headerlink" title="等主库位点方案"></a>等主库位点方案</h1><p>该方案涉及到以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select master_pos_wait(file, pos[, timeout]);</span><br></pre></td></tr></table></figure><p>该命令在从库执行，参数file和pos指向从库上的某个文件以及对应位置，timeout可选，表示这个函数最多的等待时间。</p><p>这个命令正常返回的结果是一个正整数M，表示从命令开始执行，到应用完file和pos表示的binlog位置，执行了多少事务。</p><p>那么我们的查询逻辑变为以下：</p><p>1、主库执行完事务后，执行show master status得到当前主库执行到的File和Position；</p><p>2、从库查询之间，先执行master_pos_wait（File，Position）</p><p>3、如果返回 &gt;&#x3D; 0的正整数，则在该从库执行查询，否则到主库查询。</p><h1 id="GTID方案"><a href="#GTID方案" class="headerlink" title="GTID方案"></a>GTID方案</h1><p>该方案和上述等主库位点方案思路一致，只不过是后续MySQL做了优化。</p><p>我们不再需要去主库执行show master status来获取位点，而是主库执行完后，直接返回一个事务的GTID，然后从库执行时，只需要在从库执行select wait_for_executed_gtid_set(gtid1, 1)，该命令也是用于等待主从同步的命令。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《MySQL45讲》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在MySQL的一主多从的架构中，往往有以下两种设计方案：&lt;/p&gt;
&lt;p&gt;1、由客户端决定连接哪个数据库&lt;/p&gt;
&lt;img src=&quot;https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-2023042310</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="MySQL" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/MySQL/"/>
    
    <category term="其他" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/MySQL/%E5%85%B6%E4%BB%96/"/>
    
    
    <category term="MySQL45讲" scheme="http://example.com/tags/MySQL45%E8%AE%B2/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统的通用设计方案</title>
    <link href="http://example.com/2023/04/22/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%80%9A%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88/"/>
    <id>http://example.com/2023/04/22/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%80%9A%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88/</id>
    <published>2023-04-22T10:07:31.000Z</published>
    <updated>2023-04-22T10:29:26.107Z</updated>
    
    <content type="html"><![CDATA[<p>高并发系统的通用设计：</p><p>Scale-out（横向扩展）：采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。</p><p>缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击。</p><p>异步：在某些场景下，未处理完成之前我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。</p><h1 id="Scale-out"><a href="#Scale-out" class="headerlink" title="Scale-out"></a>Scale-out</h1><p>这里牵扯到一个横向扩展（Scale-out）与纵向扩展（Scale-up）。其中纵向扩展是不断的提高单个cpu的处理能力，来处理更多的请求。而横向扩展则是指利用多个cpu资源来并行处理，来处理更多请求。</p><p>一般来说，在项目初期，我们可以采用纵向扩展，当单机无法承受时，再使用横向扩展。</p><h1 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h1><p>我们的数据都是存储在磁盘上的，而磁盘的读取速度特别的慢，会给处理请求带来很大的压力。所以产生了缓存。在现代的设计中，从操作系统到浏览器，从数据库到消息队列都可以看到缓存的影子。</p><p>由于缓存是基于内存读写的，所以速度要比磁盘读取快很多。如果能够能快的读写数据，那么每个请求的处理时间都会变短，那么就会提高系统的并发度。</p><h1 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h1><p>异步处理相对应的就是同步。</p><p>同步是指调用一个方法，需要等到该方法返回之后，才可以继续执行后续的操作。这种情况下，如果调用的方法响应时间太长的话，会导致后续的业务阻塞。</p><p>异步处理是指调用方法后，并不需要等待方法处理完，可以直接执行后续的请求。比如说，我们可以将请求放入队列当中，然后响应用户一个信息，等处理完结果后，再给用户反馈一下，这样可以处理更多的请求。</p><p><img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20230422182314880.png" alt="image-20230422182314880"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>《高并发系统设计40问》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;高并发系统的通用设计：&lt;/p&gt;
&lt;p&gt;Scale-out（横向扩展）：采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。&lt;/p&gt;
&lt;p&gt;缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击。&lt;/p&gt;
&lt;p&gt;异步：在某些场景下，</summary>
      
    
    
    
    <category term="学习笔记" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="高并发系统设计" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="并发" scheme="http://example.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
</feed>
